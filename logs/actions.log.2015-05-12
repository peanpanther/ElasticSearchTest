2015-05-12-09:59:12:849 - INFO  - Log4jESLogger - [Ocean] version[0.90.5], pid[5595], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-09:59:12:853 - INFO  - Log4jESLogger - [Ocean] initializing ...
2015-05-12-09:59:12:855 - DEBUG - Log4jESLogger - [Ocean] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-09:59:12:866 - INFO  - Log4jESLogger - [Ocean] loaded [], sites []
2015-05-12-09:59:12:892 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-09:59:12:934 - TRACE - Log4jESLogger - [Ocean] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-09:59:12:944 - DEBUG - Log4jESLogger - [Ocean] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-09:59:12:950 - TRACE - Log4jESLogger - [Ocean] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-09:59:13:524 - TRACE - Log4jESLogger - [Ocean] sigar loaded successfully
2015-05-12-09:59:14:148 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-09:59:14:153 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-09:59:14:157 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-09:59:14:158 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-09:59:14:160 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-09:59:14:172 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-09:59:14:173 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-09:59:14:176 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-09:59:14:178 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:14:178 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:14:179 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:14:179 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:14:179 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:14:180 - DEBUG - Log4jESLogger - [Ocean] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-09:59:14:195 - DEBUG - Log4jESLogger - [Ocean] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-09:59:14:206 - DEBUG - Log4jESLogger - [Ocean] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-09:59:14:211 - DEBUG - Log4jESLogger - [Ocean] using initial hosts [], with concurrent_connects [10]
2015-05-12-09:59:14:214 - DEBUG - Log4jESLogger - [Ocean] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-09:59:14:215 - DEBUG - Log4jESLogger - [Ocean] using minimum_master_nodes [-1]
2015-05-12-09:59:14:217 - DEBUG - Log4jESLogger - [Ocean] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-09:59:14:223 - DEBUG - Log4jESLogger - [Ocean] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-09:59:14:260 - DEBUG - Log4jESLogger - [Ocean] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-09:59:14:770 - DEBUG - Log4jESLogger - [Ocean] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-09:59:14:804 - DEBUG - Log4jESLogger - [Ocean] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-09:59:14:811 - DEBUG - Log4jESLogger - [Ocean] Using refresh_interval [1s]
2015-05-12-09:59:14:812 - DEBUG - Log4jESLogger - [Ocean] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-09:59:14:817 - DEBUG - Log4jESLogger - [Ocean] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-09:59:14:820 - TRACE - Log4jESLogger - [Ocean] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:9758 errors:0 dropped:0 overruns:0 frame:0
	TX packets:9758 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:958312 (936K)  TX bytes:958312 (936K)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:206486 errors:0 dropped:0 overruns:0 frame:0
	TX packets:109881 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:239412193 (228M)  TX bytes:11816328 ( 11M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:209 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:208 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-09:59:14:826 - DEBUG - Log4jESLogger - [Ocean] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-09:59:15:126 - DEBUG - Log4jESLogger - [Ocean] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-09:59:15:140 - DEBUG - Log4jESLogger - [Ocean] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-09:59:15:150 - DEBUG - Log4jESLogger - [Ocean] using script cache with max_size [500], expire [null]
2015-05-12-09:59:15:158 - DEBUG - Log4jESLogger - [Ocean] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-09:59:15:162 - DEBUG - Log4jESLogger - [Ocean] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-09:59:15:164 - DEBUG - Log4jESLogger - [Ocean] using [cluster_concurrent_rebalance] with [2]
2015-05-12-09:59:15:176 - DEBUG - Log4jESLogger - [Ocean] using initial_shards [quorum], list_timeout [30s]
2015-05-12-09:59:15:276 - DEBUG - Log4jESLogger - [Ocean] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-09:59:15:342 - DEBUG - Log4jESLogger - [Ocean] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-09:59:15:351 - DEBUG - Log4jESLogger - [Ocean] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-09:59:15:354 - DEBUG - Log4jESLogger - [Ocean] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-09:59:15:357 - DEBUG - Log4jESLogger - [Ocean] using size [-1] [-1b], expire [null]
2015-05-12-09:59:15:373 - DEBUG - Log4jESLogger - [Ocean] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-09:59:15:407 - TRACE - Log4jESLogger - [Ocean] [upgrade]: processing [global-21]
2015-05-12-09:59:15:553 - DEBUG - Log4jESLogger - [Ocean] took 146ms to load state
2015-05-12-09:59:15:554 - TRACE - Log4jESLogger - [Ocean] [find_latest_state]: processing [global-21]
2015-05-12-09:59:15:654 - DEBUG - Log4jESLogger - [Ocean] took 100ms to load started shards state
2015-05-12-09:59:15:657 - DEBUG - Log4jESLogger - [Ocean] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-09:59:15:662 - DEBUG - Log4jESLogger - [Ocean] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-09:59:15:662 - DEBUG - Log4jESLogger - [Ocean] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-09:59:15:663 - DEBUG - Log4jESLogger - [Ocean] using [cluster_concurrent_rebalance] with [2]
2015-05-12-09:59:15:664 - DEBUG - Log4jESLogger - [Ocean] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-09:59:15:664 - DEBUG - Log4jESLogger - [Ocean] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-09:59:15:665 - DEBUG - Log4jESLogger - [Ocean] using [cluster_concurrent_rebalance] with [2]
2015-05-12-09:59:15:671 - INFO  - Log4jESLogger - [Ocean] initialized
2015-05-12-09:59:15:672 - INFO  - Log4jESLogger - [Ocean] starting ...
2015-05-12-09:59:15:696 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-09:59:15:697 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-09:59:15:765 - DEBUG - Log4jESLogger - [Ocean] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-09:59:15:769 - INFO  - Log4jESLogger - [Ocean] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-09:59:15:796 - TRACE - Log4jESLogger - [Ocean] waiting for 30s for the initial state to be set by the discovery
2015-05-12-09:59:15:803 - TRACE - Log4jESLogger - [Ocean] [1] sending ping request
2015-05-12-09:59:17:305 - TRACE - Log4jESLogger - [Ocean] [1] sending ping request
2015-05-12-09:59:18:811 - TRACE - Log4jESLogger - [Ocean] full ping responses: {none}
2015-05-12-09:59:18:812 - DEBUG - Log4jESLogger - [Ocean] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-09:59:18:816 - DEBUG - Log4jESLogger - [Ocean] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-09:59:18:818 - TRACE - Log4jESLogger - [Ocean] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[JCZd_C9DQ8S6J2IYFAxCFw][V]
---- unassigned

2015-05-12-09:59:18:820 - INFO  - Log4jESLogger - [Ocean] new_master [Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-12-09:59:18:834 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0xaf078f59, /10.11.66.27:47505 => /10.11.66.27:9300]
2015-05-12-09:59:18:836 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0xf810c656, /10.11.66.27:47506 => /10.11.66.27:9300]
2015-05-12-09:59:18:837 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0x4896f4ce, /10.11.66.27:47507 => /10.11.66.27:9300]
2015-05-12-09:59:18:840 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0xa1ddffdd, /10.11.66.27:47508 => /10.11.66.27:9300]
2015-05-12-09:59:18:842 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0x0bb4044e, /10.11.66.27:47509 => /10.11.66.27:9300]
2015-05-12-09:59:18:845 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0xdb8cfe54, /10.11.66.27:47510 => /10.11.66.27:9300]
2015-05-12-09:59:18:845 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0x50d7d71d, /10.11.66.27:47511 => /10.11.66.27:9300]
2015-05-12-09:59:18:846 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0x7ae68125, /10.11.66.27:47512 => /10.11.66.27:9300]
2015-05-12-09:59:18:851 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0x750903cf, /10.11.66.27:47513 => /10.11.66.27:9300]
2015-05-12-09:59:18:852 - DEBUG - Log4jESLogger - [Ocean] connected to node [[Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]]]
2015-05-12-09:59:18:852 - TRACE - Log4jESLogger - [Ocean] channel opened: [id: 0xd93df85c, /10.11.66.27:47514 => /10.11.66.27:9300]
2015-05-12-09:59:18:853 - DEBUG - Log4jESLogger - [Ocean] Publishing cluster state version 1
2015-05-12-09:59:18:854 - DEBUG - Log4jESLogger - [Ocean] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-09:59:18:857 - DEBUG - Log4jESLogger - [Ocean] processing [reroute_rivers_node_changed]: execute
2015-05-12-09:59:18:857 - DEBUG - Log4jESLogger - [Ocean] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-09:59:18:857 - TRACE - Log4jESLogger - [Ocean] initial state set from discovery
2015-05-12-09:59:18:857 - DEBUG - Log4jESLogger - [Ocean] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-09:59:18:857 - TRACE - Log4jESLogger - [Ocean] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-09:59:18:859 - INFO  - Log4jESLogger - [Ocean] peansData/JCZd_C9DQ8S6J2IYFAxCFw
2015-05-12-09:59:18:860 - TRACE - Log4jESLogger - [Ocean] performing state recovery...
2015-05-12-09:59:18:860 - TRACE - Log4jESLogger - [Ocean] performing state recovery from [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:868 - TRACE - Log4jESLogger - [Ocean] successful state recovery, importing cluster state...
2015-05-12-09:59:18:870 - DEBUG - Log4jESLogger - [Ocean] processing [local-gateway-elected-state]: execute
2015-05-12-09:59:18:888 - DEBUG - Log4jESLogger - [Ocean] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-09:59:18:889 - INFO  - Log4jESLogger - [Ocean] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-12-09:59:18:890 - INFO  - Log4jESLogger - [Ocean] started
2015-05-12-09:59:18:896 - DEBUG - Log4jESLogger - [Ocean] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-09:59:18:898 - DEBUG - Log4jESLogger - [Ocean] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-09:59:18:899 - DEBUG - Log4jESLogger - [Ocean] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-09:59:18:901 - DEBUG - Log4jESLogger - [Ocean] [mimos][4]: throttling allocation [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[[Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-12-09:59:18:904 - TRACE - Log4jESLogger - [Ocean] Start balancing cluster
2015-05-12-09:59:18:906 - TRACE - Log4jESLogger - [Ocean] Start distributing Shards
2015-05-12-09:59:18:907 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:908 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:908 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:908 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:908 - TRACE - Log4jESLogger - [Ocean] Start allocating unassigned shards
2015-05-12-09:59:18:909 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:18:910 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:18:910 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:18:910 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:18:910 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:18:912 - TRACE - Log4jESLogger - [Ocean] Start balancing cluster
2015-05-12-09:59:18:912 - TRACE - Log4jESLogger - [Ocean] Start distributing Shards
2015-05-12-09:59:18:912 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:912 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:912 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:913 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:18:913 - TRACE - Log4jESLogger - [Ocean] Start allocating unassigned shards
2015-05-12-09:59:18:915 - TRACE - Log4jESLogger - [Ocean] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[JCZd_C9DQ8S6J2IYFAxCFw][V]
--------[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
--------[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
--------[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
--------[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-09:59:18:916 - DEBUG - Log4jESLogger - [Ocean] Publishing cluster state version 2
2015-05-12-09:59:18:917 - DEBUG - Log4jESLogger - [Ocean] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-09:59:18:918 - DEBUG - Log4jESLogger - [Ocean] processing [reroute_rivers_node_changed]: execute
2015-05-12-09:59:18:918 - DEBUG - Log4jESLogger - [Ocean] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-09:59:18:919 - DEBUG - Log4jESLogger - [Ocean] [mimos] creating index
2015-05-12-09:59:18:919 - DEBUG - Log4jESLogger - [Ocean] creating Index [mimos], shards [5]/[1]
2015-05-12-09:59:19:285 - TRACE - Log4jESLogger - [Ocean] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [JCZd_C9DQ8S6J2IYFAxCFw], scheduling a retry.
2015-05-12-09:59:19:322 - DEBUG - Log4jESLogger - [Ocean] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-09:59:19:323 - DEBUG - Log4jESLogger - [Ocean] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-09:59:19:337 - DEBUG - Log4jESLogger - [Ocean] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-09:59:19:425 - DEBUG - Log4jESLogger - [Ocean] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-09:59:19:508 - DEBUG - Log4jESLogger - [Ocean] Sending mapping created for index mimos, type Programmer
2015-05-12-09:59:19:511 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] creating shard
2015-05-12-09:59:19:511 - DEBUG - Log4jESLogger - [Ocean] [mimos] creating shard_id [0]
2015-05-12-09:59:19:664 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-09:59:19:669 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-09:59:19:670 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-09:59:19:676 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] state: [CREATED]
2015-05-12-09:59:19:678 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-09:59:19:685 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-09:59:19:688 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] starting recovery from local ...
2015-05-12-09:59:19:690 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] creating shard
2015-05-12-09:59:19:691 - DEBUG - Log4jESLogger - [Ocean] [mimos] creating shard_id [1]
2015-05-12-09:59:19:702 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-09:59:19:703 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-09:59:19:705 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-09:59:19:708 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] state: [CREATED]
2015-05-12-09:59:19:709 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-09:59:19:710 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-09:59:19:712 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] creating shard
2015-05-12-09:59:19:712 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] starting recovery from local ...
2015-05-12-09:59:19:721 - TRACE - Log4jESLogger - [Ocean] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-09:59:19:721 - DEBUG - Log4jESLogger - [Ocean] [mimos] creating shard_id [2]
2015-05-12-09:59:19:722 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] starting engine
2015-05-12-09:59:19:737 - TRACE - Log4jESLogger - [Ocean] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-09:59:19:744 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] starting engine
2015-05-12-09:59:19:794 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-09:59:19:795 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-09:59:19:795 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-09:59:19:796 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] state: [CREATED]
2015-05-12-09:59:19:797 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-09:59:19:804 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-09:59:19:821 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] creating shard
2015-05-12-09:59:19:821 - DEBUG - Log4jESLogger - [Ocean] [mimos] creating shard_id [3]
2015-05-12-09:59:19:821 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] starting recovery from local ...
2015-05-12-09:59:19:840 - TRACE - Log4jESLogger - [Ocean] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-09:59:19:840 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] starting engine
2015-05-12-09:59:19:841 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-09:59:19:842 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-09:59:19:843 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-09:59:19:844 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] state: [CREATED]
2015-05-12-09:59:19:845 - TRACE - Log4jESLogger - [Ocean] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-09:59:19:845 - TRACE - Log4jESLogger - [Ocean] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-09:59:19:845 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-09:59:19:847 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-09:59:19:853 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] starting recovery from local ...
2015-05-12-09:59:19:854 - TRACE - Log4jESLogger - [Ocean] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-09:59:19:854 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] starting engine
2015-05-12-09:59:19:845 - TRACE - Log4jESLogger - [Ocean] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-09:59:19:857 - TRACE - Log4jESLogger - [Ocean] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-09:59:19:864 - TRACE - Log4jESLogger - [Ocean] [mimos][2] warming took [18.9ms]
2015-05-12-09:59:19:869 - TRACE - Log4jESLogger - [Ocean] [_global] writing state, reason [changed]
2015-05-12-09:59:19:877 - TRACE - Log4jESLogger - [Ocean] [mimos][0] warming took [31.2ms]
2015-05-12-09:59:19:878 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-09:59:19:879 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] scheduling refresher every 1s
2015-05-12-09:59:19:881 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-09:59:19:881 - TRACE - Log4jESLogger - [Ocean] [mimos][3] warming took [23.4ms]
2015-05-12-09:59:19:883 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-09:59:19:868 - TRACE - Log4jESLogger - [Ocean] [mimos][1] warming took [11ms]
2015-05-12-09:59:19:885 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-09:59:19:876 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-09:59:19:886 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] scheduling refresher every 1s
2015-05-12-09:59:19:887 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-09:59:19:881 - TRACE - Log4jESLogger - [Ocean] [mimos][0] refresh with force[true]
2015-05-12-09:59:19:888 - DEBUG - Log4jESLogger - [Ocean] [mimos][0] recovery completed from [local], took [199ms]
2015-05-12-09:59:19:888 - DEBUG - Log4jESLogger - [Ocean] sending shard started for [mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:19:888 - DEBUG - Log4jESLogger - [Ocean] received shard started for [mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:19:890 - TRACE - Log4jESLogger - [Ocean] [mimos][2] refresh with force[true]
2015-05-12-09:59:19:891 - DEBUG - Log4jESLogger - [Ocean] [mimos][2] recovery completed from [local], took [70ms]
2015-05-12-09:59:19:891 - DEBUG - Log4jESLogger - [Ocean] sending shard started for [mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:19:891 - DEBUG - Log4jESLogger - [Ocean] received shard started for [mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:19:890 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] scheduling refresher every 1s
2015-05-12-09:59:19:892 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-09:59:19:893 - TRACE - Log4jESLogger - [Ocean] [mimos][3] refresh with force[true]
2015-05-12-09:59:19:893 - DEBUG - Log4jESLogger - [Ocean] [mimos][3] recovery completed from [local], took [40ms]
2015-05-12-09:59:19:893 - DEBUG - Log4jESLogger - [Ocean] sending shard started for [mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:19:893 - DEBUG - Log4jESLogger - [Ocean] received shard started for [mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:19:890 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] scheduling refresher every 1s
2015-05-12-09:59:19:895 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-09:59:19:895 - TRACE - Log4jESLogger - [Ocean] [mimos][1] refresh with force[true]
2015-05-12-09:59:19:896 - DEBUG - Log4jESLogger - [Ocean] [mimos][1] recovery completed from [local], took [184ms]
2015-05-12-09:59:19:896 - DEBUG - Log4jESLogger - [Ocean] sending shard started for [mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:19:896 - DEBUG - Log4jESLogger - [Ocean] received shard started for [mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:19:952 - INFO  - Log4jESLogger - [Ocean] recovered [1] indices into cluster_state
2015-05-12-09:59:19:952 - DEBUG - Log4jESLogger - [Ocean] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-09:59:19:954 - TRACE - Log4jESLogger - [Ocean] listener to cluster state added, trying to index again
2015-05-12-09:59:19:954 - TRACE - Log4jESLogger - [Ocean] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [JCZd_C9DQ8S6J2IYFAxCFw], scheduling a retry.
2015-05-12-09:59:19:955 - TRACE - Log4jESLogger - [Ocean] retry scheduling ignored as it as we already have a listener in place
2015-05-12-09:59:19:955 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-09:59:19:956 - DEBUG - Log4jESLogger - [Ocean] applying started shards [[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], [mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], [mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], [mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-09:59:19:957 - DEBUG - Log4jESLogger - [Ocean] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-09:59:19:958 - TRACE - Log4jESLogger - [Ocean] Start balancing cluster
2015-05-12-09:59:19:959 - TRACE - Log4jESLogger - [Ocean] Start distributing Shards
2015-05-12-09:59:19:959 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:959 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:959 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:960 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:960 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:960 - TRACE - Log4jESLogger - [Ocean] Start allocating unassigned shards
2015-05-12-09:59:19:960 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:19:961 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:19:961 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:19:962 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:19:962 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:19:963 - TRACE - Log4jESLogger - [Ocean] Start balancing cluster
2015-05-12-09:59:19:963 - TRACE - Log4jESLogger - [Ocean] Start distributing Shards
2015-05-12-09:59:19:964 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:964 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:964 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:965 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:965 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:19:965 - TRACE - Log4jESLogger - [Ocean] Start allocating unassigned shards
2015-05-12-09:59:19:966 - TRACE - Log4jESLogger - [Ocean] cluster state updated:
version [3], source [shard-started ([mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[JCZd_C9DQ8S6J2IYFAxCFw][V]
--------[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-09:59:19:967 - DEBUG - Log4jESLogger - [Ocean] Publishing cluster state version 3
2015-05-12-09:59:19:967 - DEBUG - Log4jESLogger - [Ocean] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-09:59:19:968 - DEBUG - Log4jESLogger - [Ocean] processing [reroute_rivers_node_changed]: execute
2015-05-12-09:59:19:969 - DEBUG - Log4jESLogger - [Ocean] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-09:59:19:976 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] creating shard
2015-05-12-09:59:19:977 - DEBUG - Log4jESLogger - [Ocean] [mimos] creating shard_id [4]
2015-05-12-09:59:19:986 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-09:59:19:988 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-09:59:19:989 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-09:59:19:990 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] state: [CREATED]
2015-05-12-09:59:19:991 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-09:59:19:992 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-09:59:19:992 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] starting recovery from local ...
2015-05-12-09:59:19:993 - TRACE - Log4jESLogger - [Ocean] cluster changed (version 3), trying to index again
2015-05-12-09:59:19:995 - TRACE - Log4jESLogger - [Ocean] [mimos][0] writing shard state, reason [version changed from [36] to [38]]
2015-05-12-09:59:20:010 - TRACE - Log4jESLogger - [Ocean] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-09:59:20:010 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] starting engine
2015-05-12-09:59:20:013 - TRACE - Log4jESLogger - [Ocean] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-09:59:20:014 - TRACE - Log4jESLogger - [Ocean] [mimos][4] warming took [96.5micros]
2015-05-12-09:59:20:014 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-09:59:20:015 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] scheduling refresher every 1s
2015-05-12-09:59:20:015 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-09:59:20:015 - TRACE - Log4jESLogger - [Ocean] [mimos][4] refresh with force[true]
2015-05-12-09:59:20:017 - DEBUG - Log4jESLogger - [Ocean] [mimos][4] recovery completed from [local], took [24ms]
2015-05-12-09:59:20:019 - DEBUG - Log4jESLogger - [Ocean] sending shard started for [mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:20:019 - DEBUG - Log4jESLogger - [Ocean] received shard started for [mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-09:59:20:033 - TRACE - Log4jESLogger - [Ocean] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-09:59:20:068 - DEBUG - Log4jESLogger - [Ocean] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-09:59:20:077 - INFO  - Log4jESLogger - [Wreckage] version[0.90.5], pid[5595], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-09:59:20:078 - INFO  - Log4jESLogger - [Wreckage] initializing ...
2015-05-12-09:59:20:078 - DEBUG - Log4jESLogger - [Wreckage] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-09:59:20:078 - INFO  - Log4jESLogger - [Wreckage] loaded [], sites []
2015-05-12-09:59:20:118 - TRACE - Log4jESLogger - [Wreckage] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-09:59:20:118 - TRACE - Log4jESLogger - [Ocean] [mimos][3] writing shard state, reason [version changed from [36] to [38]]
2015-05-12-09:59:20:119 - DEBUG - Log4jESLogger - [Wreckage] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-09:59:20:119 - TRACE - Log4jESLogger - [Wreckage] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-09:59:20:168 - TRACE - Log4jESLogger - [Ocean] [mimos][2] writing shard state, reason [version changed from [26] to [28]]
2015-05-12-09:59:20:172 - TRACE - Log4jESLogger - [Wreckage] sigar loaded successfully
2015-05-12-09:59:20:219 - TRACE - Log4jESLogger - [Ocean] [mimos][1] writing shard state, reason [version changed from [22] to [24]]
2015-05-12-09:59:20:266 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-09:59:20:267 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-09:59:20:268 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-09:59:20:268 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-09:59:20:269 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-09:59:20:269 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-09:59:20:269 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-09:59:20:270 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-09:59:20:270 - DEBUG - Log4jESLogger - [Ocean] applying started shards [[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-09:59:20:271 - TRACE - Log4jESLogger - [Ocean] Start balancing cluster
2015-05-12-09:59:20:271 - TRACE - Log4jESLogger - [Ocean] Start distributing Shards
2015-05-12-09:59:20:271 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:271 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:271 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:271 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:271 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:272 - TRACE - Log4jESLogger - [Ocean] Start allocating unassigned shards
2015-05-12-09:59:20:270 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-09:59:20:272 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:20:272 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:20:273 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:20:273 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:20:273 - TRACE - Log4jESLogger - [Ocean] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:20:273 - TRACE - Log4jESLogger - [Ocean] Start balancing cluster
2015-05-12-09:59:20:273 - TRACE - Log4jESLogger - [Ocean] Start distributing Shards
2015-05-12-09:59:20:274 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:274 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:274 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:274 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:274 - TRACE - Log4jESLogger - [Ocean] Assigned shard [[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]] to node [JCZd_C9DQ8S6J2IYFAxCFw]
2015-05-12-09:59:20:274 - TRACE - Log4jESLogger - [Ocean] Start allocating unassigned shards
2015-05-12-09:59:20:275 - TRACE - Log4jESLogger - [Ocean] cluster state updated:
version [4], source [shard-started ([mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Ocean][JCZd_C9DQ8S6J2IYFAxCFw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[JCZd_C9DQ8S6J2IYFAxCFw][V]
--------[mimos][0], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
--------[mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-09:59:20:276 - DEBUG - Log4jESLogger - [Ocean] Publishing cluster state version 4
2015-05-12-09:59:20:276 - DEBUG - Log4jESLogger - [Ocean] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-09:59:20:276 - DEBUG - Log4jESLogger - [Ocean] processing [reroute_rivers_node_changed]: execute
2015-05-12-09:59:20:277 - DEBUG - Log4jESLogger - [Ocean] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-09:59:20:272 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-09:59:20:281 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:20:282 - TRACE - Log4jESLogger - [Ocean] [mimos][4] writing shard state, reason [version changed from [38] to [40]]
2015-05-12-09:59:20:283 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:20:285 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:20:287 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:20:289 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-09:59:20:291 - DEBUG - Log4jESLogger - [Wreckage] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-09:59:20:293 - DEBUG - Log4jESLogger - [Wreckage] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-09:59:20:294 - DEBUG - Log4jESLogger - [Wreckage] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-09:59:20:295 - DEBUG - Log4jESLogger - [Wreckage] using initial hosts [], with concurrent_connects [10]
2015-05-12-09:59:20:295 - DEBUG - Log4jESLogger - [Wreckage] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-09:59:20:297 - DEBUG - Log4jESLogger - [Wreckage] using minimum_master_nodes [-1]
2015-05-12-09:59:20:300 - DEBUG - Log4jESLogger - [Wreckage] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-09:59:20:302 - DEBUG - Log4jESLogger - [Wreckage] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-09:59:20:309 - DEBUG - Log4jESLogger - [Wreckage] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-09:59:20:320 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][2], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-09:59:20:320 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-09:59:20:321 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][1], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-09:59:20:321 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-09:59:20:321 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][3], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-09:59:20:321 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-09:59:20:321 - DEBUG - Log4jESLogger - [Ocean] processing [shard-started ([mimos][4], node[JCZd_C9DQ8S6J2IYFAxCFw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-09:59:20:321 - DEBUG - Log4jESLogger - [Ocean] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-09:59:20:322 - DEBUG - Log4jESLogger - [Ocean] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-09:59:20:812 - DEBUG - Log4jESLogger - [Wreckage] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@45404d5] with refresh_interval [1s]
2015-05-12-09:59:20:813 - DEBUG - Log4jESLogger - [Wreckage] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@6dbcf214] with refresh_interval [1s]
2015-05-12-09:59:20:815 - DEBUG - Log4jESLogger - [Wreckage] Using refresh_interval [1s]
2015-05-12-09:59:20:816 - DEBUG - Log4jESLogger - [Wreckage] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@2e6f610d] with refresh_interval [5s]
2015-05-12-09:59:20:817 - DEBUG - Log4jESLogger - [Wreckage] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-09:59:20:818 - TRACE - Log4jESLogger - [Wreckage] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:9794 errors:0 dropped:0 overruns:0 frame:0
	TX packets:9794 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:960561 (938K)  TX bytes:960561 (938K)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:206565 errors:0 dropped:0 overruns:0 frame:0
	TX packets:109922 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:239420360 (228M)  TX bytes:11821495 ( 11M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:210 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:209 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-09:59:20:819 - DEBUG - Log4jESLogger - [Wreckage] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@741f8dbe] with refresh_interval [1s]
2015-05-12-09:59:20:821 - DEBUG - Log4jESLogger - [Wreckage] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-09:59:20:823 - DEBUG - Log4jESLogger - [Wreckage] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-09:59:20:824 - DEBUG - Log4jESLogger - [Wreckage] using script cache with max_size [500], expire [null]
2015-05-12-09:59:20:825 - DEBUG - Log4jESLogger - [Wreckage] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-09:59:20:826 - DEBUG - Log4jESLogger - [Wreckage] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-09:59:20:826 - DEBUG - Log4jESLogger - [Wreckage] using [cluster_concurrent_rebalance] with [2]
2015-05-12-09:59:20:827 - DEBUG - Log4jESLogger - [Wreckage] using initial_shards [quorum], list_timeout [30s]
2015-05-12-09:59:20:832 - DEBUG - Log4jESLogger - [Wreckage] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-09:59:20:982 - TRACE - Log4jESLogger - [Ocean] [mimos][2] refresh with force[false]
2015-05-12-09:59:20:983 - DEBUG - Log4jESLogger - [Wreckage] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-09:59:20:987 - DEBUG - Log4jESLogger - [Wreckage] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-09:59:20:987 - DEBUG - Log4jESLogger - [Wreckage] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-09:59:20:987 - DEBUG - Log4jESLogger - [Wreckage] using size [-1] [-1b], expire [null]
2015-05-12-09:59:20:989 - DEBUG - Log4jESLogger - [Wreckage] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-09:59:20:995 - TRACE - Log4jESLogger - [Wreckage] [upgrade]: processing [global-12]
2015-05-12-09:59:21:030 - DEBUG - Log4jESLogger - [Wreckage] took 35ms to load state
2015-05-12-09:59:21:030 - TRACE - Log4jESLogger - [Wreckage] [find_latest_state]: processing [global-12]
2015-05-12-09:59:21:056 - DEBUG - Log4jESLogger - [Wreckage] took 25ms to load started shards state
2015-05-12-09:59:21:057 - DEBUG - Log4jESLogger - [Wreckage] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-09:59:21:062 - DEBUG - Log4jESLogger - [Wreckage] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-09:59:21:063 - DEBUG - Log4jESLogger - [Wreckage] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-09:59:21:063 - DEBUG - Log4jESLogger - [Wreckage] using [cluster_concurrent_rebalance] with [2]
2015-05-12-09:59:21:063 - DEBUG - Log4jESLogger - [Wreckage] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-09:59:21:064 - DEBUG - Log4jESLogger - [Wreckage] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-09:59:21:064 - DEBUG - Log4jESLogger - [Wreckage] using [cluster_concurrent_rebalance] with [2]
2015-05-12-09:59:21:068 - INFO  - Log4jESLogger - [Wreckage] initialized
2015-05-12-09:59:21:068 - INFO  - Log4jESLogger - [Wreckage] starting ...
2015-05-12-09:59:21:080 - TRACE - Log4jESLogger - [Ocean] [mimos][2] warming [StandardDirectoryReader(segments_1:3:nrt _0(4.4):c1)], new [MultiReader(_0(4.4):c1)]
2015-05-12-09:59:21:081 - TRACE - Log4jESLogger - [Ocean] [mimos][2] warming took [211.3micros]
2015-05-12-09:59:21:092 - DEBUG - Log4jESLogger - [Wreckage] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-09:59:21:097 - INFO  - Log4jESLogger - [Wreckage] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-09:59:21:099 - TRACE - Log4jESLogger - [Wreckage] waiting for 30s for the initial state to be set by the discovery
2015-05-12-09:59:21:101 - TRACE - Log4jESLogger - [Ocean] [1] received ping_request from [[Wreckage][YxjMYjwtSGCG7kR5-TyYKg][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-09:59:21:101 - TRACE - Log4jESLogger - [Wreckage] [1] sending ping request
2015-05-12-09:59:22:602 - TRACE - Log4jESLogger - [Ocean] [1] received ping_request from [[Wreckage][YxjMYjwtSGCG7kR5-TyYKg][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-09:59:22:602 - TRACE - Log4jESLogger - [Wreckage] [1] sending ping request
2015-05-12-09:59:24:102 - TRACE - Log4jESLogger - [Wreckage] full ping responses: {none}
2015-05-12-09:59:24:102 - DEBUG - Log4jESLogger - [Wreckage] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-09:59:24:103 - DEBUG - Log4jESLogger - [Wreckage] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-09:59:24:104 - TRACE - Log4jESLogger - [Wreckage] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Wreckage][YxjMYjwtSGCG7kR5-TyYKg][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[YxjMYjwtSGCG7kR5-TyYKg][V]
---- unassigned

2015-05-12-09:59:24:105 - INFO  - Log4jESLogger - [Wreckage] new_master [Wreckage][YxjMYjwtSGCG7kR5-TyYKg][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-09:59:24:107 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0x56cca24c, /10.11.66.27:48981 => /10.11.66.27:9301]
2015-05-12-09:59:24:108 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0x2d2b622c, /10.11.66.27:48982 => /10.11.66.27:9301]
2015-05-12-09:59:24:111 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0x39f6c153, /10.11.66.27:48983 => /10.11.66.27:9301]
2015-05-12-09:59:24:112 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0xac3587c3, /10.11.66.27:48984 => /10.11.66.27:9301]
2015-05-12-09:59:24:114 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0x7ca02f0b, /10.11.66.27:48985 => /10.11.66.27:9301]
2015-05-12-09:59:24:116 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0x184e2b78, /10.11.66.27:48986 => /10.11.66.27:9301]
2015-05-12-09:59:24:117 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0x8f2098cd, /10.11.66.27:48987 => /10.11.66.27:9301]
2015-05-12-09:59:24:121 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0x7b1e6777, /10.11.66.27:48988 => /10.11.66.27:9301]
2015-05-12-09:59:24:124 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0x7342f568, /10.11.66.27:48989 => /10.11.66.27:9301]
2015-05-12-09:59:24:128 - TRACE - Log4jESLogger - [Wreckage] channel opened: [id: 0xb8cf15ed, /10.11.66.27:48990 => /10.11.66.27:9301]
2015-05-12-09:59:24:128 - DEBUG - Log4jESLogger - [Wreckage] connected to node [[Wreckage][YxjMYjwtSGCG7kR5-TyYKg][inet[/10.11.66.27:9301]]]
2015-05-12-09:59:24:130 - DEBUG - Log4jESLogger - [Wreckage] Publishing cluster state version 1
2015-05-12-09:59:24:130 - DEBUG - Log4jESLogger - [Wreckage] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-09:59:24:132 - DEBUG - Log4jESLogger - [Wreckage] processing [reroute_rivers_node_changed]: execute
2015-05-12-09:59:24:134 - DEBUG - Log4jESLogger - [Wreckage] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-09:59:24:133 - TRACE - Log4jESLogger - [Wreckage] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-09:59:24:132 - TRACE - Log4jESLogger - [Wreckage] initial state set from discovery
2015-05-12-09:59:24:135 - INFO  - Log4jESLogger - [Wreckage] kodcu/YxjMYjwtSGCG7kR5-TyYKg
2015-05-12-09:59:24:135 - TRACE - Log4jESLogger - [Wreckage] performing state recovery...
2015-05-12-09:59:24:132 - DEBUG - Log4jESLogger - [Wreckage] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-09:59:24:136 - TRACE - Log4jESLogger - [Wreckage] performing state recovery from [YxjMYjwtSGCG7kR5-TyYKg]
2015-05-12-09:59:24:137 - TRACE - Log4jESLogger - [Wreckage] successful state recovery, importing cluster state...
2015-05-12-09:59:24:138 - DEBUG - Log4jESLogger - [Wreckage] processing [local-gateway-elected-state]: execute
2015-05-12-09:59:24:140 - DEBUG - Log4jESLogger - [Wreckage] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-09:59:24:141 - DEBUG - Log4jESLogger - [Wreckage] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-09:59:24:142 - DEBUG - Log4jESLogger - [Wreckage] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Wreckage][YxjMYjwtSGCG7kR5-TyYKg][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-09:59:24:143 - DEBUG - Log4jESLogger - [Wreckage] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-09:59:24:144 - DEBUG - Log4jESLogger - [Wreckage] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Wreckage][YxjMYjwtSGCG7kR5-TyYKg][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-09:59:24:144 - TRACE - Log4jESLogger - [Wreckage] Start balancing cluster
2015-05-12-09:59:24:145 - TRACE - Log4jESLogger - [Wreckage] Start distributing Shards
2015-05-12-09:59:24:145 - TRACE - Log4jESLogger - [Wreckage] Assigned shard [[mimos][0], node[YxjMYjwtSGCG7kR5-TyYKg], [P], s[INITIALIZING]] to node [YxjMYjwtSGCG7kR5-TyYKg]
2015-05-12-09:59:24:145 - TRACE - Log4jESLogger - [Wreckage] Assigned shard [[mimos][2], node[YxjMYjwtSGCG7kR5-TyYKg], [P], s[INITIALIZING]] to node [YxjMYjwtSGCG7kR5-TyYKg]
2015-05-12-09:59:24:145 - TRACE - Log4jESLogger - [Wreckage] Start allocating unassigned shards
2015-05-12-09:59:24:145 - TRACE - Log4jESLogger - [Wreckage] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:24:146 - TRACE - Log4jESLogger - [Wreckage] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:24:146 - TRACE - Log4jESLogger - [Wreckage] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:24:146 - TRACE - Log4jESLogger - [Wreckage] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:24:146 - TRACE - Log4jESLogger - [Wreckage] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-09:59:24:146 - TRACE - Log4jESLogger - [Wreckage] Start balancing cluster
2015-05-12-09:59:24:146 - TRACE - Log4jESLogger - [Wreckage] Start distributing Shards
2015-05-12-09:59:24:147 - TRACE - Log4jESLogger - [Wreckage] Assigned shard [[mimos][0], node[YxjMYjwtSGCG7kR5-TyYKg], [P], s[INITIALIZING]] to node [YxjMYjwtSGCG7kR5-TyYKg]
2015-05-12-09:59:24:147 - TRACE - Log4jESLogger - [Wreckage] Assigned shard [[mimos][2], node[YxjMYjwtSGCG7kR5-TyYKg], [P], s[INITIALIZING]] to node [YxjMYjwtSGCG7kR5-TyYKg]
2015-05-12-09:59:24:147 - TRACE - Log4jESLogger - [Wreckage] Start allocating unassigned shards
2015-05-12-09:59:24:148 - TRACE - Log4jESLogger - [Wreckage] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Wreckage][YxjMYjwtSGCG7kR5-TyYKg][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[YxjMYjwtSGCG7kR5-TyYKg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[YxjMYjwtSGCG7kR5-TyYKg], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[YxjMYjwtSGCG7kR5-TyYKg][V]
--------[mimos][0], node[YxjMYjwtSGCG7kR5-TyYKg], [P], s[INITIALIZING]
--------[mimos][2], node[YxjMYjwtSGCG7kR5-TyYKg], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-09:59:24:148 - DEBUG - Log4jESLogger - [Wreckage] Publishing cluster state version 2
2015-05-12-09:59:24:148 - DEBUG - Log4jESLogger - [Wreckage] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-09:59:24:156 - DEBUG - Log4jESLogger - [Wreckage] processing [reroute_rivers_node_changed]: execute
2015-05-12-09:59:24:158 - DEBUG - Log4jESLogger - [Wreckage] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-09:59:24:156 - DEBUG - Log4jESLogger - [Wreckage] [mimos] creating index
2015-05-12-09:59:24:160 - DEBUG - Log4jESLogger - [Wreckage] creating Index [mimos], shards [5]/[1]
2015-05-12-09:59:24:162 - INFO  - Log4jESLogger - [Wreckage] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-09:59:24:162 - INFO  - Log4jESLogger - [Wreckage] started
2015-05-12-09:59:24:162 - INFO  - Log4jESLogger - [Wreckage] stopping ...
2015-05-12-09:59:24:199 - DEBUG - Log4jESLogger - [Wreckage] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-09:59:24:200 - DEBUG - Log4jESLogger - [Wreckage] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-09:59:24:202 - DEBUG - Log4jESLogger - [Wreckage] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-09:59:24:203 - DEBUG - Log4jESLogger - [Wreckage] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"author":{"type":"string"},"content":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-09:59:24:205 - DEBUG - Log4jESLogger - [Wreckage] Sending mapping created for index mimos, type Programmer
2015-05-12-09:59:24:207 - DEBUG - Log4jESLogger - [Wreckage] [mimos] cleaning index (no shards allocated)
2015-05-12-09:59:24:207 - DEBUG - Log4jESLogger - [Wreckage] [mimos] full cache clear, reason [close]
2015-05-12-09:59:24:208 - TRACE - Log4jESLogger - [Wreckage] [_global] writing state, reason [changed]
2015-05-12-09:59:24:266 - INFO  - Log4jESLogger - [Wreckage] recovered [1] indices into cluster_state
2015-05-12-09:59:24:266 - DEBUG - Log4jESLogger - [Wreckage] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-09:59:24:278 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0x56cca24c, /10.11.66.27:48981 => /10.11.66.27:9301]
2015-05-12-09:59:24:282 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0x2d2b622c, /10.11.66.27:48982 => /10.11.66.27:9301]
2015-05-12-09:59:24:287 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0x7ca02f0b, /10.11.66.27:48985 => /10.11.66.27:9301]
2015-05-12-09:59:24:288 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0xac3587c3, /10.11.66.27:48984 => /10.11.66.27:9301]
2015-05-12-09:59:24:287 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0x39f6c153, /10.11.66.27:48983 => /10.11.66.27:9301]
2015-05-12-09:59:24:290 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0x184e2b78, /10.11.66.27:48986 => /10.11.66.27:9301]
2015-05-12-09:59:24:287 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0x8f2098cd, /10.11.66.27:48987 => /10.11.66.27:9301]
2015-05-12-09:59:24:296 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0x7b1e6777, /10.11.66.27:48988 => /10.11.66.27:9301]
2015-05-12-09:59:24:298 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0x7342f568, /10.11.66.27:48989 => /10.11.66.27:9301]
2015-05-12-09:59:24:298 - TRACE - Log4jESLogger - [Wreckage] channel closed: [id: 0xb8cf15ed, /10.11.66.27:48990 => /10.11.66.27:9301]
2015-05-12-09:59:24:304 - INFO  - Log4jESLogger - [Wreckage] stopped
2015-05-12-09:59:24:304 - INFO  - Log4jESLogger - [Wreckage] closing ...
2015-05-12-09:59:24:334 - TRACE - Log4jESLogger - [Wreckage] Close times for each service:
StopWatch 'node_close': running time  = 23ms
-----------------------------------------
ms     %     Task name
-----------------------------------------
00000  000%  bulk.udp
00000  000%  http
00000  000%  rivers
00000  000%  client
00000  000%  indices_cluster
00000  000%  indices
00000  000%  routing
00000  000%  cluster
00000  000%  discovery
00000  000%  monitor
00000  000%  gateway
00000  000%  search
00000  000%  rest
00000  000%  transport
00022  096%  node_cache
00000  000%  script
00001  004%  thread_pool
00000  000%  thread_pool_force_shutdown

2015-05-12-09:59:24:334 - TRACE - Log4jESLogger - [Wreckage] releasing lock [NativeFSLock@/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0/node.lock]
2015-05-12-09:59:24:336 - INFO  - Log4jESLogger - [Wreckage] closed
2015-05-12-10:05:45:328 - INFO  - Log4jESLogger - [Iron Man 2020] version[0.90.5], pid[5938], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-10:05:45:331 - INFO  - Log4jESLogger - [Iron Man 2020] initializing ...
2015-05-12-10:05:45:332 - DEBUG - Log4jESLogger - [Iron Man 2020] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-10:05:45:342 - INFO  - Log4jESLogger - [Iron Man 2020] loaded [], sites []
2015-05-12-10:05:45:367 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-10:05:45:371 - TRACE - Log4jESLogger - [Iron Man 2020] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-10:05:45:378 - DEBUG - Log4jESLogger - [Iron Man 2020] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-10:05:45:383 - TRACE - Log4jESLogger - [Iron Man 2020] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-10:05:45:960 - TRACE - Log4jESLogger - [Iron Man 2020] sigar loaded successfully
2015-05-12-10:05:46:635 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-10:05:46:642 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-10:05:46:646 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-10:05:46:647 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-10:05:46:649 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-10:05:46:651 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-10:05:46:664 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-10:05:46:667 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-10:05:46:669 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:46:670 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:46:670 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:46:671 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:46:671 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:46:671 - DEBUG - Log4jESLogger - [Iron Man 2020] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-10:05:46:690 - DEBUG - Log4jESLogger - [Iron Man 2020] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-10:05:46:702 - DEBUG - Log4jESLogger - [Iron Man 2020] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-10:05:46:709 - DEBUG - Log4jESLogger - [Iron Man 2020] using initial hosts [], with concurrent_connects [10]
2015-05-12-10:05:46:713 - DEBUG - Log4jESLogger - [Iron Man 2020] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-10:05:46:716 - DEBUG - Log4jESLogger - [Iron Man 2020] using minimum_master_nodes [-1]
2015-05-12-10:05:46:719 - DEBUG - Log4jESLogger - [Iron Man 2020] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:05:46:727 - DEBUG - Log4jESLogger - [Iron Man 2020] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:05:46:787 - DEBUG - Log4jESLogger - [Iron Man 2020] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-10:05:47:299 - DEBUG - Log4jESLogger - [Iron Man 2020] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-10:05:47:305 - DEBUG - Log4jESLogger - [Iron Man 2020] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-10:05:47:313 - DEBUG - Log4jESLogger - [Iron Man 2020] Using refresh_interval [1s]
2015-05-12-10:05:47:314 - DEBUG - Log4jESLogger - [Iron Man 2020] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-10:05:47:320 - DEBUG - Log4jESLogger - [Iron Man 2020] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-10:05:47:323 - TRACE - Log4jESLogger - [Iron Man 2020] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:11891 errors:0 dropped:0 overruns:0 frame:0
	TX packets:11891 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:4570306 (4.4M)  TX bytes:4570306 (4.4M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:226144 errors:0 dropped:0 overruns:0 frame:0
	TX packets:120199 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:261060784 (249M)  TX bytes:12985886 ( 12M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:228 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:227 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-10:05:47:331 - DEBUG - Log4jESLogger - [Iron Man 2020] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-10:05:47:609 - DEBUG - Log4jESLogger - [Iron Man 2020] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-10:05:47:618 - DEBUG - Log4jESLogger - [Iron Man 2020] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-10:05:47:627 - DEBUG - Log4jESLogger - [Iron Man 2020] using script cache with max_size [500], expire [null]
2015-05-12-10:05:47:635 - DEBUG - Log4jESLogger - [Iron Man 2020] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:05:47:638 - DEBUG - Log4jESLogger - [Iron Man 2020] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:05:47:638 - DEBUG - Log4jESLogger - [Iron Man 2020] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:05:47:644 - DEBUG - Log4jESLogger - [Iron Man 2020] using initial_shards [quorum], list_timeout [30s]
2015-05-12-10:05:47:738 - DEBUG - Log4jESLogger - [Iron Man 2020] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-10:05:47:844 - DEBUG - Log4jESLogger - [Iron Man 2020] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-10:05:47:852 - DEBUG - Log4jESLogger - [Iron Man 2020] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-10:05:47:854 - DEBUG - Log4jESLogger - [Iron Man 2020] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-10:05:47:857 - DEBUG - Log4jESLogger - [Iron Man 2020] using size [-1] [-1b], expire [null]
2015-05-12-10:05:47:879 - DEBUG - Log4jESLogger - [Iron Man 2020] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-10:05:47:885 - TRACE - Log4jESLogger - [Iron Man 2020] [upgrade]: processing [global-22]
2015-05-12-10:05:48:006 - DEBUG - Log4jESLogger - [Iron Man 2020] took 120ms to load state
2015-05-12-10:05:48:007 - TRACE - Log4jESLogger - [Iron Man 2020] [find_latest_state]: processing [global-22]
2015-05-12-10:05:48:011 - DEBUG - Log4jESLogger - [Iron Man 2020] took 2ms to load started shards state
2015-05-12-10:05:48:015 - DEBUG - Log4jESLogger - [Iron Man 2020] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-10:05:48:020 - DEBUG - Log4jESLogger - [Iron Man 2020] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:05:48:020 - DEBUG - Log4jESLogger - [Iron Man 2020] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:05:48:021 - DEBUG - Log4jESLogger - [Iron Man 2020] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:05:48:021 - DEBUG - Log4jESLogger - [Iron Man 2020] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:05:48:022 - DEBUG - Log4jESLogger - [Iron Man 2020] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:05:48:022 - DEBUG - Log4jESLogger - [Iron Man 2020] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:05:48:027 - INFO  - Log4jESLogger - [Iron Man 2020] initialized
2015-05-12-10:05:48:028 - INFO  - Log4jESLogger - [Iron Man 2020] starting ...
2015-05-12-10:05:48:051 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-10:05:48:051 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-10:05:48:167 - DEBUG - Log4jESLogger - [Iron Man 2020] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-10:05:48:172 - INFO  - Log4jESLogger - [Iron Man 2020] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-10:05:48:197 - TRACE - Log4jESLogger - [Iron Man 2020] waiting for 30s for the initial state to be set by the discovery
2015-05-12-10:05:48:208 - TRACE - Log4jESLogger - [Iron Man 2020] [1] sending ping request
2015-05-12-10:05:49:711 - TRACE - Log4jESLogger - [Iron Man 2020] [1] sending ping request
2015-05-12-10:05:51:215 - TRACE - Log4jESLogger - [Iron Man 2020] full ping responses: {none}
2015-05-12-10:05:51:215 - DEBUG - Log4jESLogger - [Iron Man 2020] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-10:05:51:219 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-10:05:51:221 - TRACE - Log4jESLogger - [Iron Man 2020] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[ZTRAZYhTRBWQQ4yJyNTJIg][V]
---- unassigned

2015-05-12-10:05:51:222 - INFO  - Log4jESLogger - [Iron Man 2020] new_master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-12-10:05:51:239 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0xa592e098, /10.11.66.27:47675 => /10.11.66.27:9300]
2015-05-12-10:05:51:241 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0xe5497313, /10.11.66.27:47676 => /10.11.66.27:9300]
2015-05-12-10:05:51:242 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0x0372e77d, /10.11.66.27:47677 => /10.11.66.27:9300]
2015-05-12-10:05:51:248 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0x1217462d, /10.11.66.27:47678 => /10.11.66.27:9300]
2015-05-12-10:05:51:251 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0x39377f6b, /10.11.66.27:47679 => /10.11.66.27:9300]
2015-05-12-10:05:51:253 - DEBUG - Log4jESLogger - [Iron Man 2020] connected to node [[Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]]]
2015-05-12-10:05:51:255 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0x98447cd0, /10.11.66.27:47680 => /10.11.66.27:9300]
2015-05-12-10:05:51:256 - DEBUG - Log4jESLogger - [Iron Man 2020] Publishing cluster state version 1
2015-05-12-10:05:51:256 - DEBUG - Log4jESLogger - [Iron Man 2020] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-10:05:51:257 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0xbe8d33fe, /10.11.66.27:47681 => /10.11.66.27:9300]
2015-05-12-10:05:51:258 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0xccad4830, /10.11.66.27:47682 => /10.11.66.27:9300]
2015-05-12-10:05:51:259 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0x7a27a9e7, /10.11.66.27:47683 => /10.11.66.27:9300]
2015-05-12-10:05:51:259 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0xe5b2efb4, /10.11.66.27:47684 => /10.11.66.27:9300]
2015-05-12-10:05:51:259 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:05:51:260 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-10:05:51:260 - TRACE - Log4jESLogger - [Iron Man 2020] initial state set from discovery
2015-05-12-10:05:51:261 - INFO  - Log4jESLogger - [Iron Man 2020] peansData/ZTRAZYhTRBWQQ4yJyNTJIg
2015-05-12-10:05:51:262 - TRACE - Log4jESLogger - [Iron Man 2020] performing state recovery...
2015-05-12-10:05:51:262 - TRACE - Log4jESLogger - [Iron Man 2020] performing state recovery from [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:260 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:05:51:267 - TRACE - Log4jESLogger - [Iron Man 2020] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-10:05:51:273 - TRACE - Log4jESLogger - [Iron Man 2020] successful state recovery, importing cluster state...
2015-05-12-10:05:51:275 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [local-gateway-elected-state]: execute
2015-05-12-10:05:51:285 - INFO  - Log4jESLogger - [Iron Man 2020] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-12-10:05:51:286 - INFO  - Log4jESLogger - [Iron Man 2020] started
2015-05-12-10:05:51:291 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-10:05:51:292 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-10:05:51:293 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-10:05:51:294 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-10:05:51:295 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2]: throttling allocation [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[[Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-12-10:05:51:298 - TRACE - Log4jESLogger - [Iron Man 2020] Start balancing cluster
2015-05-12-10:05:51:300 - TRACE - Log4jESLogger - [Iron Man 2020] Start distributing Shards
2015-05-12-10:05:51:301 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:302 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:302 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:302 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:302 - TRACE - Log4jESLogger - [Iron Man 2020] Start allocating unassigned shards
2015-05-12-10:05:51:304 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:51:304 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:51:305 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:51:306 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:51:307 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:51:308 - TRACE - Log4jESLogger - [Iron Man 2020] Start balancing cluster
2015-05-12-10:05:51:308 - TRACE - Log4jESLogger - [Iron Man 2020] Start distributing Shards
2015-05-12-10:05:51:309 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:309 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:309 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:309 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:51:310 - TRACE - Log4jESLogger - [Iron Man 2020] Start allocating unassigned shards
2015-05-12-10:05:51:312 - TRACE - Log4jESLogger - [Iron Man 2020] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[null], [P], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[ZTRAZYhTRBWQQ4yJyNTJIg][V]
--------[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [P], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:05:51:313 - DEBUG - Log4jESLogger - [Iron Man 2020] Publishing cluster state version 2
2015-05-12-10:05:51:313 - DEBUG - Log4jESLogger - [Iron Man 2020] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-10:05:51:314 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:05:51:319 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:05:51:324 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] creating index
2015-05-12-10:05:51:324 - DEBUG - Log4jESLogger - [Iron Man 2020] creating Index [mimos], shards [5]/[1]
2015-05-12-10:05:51:699 - TRACE - Log4jESLogger - [Iron Man 2020] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [null], scheduling a retry.
2015-05-12-10:05:51:727 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-10:05:51:730 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-10:05:51:743 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-10:05:51:821 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-10:05:51:901 - DEBUG - Log4jESLogger - [Iron Man 2020] Sending mapping created for index mimos, type Programmer
2015-05-12-10:05:51:910 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] creating shard
2015-05-12-10:05:51:910 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] creating shard_id [0]
2015-05-12-10:05:52:065 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-10:05:52:069 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:05:52:070 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:05:52:075 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] state: [CREATED]
2015-05-12-10:05:52:076 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:05:52:082 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:05:52:084 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] creating shard
2015-05-12-10:05:52:084 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] creating shard_id [1]
2015-05-12-10:05:52:084 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] starting recovery from local ...
2015-05-12-10:05:52:093 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-10:05:52:094 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:05:52:095 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:05:52:096 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] state: [CREATED]
2015-05-12-10:05:52:097 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:05:52:098 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:05:52:098 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] starting recovery from local ...
2015-05-12-10:05:52:103 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-10:05:52:104 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] starting engine
2015-05-12-10:05:52:112 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] creating shard
2015-05-12-10:05:52:112 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] creating shard_id [3]
2015-05-12-10:05:52:113 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-10:05:52:125 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] starting engine
2015-05-12-10:05:52:153 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-10:05:52:154 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:05:52:155 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:05:52:157 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] state: [CREATED]
2015-05-12-10:05:52:180 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:05:52:182 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:05:52:183 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] creating shard
2015-05-12-10:05:52:183 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] creating shard_id [4]
2015-05-12-10:05:52:195 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] starting recovery from local ...
2015-05-12-10:05:52:196 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-10:05:52:196 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] starting engine
2015-05-12-10:05:52:199 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-10:05:52:200 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:05:52:201 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:05:52:206 - TRACE - Log4jESLogger - [Iron Man 2020] channel opened: [id: 0x9a99bb80, /127.0.0.1:37343 => /127.0.0.1:9200]
2015-05-12-10:05:52:214 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] state: [CREATED]
2015-05-12-10:05:52:214 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:05:52:226 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:05:52:244 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] starting recovery from local ...
2015-05-12-10:05:52:249 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-10:05:52:250 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] starting engine
2015-05-12-10:05:52:264 - TRACE - Log4jESLogger - [Iron Man 2020] [_global] writing state, reason [changed]
2015-05-12-10:05:52:324 - INFO  - Log4jESLogger - [Iron Man 2020] recovered [1] indices into cluster_state
2015-05-12-10:05:52:325 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-10:05:52:336 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:05:52:338 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:05:52:341 - TRACE - Log4jESLogger - [Iron Man 2020] listener to cluster state added, trying to index again
2015-05-12-10:05:52:338 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:05:52:337 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:05:52:341 - TRACE - Log4jESLogger - [Iron Man 2020] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [null], scheduling a retry.
2015-05-12-10:05:52:343 - TRACE - Log4jESLogger - [Iron Man 2020] retry scheduling ignored as it as we already have a listener in place
2015-05-12-10:05:52:350 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][1] warming took [7.9ms]
2015-05-12-10:05:52:352 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:05:52:353 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][0] warming took [9.8ms]
2015-05-12-10:05:52:358 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][4] warming took [13.7ms]
2015-05-12-10:05:52:357 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][3] warming took [16.9ms]
2015-05-12-10:05:52:360 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:05:52:361 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] scheduling refresher every 1s
2015-05-12-10:05:52:361 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-10:05:52:362 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][1] refresh with force[true]
2015-05-12-10:05:52:362 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] scheduling refresher every 1s
2015-05-12-10:05:52:358 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:05:52:364 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] scheduling refresher every 1s
2015-05-12-10:05:52:365 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-10:05:52:365 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][0] refresh with force[true]
2015-05-12-10:05:52:365 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][0] recovery completed from [local], took [281ms]
2015-05-12-10:05:52:365 - DEBUG - Log4jESLogger - [Iron Man 2020] sending shard started for [mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:364 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-10:05:52:366 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][4] refresh with force[true]
2015-05-12-10:05:52:367 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][4] recovery completed from [local], took [123ms]
2015-05-12-10:05:52:367 - DEBUG - Log4jESLogger - [Iron Man 2020] sending shard started for [mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:367 - DEBUG - Log4jESLogger - [Iron Man 2020] received shard started for [mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:362 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][1] recovery completed from [local], took [264ms]
2015-05-12-10:05:52:360 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:05:52:369 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] scheduling refresher every 1s
2015-05-12-10:05:52:369 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-10:05:52:369 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][3] refresh with force[true]
2015-05-12-10:05:52:369 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][3] recovery completed from [local], took [174ms]
2015-05-12-10:05:52:369 - DEBUG - Log4jESLogger - [Iron Man 2020] sending shard started for [mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:370 - DEBUG - Log4jESLogger - [Iron Man 2020] received shard started for [mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:370 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:05:52:370 - DEBUG - Log4jESLogger - [Iron Man 2020] applying started shards [[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], [mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-10:05:52:371 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-10:05:52:371 - TRACE - Log4jESLogger - [Iron Man 2020] Start balancing cluster
2015-05-12-10:05:52:371 - TRACE - Log4jESLogger - [Iron Man 2020] Start distributing Shards
2015-05-12-10:05:52:371 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:372 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:372 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:372 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:372 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:372 - TRACE - Log4jESLogger - [Iron Man 2020] Start allocating unassigned shards
2015-05-12-10:05:52:373 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:373 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:373 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:374 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:374 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:375 - TRACE - Log4jESLogger - [Iron Man 2020] Start balancing cluster
2015-05-12-10:05:52:375 - TRACE - Log4jESLogger - [Iron Man 2020] Start distributing Shards
2015-05-12-10:05:52:376 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:376 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:376 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:376 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:377 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:377 - TRACE - Log4jESLogger - [Iron Man 2020] Start allocating unassigned shards
2015-05-12-10:05:52:368 - DEBUG - Log4jESLogger - [Iron Man 2020] sending shard started for [mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:366 - DEBUG - Log4jESLogger - [Iron Man 2020] received shard started for [mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:378 - DEBUG - Log4jESLogger - [Iron Man 2020] received shard started for [mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:379 - TRACE - Log4jESLogger - [Iron Man 2020] cluster state updated:
version [3], source [shard-started ([mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[ZTRAZYhTRBWQQ4yJyNTJIg][V]
--------[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]
--------[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:05:52:379 - DEBUG - Log4jESLogger - [Iron Man 2020] Publishing cluster state version 3
2015-05-12-10:05:52:380 - DEBUG - Log4jESLogger - [Iron Man 2020] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-10:05:52:380 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:05:52:391 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:05:52:391 - TRACE - Log4jESLogger - [Iron Man 2020] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-10:05:52:393 - DEBUG - Log4jESLogger - [Iron Man 2020] sending shard started for [mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:05:52:393 - DEBUG - Log4jESLogger - [Iron Man 2020] received shard started for [mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:05:52:395 - TRACE - Log4jESLogger - [Iron Man 2020] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-10:05:52:395 - DEBUG - Log4jESLogger - [Iron Man 2020] sending shard started for [mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:05:52:395 - DEBUG - Log4jESLogger - [Iron Man 2020] received shard started for [mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:05:52:395 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] creating shard
2015-05-12-10:05:52:395 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos] creating shard_id [2]
2015-05-12-10:05:52:408 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-10:05:52:409 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:05:52:411 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:05:52:412 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] state: [CREATED]
2015-05-12-10:05:52:413 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:05:52:414 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:05:52:414 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] starting recovery from local ...
2015-05-12-10:05:52:416 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-10:05:52:417 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] starting engine
2015-05-12-10:05:52:420 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:05:52:421 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] warming took [301.3micros]
2015-05-12-10:05:52:423 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:05:52:423 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] scheduling refresher every 1s
2015-05-12-10:05:52:424 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-10:05:52:425 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] refresh with force[true]
2015-05-12-10:05:52:425 - DEBUG - Log4jESLogger - [Iron Man 2020] [mimos][2] recovery completed from [local], took [11ms]
2015-05-12-10:05:52:426 - DEBUG - Log4jESLogger - [Iron Man 2020] sending shard started for [mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:429 - DEBUG - Log4jESLogger - [Iron Man 2020] received shard started for [mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:05:52:431 - TRACE - Log4jESLogger - [Iron Man 2020] cluster changed (version 3), trying to index again
2015-05-12-10:05:52:432 - TRACE - Log4jESLogger - [Iron Man 2020] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [ZTRAZYhTRBWQQ4yJyNTJIg], scheduling a retry.
2015-05-12-10:05:52:432 - TRACE - Log4jESLogger - [Iron Man 2020] retry scheduling ignored as it as we already have a listener in place
2015-05-12-10:05:52:434 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][4] writing shard state, reason [version changed from [40] to [42]]
2015-05-12-10:05:52:505 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][3] writing shard state, reason [version changed from [38] to [40]]
2015-05-12-10:05:52:556 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-10:05:52:556 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:05:52:556 - DEBUG - Log4jESLogger - [Iron Man 2020] applying started shards [[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], [mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], [mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], [mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING], [mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-10:05:52:557 - TRACE - Log4jESLogger - [Iron Man 2020] Start balancing cluster
2015-05-12-10:05:52:557 - TRACE - Log4jESLogger - [Iron Man 2020] Start distributing Shards
2015-05-12-10:05:52:557 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:557 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:558 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:558 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:558 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:558 - TRACE - Log4jESLogger - [Iron Man 2020] Start allocating unassigned shards
2015-05-12-10:05:52:558 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:559 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:559 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:559 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:559 - TRACE - Log4jESLogger - [Iron Man 2020] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:52:560 - TRACE - Log4jESLogger - [Iron Man 2020] Start balancing cluster
2015-05-12-10:05:52:560 - TRACE - Log4jESLogger - [Iron Man 2020] Start distributing Shards
2015-05-12-10:05:52:561 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:561 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:561 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:561 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:561 - TRACE - Log4jESLogger - [Iron Man 2020] Assigned shard [[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]] to node [ZTRAZYhTRBWQQ4yJyNTJIg]
2015-05-12-10:05:52:562 - TRACE - Log4jESLogger - [Iron Man 2020] Start allocating unassigned shards
2015-05-12-10:05:52:563 - TRACE - Log4jESLogger - [Iron Man 2020] cluster state updated:
version [4], source [shard-started ([mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[ZTRAZYhTRBWQQ4yJyNTJIg][V]
--------[mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][3], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
--------[mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:05:52:563 - DEBUG - Log4jESLogger - [Iron Man 2020] Publishing cluster state version 4
2015-05-12-10:05:52:563 - DEBUG - Log4jESLogger - [Iron Man 2020] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-10:05:52:564 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:05:52:564 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:05:52:566 - TRACE - Log4jESLogger - [Iron Man 2020] cluster changed (version 4), trying to index again
2015-05-12-10:05:52:569 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][0] writing shard state, reason [version changed from [38] to [40]]
2015-05-12-10:05:52:589 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-10:05:52:622 - DEBUG - Log4jESLogger - [Iron Man 2020] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-10:05:52:623 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] writing shard state, reason [version changed from [28] to [30]]
2015-05-12-10:05:52:632 - INFO  - Log4jESLogger - [Grey-Summers, Jean] version[0.90.5], pid[5938], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-10:05:52:633 - INFO  - Log4jESLogger - [Grey-Summers, Jean] initializing ...
2015-05-12-10:05:52:633 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-10:05:52:634 - INFO  - Log4jESLogger - [Grey-Summers, Jean] loaded [], sites []
2015-05-12-10:05:52:634 - TRACE - Log4jESLogger - [Grey-Summers, Jean] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-10:05:52:635 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-10:05:52:635 - TRACE - Log4jESLogger - [Grey-Summers, Jean] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-10:05:52:657 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][1] writing shard state, reason [version changed from [24] to [26]]
2015-05-12-10:05:52:689 - TRACE - Log4jESLogger - [Grey-Summers, Jean] sigar loaded successfully
2015-05-12-10:05:52:691 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][4], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-10:05:52:692 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:05:52:692 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:05:52:692 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:05:52:692 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:05:52:692 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-10:05:52:692 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][0], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-10:05:52:692 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-10:05:52:693 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][1], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [master [Iron Man 2020][ZTRAZYhTRBWQQ4yJyNTJIg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-10:05:52:693 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:05:52:693 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [shard-started ([mimos][2], node[ZTRAZYhTRBWQQ4yJyNTJIg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:05:52:693 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-10:05:52:696 - DEBUG - Log4jESLogger - [Iron Man 2020] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-10:05:52:753 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-10:05:52:753 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-10:05:52:754 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-10:05:52:754 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-10:05:52:754 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-10:05:52:755 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-10:05:52:755 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-10:05:52:755 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-10:05:52:756 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:52:756 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:52:757 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:52:757 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:52:757 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:05:52:758 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-10:05:52:761 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-10:05:52:762 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-10:05:52:763 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using initial hosts [], with concurrent_connects [10]
2015-05-12-10:05:52:764 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-10:05:52:764 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using minimum_master_nodes [-1]
2015-05-12-10:05:52:765 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:05:52:765 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:05:52:773 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-10:05:53:275 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@3c69362a] with refresh_interval [1s]
2015-05-12-10:05:53:276 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@29138d3a] with refresh_interval [1s]
2015-05-12-10:05:53:278 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Using refresh_interval [1s]
2015-05-12-10:05:53:278 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@17d32e9b] with refresh_interval [5s]
2015-05-12-10:05:53:280 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-10:05:53:281 - TRACE - Log4jESLogger - [Grey-Summers, Jean] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:11948 errors:0 dropped:0 overruns:0 frame:0
	TX packets:11948 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:4574120 (4.4M)  TX bytes:4574120 (4.4M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:226199 errors:0 dropped:0 overruns:0 frame:0
	TX packets:120226 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:261066660 (249M)  TX bytes:12990992 ( 12M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:229 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:228 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-10:05:53:282 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@1e86a5a7] with refresh_interval [1s]
2015-05-12-10:05:53:284 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-10:05:53:284 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-10:05:53:286 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using script cache with max_size [500], expire [null]
2015-05-12-10:05:53:287 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:05:53:287 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:05:53:288 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:05:53:288 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using initial_shards [quorum], list_timeout [30s]
2015-05-12-10:05:53:297 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-10:05:53:305 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-10:05:53:306 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-10:05:53:307 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-10:05:53:308 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using size [-1] [-1b], expire [null]
2015-05-12-10:05:53:310 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-10:05:53:311 - TRACE - Log4jESLogger - [Grey-Summers, Jean] [upgrade]: processing [global-13]
2015-05-12-10:05:53:313 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] took 2ms to load state
2015-05-12-10:05:53:313 - TRACE - Log4jESLogger - [Grey-Summers, Jean] [find_latest_state]: processing [global-13]
2015-05-12-10:05:53:317 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] took 3ms to load started shards state
2015-05-12-10:05:53:318 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-10:05:53:320 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:05:53:321 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:05:53:321 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:05:53:321 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:05:53:322 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:05:53:322 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:05:53:514 - INFO  - Log4jESLogger - [Grey-Summers, Jean] initialized
2015-05-12-10:05:53:514 - INFO  - Log4jESLogger - [Grey-Summers, Jean] starting ...
2015-05-12-10:05:53:516 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] refresh with force[false]
2015-05-12-10:05:53:567 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-10:05:53:573 - INFO  - Log4jESLogger - [Grey-Summers, Jean] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-10:05:53:574 - TRACE - Log4jESLogger - [Grey-Summers, Jean] waiting for 30s for the initial state to be set by the discovery
2015-05-12-10:05:53:577 - TRACE - Log4jESLogger - [Iron Man 2020] [1] received ping_request from [[Grey-Summers, Jean][U1T9aXP-RsGP13vR5D1gJg][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-10:05:53:577 - TRACE - Log4jESLogger - [Grey-Summers, Jean] [1] sending ping request
2015-05-12-10:05:53:628 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] warming [StandardDirectoryReader(segments_1:3:nrt _0(4.4):c1)], new [MultiReader(_0(4.4):c1)]
2015-05-12-10:05:53:628 - TRACE - Log4jESLogger - [Iron Man 2020] [mimos][2] warming took [117.1micros]
2015-05-12-10:05:55:078 - TRACE - Log4jESLogger - [Grey-Summers, Jean] [1] sending ping request
2015-05-12-10:05:55:079 - TRACE - Log4jESLogger - [Iron Man 2020] [1] received ping_request from [[Grey-Summers, Jean][U1T9aXP-RsGP13vR5D1gJg][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-10:05:56:579 - TRACE - Log4jESLogger - [Grey-Summers, Jean] full ping responses: {none}
2015-05-12-10:05:56:579 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-10:05:56:580 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-10:05:56:580 - TRACE - Log4jESLogger - [Grey-Summers, Jean] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Grey-Summers, Jean][U1T9aXP-RsGP13vR5D1gJg][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[U1T9aXP-RsGP13vR5D1gJg][V]
---- unassigned

2015-05-12-10:05:56:580 - INFO  - Log4jESLogger - [Grey-Summers, Jean] new_master [Grey-Summers, Jean][U1T9aXP-RsGP13vR5D1gJg][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-10:05:56:581 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0x1fa22da3, /10.11.66.27:49151 => /10.11.66.27:9301]
2015-05-12-10:05:56:582 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0x87b4f078, /10.11.66.27:49152 => /10.11.66.27:9301]
2015-05-12-10:05:56:582 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0xa9d2cf7f, /10.11.66.27:49153 => /10.11.66.27:9301]
2015-05-12-10:05:56:588 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0x8ea7529b, /10.11.66.27:49154 => /10.11.66.27:9301]
2015-05-12-10:05:56:588 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0xd7f142c6, /10.11.66.27:49155 => /10.11.66.27:9301]
2015-05-12-10:05:56:589 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0x12e37c65, /10.11.66.27:49156 => /10.11.66.27:9301]
2015-05-12-10:05:56:590 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0xd1d36bc2, /10.11.66.27:49157 => /10.11.66.27:9301]
2015-05-12-10:05:56:590 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0x36c0fcf5, /10.11.66.27:49158 => /10.11.66.27:9301]
2015-05-12-10:05:56:591 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0xc2090411, /10.11.66.27:49159 => /10.11.66.27:9301]
2015-05-12-10:05:56:591 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel opened: [id: 0xdb7e7761, /10.11.66.27:49160 => /10.11.66.27:9301]
2015-05-12-10:05:56:593 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] connected to node [[Grey-Summers, Jean][U1T9aXP-RsGP13vR5D1gJg][inet[/10.11.66.27:9301]]]
2015-05-12-10:05:56:593 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Publishing cluster state version 1
2015-05-12-10:05:56:594 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-10:05:56:594 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:05:56:594 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:05:56:596 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-10:05:56:596 - TRACE - Log4jESLogger - [Grey-Summers, Jean] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-10:05:56:596 - TRACE - Log4jESLogger - [Grey-Summers, Jean] initial state set from discovery
2015-05-12-10:05:56:597 - INFO  - Log4jESLogger - [Grey-Summers, Jean] kodcu/U1T9aXP-RsGP13vR5D1gJg
2015-05-12-10:05:56:598 - TRACE - Log4jESLogger - [Grey-Summers, Jean] performing state recovery...
2015-05-12-10:05:56:598 - TRACE - Log4jESLogger - [Grey-Summers, Jean] performing state recovery from [U1T9aXP-RsGP13vR5D1gJg]
2015-05-12-10:05:56:599 - TRACE - Log4jESLogger - [Grey-Summers, Jean] successful state recovery, importing cluster state...
2015-05-12-10:05:56:602 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] processing [local-gateway-elected-state]: execute
2015-05-12-10:05:56:607 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Grey-Summers, Jean][U1T9aXP-RsGP13vR5D1gJg][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:05:56:609 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:05:56:617 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:05:56:618 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Grey-Summers, Jean][U1T9aXP-RsGP13vR5D1gJg][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:05:56:619 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:05:56:619 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Start balancing cluster
2015-05-12-10:05:56:619 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Start distributing Shards
2015-05-12-10:05:56:619 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Assigned shard [[mimos][2], node[U1T9aXP-RsGP13vR5D1gJg], [P], s[INITIALIZING]] to node [U1T9aXP-RsGP13vR5D1gJg]
2015-05-12-10:05:56:620 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Assigned shard [[mimos][0], node[U1T9aXP-RsGP13vR5D1gJg], [P], s[INITIALIZING]] to node [U1T9aXP-RsGP13vR5D1gJg]
2015-05-12-10:05:56:620 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Start allocating unassigned shards
2015-05-12-10:05:56:620 - TRACE - Log4jESLogger - [Grey-Summers, Jean] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:56:620 - TRACE - Log4jESLogger - [Grey-Summers, Jean] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:56:621 - TRACE - Log4jESLogger - [Grey-Summers, Jean] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:56:621 - TRACE - Log4jESLogger - [Grey-Summers, Jean] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:56:621 - TRACE - Log4jESLogger - [Grey-Summers, Jean] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:05:56:622 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Start balancing cluster
2015-05-12-10:05:56:622 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Start distributing Shards
2015-05-12-10:05:56:622 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Assigned shard [[mimos][2], node[U1T9aXP-RsGP13vR5D1gJg], [P], s[INITIALIZING]] to node [U1T9aXP-RsGP13vR5D1gJg]
2015-05-12-10:05:56:622 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Assigned shard [[mimos][0], node[U1T9aXP-RsGP13vR5D1gJg], [P], s[INITIALIZING]] to node [U1T9aXP-RsGP13vR5D1gJg]
2015-05-12-10:05:56:622 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Start allocating unassigned shards
2015-05-12-10:05:56:625 - INFO  - Log4jESLogger - [Grey-Summers, Jean] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-10:05:56:625 - INFO  - Log4jESLogger - [Grey-Summers, Jean] started
2015-05-12-10:05:56:626 - INFO  - Log4jESLogger - [Grey-Summers, Jean] stopping ...
2015-05-12-10:05:56:640 - TRACE - Log4jESLogger - [Grey-Summers, Jean] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Grey-Summers, Jean][U1T9aXP-RsGP13vR5D1gJg][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[U1T9aXP-RsGP13vR5D1gJg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[U1T9aXP-RsGP13vR5D1gJg], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[U1T9aXP-RsGP13vR5D1gJg][V]
--------[mimos][0], node[U1T9aXP-RsGP13vR5D1gJg], [P], s[INITIALIZING]
--------[mimos][2], node[U1T9aXP-RsGP13vR5D1gJg], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:05:56:641 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Publishing cluster state version 2
2015-05-12-10:05:56:641 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-10:05:56:641 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos] creating index
2015-05-12-10:05:56:641 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:05:56:643 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:05:56:641 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] creating Index [mimos], shards [5]/[1]
2015-05-12-10:05:56:684 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-10:05:56:685 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-10:05:56:690 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-10:05:56:695 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"author":{"type":"string"},"content":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-10:05:56:706 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] Sending mapping created for index mimos, type Programmer
2015-05-12-10:05:56:707 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos] cleaning index (no shards allocated)
2015-05-12-10:05:56:707 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] [mimos] full cache clear, reason [close]
2015-05-12-10:05:56:708 - TRACE - Log4jESLogger - [Grey-Summers, Jean] [_global] writing state, reason [changed]
2015-05-12-10:05:56:766 - INFO  - Log4jESLogger - [Grey-Summers, Jean] recovered [1] indices into cluster_state
2015-05-12-10:05:56:767 - DEBUG - Log4jESLogger - [Grey-Summers, Jean] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-10:05:56:776 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0x1fa22da3, /10.11.66.27:49151 => /10.11.66.27:9301]
2015-05-12-10:05:56:777 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0xa9d2cf7f, /10.11.66.27:49153 => /10.11.66.27:9301]
2015-05-12-10:05:56:778 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0x87b4f078, /10.11.66.27:49152 => /10.11.66.27:9301]
2015-05-12-10:05:56:780 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0x8ea7529b, /10.11.66.27:49154 => /10.11.66.27:9301]
2015-05-12-10:05:56:782 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0xd7f142c6, /10.11.66.27:49155 => /10.11.66.27:9301]
2015-05-12-10:05:56:784 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0x12e37c65, /10.11.66.27:49156 => /10.11.66.27:9301]
2015-05-12-10:05:56:792 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0xd1d36bc2, /10.11.66.27:49157 => /10.11.66.27:9301]
2015-05-12-10:05:56:793 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0x36c0fcf5, /10.11.66.27:49158 => /10.11.66.27:9301]
2015-05-12-10:05:56:796 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0xc2090411, /10.11.66.27:49159 => /10.11.66.27:9301]
2015-05-12-10:05:56:797 - TRACE - Log4jESLogger - [Grey-Summers, Jean] channel closed: [id: 0xdb7e7761, /10.11.66.27:49160 => /10.11.66.27:9301]
2015-05-12-10:05:56:814 - INFO  - Log4jESLogger - [Grey-Summers, Jean] stopped
2015-05-12-10:05:56:815 - INFO  - Log4jESLogger - [Grey-Summers, Jean] closing ...
2015-05-12-10:05:56:821 - TRACE - Log4jESLogger - [Grey-Summers, Jean] Close times for each service:
StopWatch 'node_close': running time  = 2ms
-----------------------------------------
ms     %     Task name
-----------------------------------------
00000  000%  bulk.udp
00000  000%  http
00000  000%  rivers
00000  000%  client
00000  000%  indices_cluster
00000  000%  indices
00000  000%  routing
00000  000%  cluster
00000  000%  discovery
00001  050%  monitor
00000  000%  gateway
00000  000%  search
00000  000%  rest
00000  000%  transport
00000  000%  node_cache
00000  000%  script
00001  050%  thread_pool
00000  000%  thread_pool_force_shutdown

2015-05-12-10:05:56:822 - TRACE - Log4jESLogger - [Grey-Summers, Jean] releasing lock [NativeFSLock@/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0/node.lock]
2015-05-12-10:05:56:823 - INFO  - Log4jESLogger - [Grey-Summers, Jean] closed
2015-05-12-10:06:27:442 - INFO  - Log4jESLogger - [Ecstasy] version[0.90.5], pid[6140], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-10:06:27:445 - INFO  - Log4jESLogger - [Ecstasy] initializing ...
2015-05-12-10:06:27:445 - DEBUG - Log4jESLogger - [Ecstasy] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-10:06:27:454 - INFO  - Log4jESLogger - [Ecstasy] loaded [], sites []
2015-05-12-10:06:27:485 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-10:06:27:489 - TRACE - Log4jESLogger - [Ecstasy] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-10:06:27:497 - DEBUG - Log4jESLogger - [Ecstasy] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-10:06:27:503 - TRACE - Log4jESLogger - [Ecstasy] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-10:06:28:093 - TRACE - Log4jESLogger - [Ecstasy] sigar loaded successfully
2015-05-12-10:06:28:737 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-10:06:28:744 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:28:748 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:28:749 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:28:752 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-10:06:28:753 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-10:06:28:764 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-10:06:28:766 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-10:06:28:767 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:28:768 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:28:768 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:28:769 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:28:769 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:28:770 - DEBUG - Log4jESLogger - [Ecstasy] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-10:06:28:789 - DEBUG - Log4jESLogger - [Ecstasy] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-10:06:28:800 - DEBUG - Log4jESLogger - [Ecstasy] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-10:06:28:805 - DEBUG - Log4jESLogger - [Ecstasy] using initial hosts [], with concurrent_connects [10]
2015-05-12-10:06:28:807 - DEBUG - Log4jESLogger - [Ecstasy] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-10:06:28:809 - DEBUG - Log4jESLogger - [Ecstasy] using minimum_master_nodes [-1]
2015-05-12-10:06:28:811 - DEBUG - Log4jESLogger - [Ecstasy] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:06:28:817 - DEBUG - Log4jESLogger - [Ecstasy] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:06:28:857 - DEBUG - Log4jESLogger - [Ecstasy] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-10:06:29:369 - DEBUG - Log4jESLogger - [Ecstasy] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-10:06:29:375 - DEBUG - Log4jESLogger - [Ecstasy] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-10:06:29:399 - DEBUG - Log4jESLogger - [Ecstasy] Using refresh_interval [1s]
2015-05-12-10:06:29:400 - DEBUG - Log4jESLogger - [Ecstasy] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-10:06:29:411 - DEBUG - Log4jESLogger - [Ecstasy] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-10:06:29:415 - TRACE - Log4jESLogger - [Ecstasy] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:12200 errors:0 dropped:0 overruns:0 frame:0
	TX packets:12200 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:4629402 (4.4M)  TX bytes:4629402 (4.4M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:227176 errors:0 dropped:0 overruns:0 frame:0
	TX packets:120643 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:262150566 (250M)  TX bytes:13031793 ( 12M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:236 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:235 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-10:06:29:427 - DEBUG - Log4jESLogger - [Ecstasy] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-10:06:29:886 - DEBUG - Log4jESLogger - [Ecstasy] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-10:06:29:898 - DEBUG - Log4jESLogger - [Ecstasy] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-10:06:29:943 - DEBUG - Log4jESLogger - [Ecstasy] using script cache with max_size [500], expire [null]
2015-05-12-10:06:29:957 - DEBUG - Log4jESLogger - [Ecstasy] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:29:977 - DEBUG - Log4jESLogger - [Ecstasy] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:29:980 - DEBUG - Log4jESLogger - [Ecstasy] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:29:993 - DEBUG - Log4jESLogger - [Ecstasy] using initial_shards [quorum], list_timeout [30s]
2015-05-12-10:06:30:223 - DEBUG - Log4jESLogger - [Ecstasy] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-10:06:30:367 - DEBUG - Log4jESLogger - [Ecstasy] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-10:06:30:378 - DEBUG - Log4jESLogger - [Ecstasy] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-10:06:30:380 - DEBUG - Log4jESLogger - [Ecstasy] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-10:06:30:382 - DEBUG - Log4jESLogger - [Ecstasy] using size [-1] [-1b], expire [null]
2015-05-12-10:06:30:444 - DEBUG - Log4jESLogger - [Ecstasy] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-10:06:30:445 - TRACE - Log4jESLogger - [Ecstasy] [upgrade]: processing [global-23]
2015-05-12-10:06:30:625 - DEBUG - Log4jESLogger - [Ecstasy] took 179ms to load state
2015-05-12-10:06:30:626 - TRACE - Log4jESLogger - [Ecstasy] [find_latest_state]: processing [global-23]
2015-05-12-10:06:30:631 - DEBUG - Log4jESLogger - [Ecstasy] took 4ms to load started shards state
2015-05-12-10:06:30:635 - DEBUG - Log4jESLogger - [Ecstasy] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-10:06:30:645 - DEBUG - Log4jESLogger - [Ecstasy] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:30:646 - DEBUG - Log4jESLogger - [Ecstasy] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:30:647 - DEBUG - Log4jESLogger - [Ecstasy] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:30:648 - DEBUG - Log4jESLogger - [Ecstasy] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:30:649 - DEBUG - Log4jESLogger - [Ecstasy] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:30:649 - DEBUG - Log4jESLogger - [Ecstasy] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:30:656 - INFO  - Log4jESLogger - [Ecstasy] initialized
2015-05-12-10:06:30:656 - INFO  - Log4jESLogger - [Ecstasy] starting ...
2015-05-12-10:06:30:686 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-10:06:30:687 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-10:06:30:801 - DEBUG - Log4jESLogger - [Ecstasy] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-10:06:30:806 - INFO  - Log4jESLogger - [Ecstasy] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-10:06:30:828 - TRACE - Log4jESLogger - [Ecstasy] waiting for 30s for the initial state to be set by the discovery
2015-05-12-10:06:30:838 - TRACE - Log4jESLogger - [Ecstasy] [1] sending ping request
2015-05-12-10:06:32:341 - TRACE - Log4jESLogger - [Ecstasy] [1] sending ping request
2015-05-12-10:06:33:843 - TRACE - Log4jESLogger - [Ecstasy] full ping responses: {none}
2015-05-12-10:06:33:844 - DEBUG - Log4jESLogger - [Ecstasy] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-10:06:33:849 - DEBUG - Log4jESLogger - [Ecstasy] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-10:06:33:851 - TRACE - Log4jESLogger - [Ecstasy] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[cpWS9QRAR6iQLHKFfHDX3Q][V]
---- unassigned

2015-05-12-10:06:33:852 - INFO  - Log4jESLogger - [Ecstasy] new_master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-10:06:33:869 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x14171374, /10.11.66.27:49203 => /10.11.66.27:9301]
2015-05-12-10:06:33:873 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x10d1ae6c, /10.11.66.27:49204 => /10.11.66.27:9301]
2015-05-12-10:06:33:874 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x3b0ddc12, /10.11.66.27:49205 => /10.11.66.27:9301]
2015-05-12-10:06:33:874 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x43947781, /10.11.66.27:49206 => /10.11.66.27:9301]
2015-05-12-10:06:33:879 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0xee17f19f, /10.11.66.27:49207 => /10.11.66.27:9301]
2015-05-12-10:06:33:885 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x5a342ee3, /10.11.66.27:49208 => /10.11.66.27:9301]
2015-05-12-10:06:33:885 - DEBUG - Log4jESLogger - [Ecstasy] connected to node [[Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]]]
2015-05-12-10:06:33:887 - DEBUG - Log4jESLogger - [Ecstasy] Publishing cluster state version 1
2015-05-12-10:06:33:886 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x86a21298, /10.11.66.27:49209 => /10.11.66.27:9301]
2015-05-12-10:06:33:887 - DEBUG - Log4jESLogger - [Ecstasy] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-10:06:33:888 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x4f753823, /10.11.66.27:49210 => /10.11.66.27:9301]
2015-05-12-10:06:33:889 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x016428bc, /10.11.66.27:49211 => /10.11.66.27:9301]
2015-05-12-10:06:33:890 - TRACE - Log4jESLogger - [Ecstasy] channel opened: [id: 0x185a726c, /10.11.66.27:49212 => /10.11.66.27:9301]
2015-05-12-10:06:33:891 - DEBUG - Log4jESLogger - [Ecstasy] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:33:892 - DEBUG - Log4jESLogger - [Ecstasy] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:33:893 - TRACE - Log4jESLogger - [Ecstasy] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-10:06:33:893 - TRACE - Log4jESLogger - [Ecstasy] initial state set from discovery
2015-05-12-10:06:33:893 - DEBUG - Log4jESLogger - [Ecstasy] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-10:06:33:894 - INFO  - Log4jESLogger - [Ecstasy] peansData/cpWS9QRAR6iQLHKFfHDX3Q
2015-05-12-10:06:33:896 - TRACE - Log4jESLogger - [Ecstasy] performing state recovery...
2015-05-12-10:06:33:896 - TRACE - Log4jESLogger - [Ecstasy] performing state recovery from [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:915 - TRACE - Log4jESLogger - [Ecstasy] successful state recovery, importing cluster state...
2015-05-12-10:06:33:918 - DEBUG - Log4jESLogger - [Ecstasy] processing [local-gateway-elected-state]: execute
2015-05-12-10:06:33:941 - INFO  - Log4jESLogger - [Ecstasy] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-10:06:33:941 - INFO  - Log4jESLogger - [Ecstasy] started
2015-05-12-10:06:33:947 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:33:948 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:33:949 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:33:950 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:33:951 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0]: throttling allocation [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[[Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]]]] on primary allocation
2015-05-12-10:06:33:956 - TRACE - Log4jESLogger - [Ecstasy] Start balancing cluster
2015-05-12-10:06:33:960 - TRACE - Log4jESLogger - [Ecstasy] Start distributing Shards
2015-05-12-10:06:33:962 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:962 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:963 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:963 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:963 - TRACE - Log4jESLogger - [Ecstasy] Start allocating unassigned shards
2015-05-12-10:06:33:965 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:33:965 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:33:966 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:33:966 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:33:967 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:33:968 - TRACE - Log4jESLogger - [Ecstasy] Start balancing cluster
2015-05-12-10:06:33:976 - TRACE - Log4jESLogger - [Ecstasy] Start distributing Shards
2015-05-12-10:06:33:977 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:977 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:977 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:977 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:33:978 - TRACE - Log4jESLogger - [Ecstasy] Start allocating unassigned shards
2015-05-12-10:06:33:981 - TRACE - Log4jESLogger - [Ecstasy] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[null], [P], s[UNASSIGNED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[cpWS9QRAR6iQLHKFfHDX3Q][V]
--------[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [P], s[UNASSIGNED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:06:33:983 - DEBUG - Log4jESLogger - [Ecstasy] Publishing cluster state version 2
2015-05-12-10:06:33:983 - DEBUG - Log4jESLogger - [Ecstasy] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-10:06:33:984 - DEBUG - Log4jESLogger - [Ecstasy] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:33:992 - DEBUG - Log4jESLogger - [Ecstasy] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:33:994 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] creating index
2015-05-12-10:06:33:996 - DEBUG - Log4jESLogger - [Ecstasy] creating Index [mimos], shards [5]/[1]
2015-05-12-10:06:34:390 - TRACE - Log4jESLogger - [Ecstasy] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [cpWS9QRAR6iQLHKFfHDX3Q], scheduling a retry.
2015-05-12-10:06:34:405 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-10:06:34:406 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-10:06:34:422 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-10:06:34:484 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-10:06:34:583 - DEBUG - Log4jESLogger - [Ecstasy] Sending mapping created for index mimos, type Programmer
2015-05-12-10:06:34:586 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] creating shard
2015-05-12-10:06:34:587 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] creating shard_id [1]
2015-05-12-10:06:34:751 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-10:06:34:757 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:34:758 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:34:764 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] state: [CREATED]
2015-05-12-10:06:34:766 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:34:774 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:34:776 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] creating shard
2015-05-12-10:06:34:777 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] creating shard_id [2]
2015-05-12-10:06:34:776 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] starting recovery from local ...
2015-05-12-10:06:34:791 - TRACE - Log4jESLogger - [Ecstasy] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-10:06:34:793 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] starting engine
2015-05-12-10:06:34:807 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-10:06:34:809 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:34:810 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:34:811 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] state: [CREATED]
2015-05-12-10:06:34:812 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:34:815 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:34:815 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] creating shard
2015-05-12-10:06:34:815 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] creating shard_id [3]
2015-05-12-10:06:34:819 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] starting recovery from local ...
2015-05-12-10:06:34:829 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-10:06:34:837 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] starting engine
2015-05-12-10:06:34:847 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-10:06:34:851 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:34:854 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:34:857 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] state: [CREATED]
2015-05-12-10:06:34:859 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:34:861 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:34:864 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] starting recovery from local ...
2015-05-12-10:06:34:864 - TRACE - Log4jESLogger - [Ecstasy] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-10:06:34:865 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] starting engine
2015-05-12-10:06:34:864 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] creating shard
2015-05-12-10:06:34:877 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] creating shard_id [4]
2015-05-12-10:06:34:891 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-10:06:34:892 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:34:892 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:34:893 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] state: [CREATED]
2015-05-12-10:06:34:894 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:34:896 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:34:909 - TRACE - Log4jESLogger - [Ecstasy] [_global] writing state, reason [changed]
2015-05-12-10:06:34:921 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] starting recovery from local ...
2015-05-12-10:06:34:922 - TRACE - Log4jESLogger - [Ecstasy] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-10:06:34:922 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] starting engine
2015-05-12-10:06:34:956 - INFO  - Log4jESLogger - [Ecstasy] recovered [1] indices into cluster_state
2015-05-12-10:06:34:956 - DEBUG - Log4jESLogger - [Ecstasy] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-10:06:34:957 - TRACE - Log4jESLogger - [Ecstasy] listener to cluster state added, trying to index again
2015-05-12-10:06:34:958 - TRACE - Log4jESLogger - [Ecstasy] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [cpWS9QRAR6iQLHKFfHDX3Q], scheduling a retry.
2015-05-12-10:06:34:958 - TRACE - Log4jESLogger - [Ecstasy] retry scheduling ignored as it as we already have a listener in place
2015-05-12-10:06:34:983 - TRACE - Log4jESLogger - [Ecstasy] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:34:984 - TRACE - Log4jESLogger - [Ecstasy] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:34:987 - TRACE - Log4jESLogger - [Ecstasy] [mimos][4] warming took [3.6ms]
2015-05-12-10:06:34:992 - TRACE - Log4jESLogger - [Ecstasy] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:34:994 - TRACE - Log4jESLogger - [Ecstasy] [mimos][3] warming took [1.2ms]
2015-05-12-10:06:34:995 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:34:996 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] scheduling refresher every 1s
2015-05-12-10:06:34:990 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:35:000 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] scheduling refresher every 1s
2015-05-12-10:06:34:991 - TRACE - Log4jESLogger - [Ecstasy] [mimos][1] warming took [6.1ms]
2015-05-12-10:06:35:002 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:35:003 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] scheduling refresher every 1s
2015-05-12-10:06:35:004 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-10:06:35:003 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:35:004 - TRACE - Log4jESLogger - [Ecstasy] [mimos][3] refresh with force[true]
2015-05-12-10:06:35:004 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-10:06:35:009 - TRACE - Log4jESLogger - [Ecstasy] [mimos][4] refresh with force[true]
2015-05-12-10:06:35:010 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][4] recovery completed from [local], took [89ms]
2015-05-12-10:06:35:010 - DEBUG - Log4jESLogger - [Ecstasy] sending shard started for [mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:010 - DEBUG - Log4jESLogger - [Ecstasy] received shard started for [mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:004 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-10:06:35:008 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][3] recovery completed from [local], took [143ms]
2015-05-12-10:06:35:008 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] warming took [2.5ms]
2015-05-12-10:06:35:015 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:35:016 - DEBUG - Log4jESLogger - [Ecstasy] applying started shards [[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-10:06:35:016 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:35:017 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] scheduling refresher every 1s
2015-05-12-10:06:35:015 - DEBUG - Log4jESLogger - [Ecstasy] sending shard started for [mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:017 - DEBUG - Log4jESLogger - [Ecstasy] received shard started for [mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:015 - TRACE - Log4jESLogger - [Ecstasy] [mimos][1] refresh with force[true]
2015-05-12-10:06:35:017 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-10:06:35:018 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] refresh with force[true]
2015-05-12-10:06:35:018 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][2] recovery completed from [local], took [199ms]
2015-05-12-10:06:35:018 - DEBUG - Log4jESLogger - [Ecstasy] sending shard started for [mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:018 - DEBUG - Log4jESLogger - [Ecstasy] received shard started for [mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:017 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:35:018 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][1] recovery completed from [local], took [242ms]
2015-05-12-10:06:35:019 - TRACE - Log4jESLogger - [Ecstasy] Start balancing cluster
2015-05-12-10:06:35:020 - TRACE - Log4jESLogger - [Ecstasy] Start distributing Shards
2015-05-12-10:06:35:020 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:020 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:020 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:021 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:020 - DEBUG - Log4jESLogger - [Ecstasy] sending shard started for [mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:021 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:022 - TRACE - Log4jESLogger - [Ecstasy] Start allocating unassigned shards
2015-05-12-10:06:35:022 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:022 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:023 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:024 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:024 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:024 - TRACE - Log4jESLogger - [Ecstasy] Start balancing cluster
2015-05-12-10:06:35:025 - TRACE - Log4jESLogger - [Ecstasy] Start distributing Shards
2015-05-12-10:06:35:025 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:025 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:026 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:026 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:026 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:027 - TRACE - Log4jESLogger - [Ecstasy] Start allocating unassigned shards
2015-05-12-10:06:35:028 - TRACE - Log4jESLogger - [Ecstasy] cluster state updated:
version [3], source [shard-started ([mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[cpWS9QRAR6iQLHKFfHDX3Q][V]
--------[mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]
--------[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:06:35:028 - DEBUG - Log4jESLogger - [Ecstasy] Publishing cluster state version 3
2015-05-12-10:06:35:030 - DEBUG - Log4jESLogger - [Ecstasy] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-10:06:35:031 - DEBUG - Log4jESLogger - [Ecstasy] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:35:021 - DEBUG - Log4jESLogger - [Ecstasy] received shard started for [mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:032 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] creating shard
2015-05-12-10:06:35:040 - DEBUG - Log4jESLogger - [Ecstasy] [mimos] creating shard_id [0]
2015-05-12-10:06:35:032 - DEBUG - Log4jESLogger - [Ecstasy] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:35:049 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-10:06:35:051 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:35:051 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:35:052 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] state: [CREATED]
2015-05-12-10:06:35:053 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:35:054 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:35:055 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] starting recovery from local ...
2015-05-12-10:06:35:055 - TRACE - Log4jESLogger - [Ecstasy] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-10:06:35:056 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] starting engine
2015-05-12-10:06:35:057 - TRACE - Log4jESLogger - [Ecstasy] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-10:06:35:058 - TRACE - Log4jESLogger - [Ecstasy] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:35:059 - TRACE - Log4jESLogger - [Ecstasy] [mimos][0] warming took [89.4micros]
2015-05-12-10:06:35:059 - DEBUG - Log4jESLogger - [Ecstasy] sending shard started for [mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:35:060 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:35:060 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] scheduling refresher every 1s
2015-05-12-10:06:35:060 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-10:06:35:061 - TRACE - Log4jESLogger - [Ecstasy] [mimos][0] refresh with force[true]
2015-05-12-10:06:35:061 - DEBUG - Log4jESLogger - [Ecstasy] [mimos][0] recovery completed from [local], took [6ms]
2015-05-12-10:06:35:061 - DEBUG - Log4jESLogger - [Ecstasy] sending shard started for [mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:061 - DEBUG - Log4jESLogger - [Ecstasy] received shard started for [mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:35:060 - DEBUG - Log4jESLogger - [Ecstasy] received shard started for [mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:35:062 - TRACE - Log4jESLogger - [Ecstasy] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-10:06:35:062 - DEBUG - Log4jESLogger - [Ecstasy] sending shard started for [mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:35:062 - DEBUG - Log4jESLogger - [Ecstasy] received shard started for [mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:35:063 - TRACE - Log4jESLogger - [Ecstasy] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-10:06:35:063 - DEBUG - Log4jESLogger - [Ecstasy] sending shard started for [mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:35:063 - DEBUG - Log4jESLogger - [Ecstasy] received shard started for [mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:35:064 - TRACE - Log4jESLogger - [Ecstasy] cluster changed (version 3), trying to index again
2015-05-12-10:06:35:064 - TRACE - Log4jESLogger - [Ecstasy] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [cpWS9QRAR6iQLHKFfHDX3Q], scheduling a retry.
2015-05-12-10:06:35:065 - TRACE - Log4jESLogger - [Ecstasy] retry scheduling ignored as it as we already have a listener in place
2015-05-12-10:06:35:065 - TRACE - Log4jESLogger - [Ecstasy] [mimos][4] writing shard state, reason [version changed from [42] to [44]]
2015-05-12-10:06:35:123 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-10:06:35:123 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:35:123 - DEBUG - Log4jESLogger - [Ecstasy] applying started shards [[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], [mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], [mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], [mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], [mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], [mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING], [mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-10:06:35:124 - TRACE - Log4jESLogger - [Ecstasy] Start balancing cluster
2015-05-12-10:06:35:124 - TRACE - Log4jESLogger - [Ecstasy] Start distributing Shards
2015-05-12-10:06:35:124 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:125 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:125 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:125 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:125 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:125 - TRACE - Log4jESLogger - [Ecstasy] Start allocating unassigned shards
2015-05-12-10:06:35:125 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:126 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:126 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:126 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:126 - TRACE - Log4jESLogger - [Ecstasy] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:35:127 - TRACE - Log4jESLogger - [Ecstasy] Start balancing cluster
2015-05-12-10:06:35:127 - TRACE - Log4jESLogger - [Ecstasy] Start distributing Shards
2015-05-12-10:06:35:127 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:127 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:127 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:127 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:127 - TRACE - Log4jESLogger - [Ecstasy] Assigned shard [[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]] to node [cpWS9QRAR6iQLHKFfHDX3Q]
2015-05-12-10:06:35:128 - TRACE - Log4jESLogger - [Ecstasy] Start allocating unassigned shards
2015-05-12-10:06:35:128 - TRACE - Log4jESLogger - [Ecstasy] cluster state updated:
version [4], source [shard-started ([mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[cpWS9QRAR6iQLHKFfHDX3Q][V]
--------[mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
--------[mimos][4], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:06:35:129 - DEBUG - Log4jESLogger - [Ecstasy] Publishing cluster state version 4
2015-05-12-10:06:35:129 - DEBUG - Log4jESLogger - [Ecstasy] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-10:06:35:129 - DEBUG - Log4jESLogger - [Ecstasy] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:35:130 - DEBUG - Log4jESLogger - [Ecstasy] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:35:131 - TRACE - Log4jESLogger - [Ecstasy] cluster changed (version 4), trying to index again
2015-05-12-10:06:35:133 - TRACE - Log4jESLogger - [Ecstasy] [mimos][0] writing shard state, reason [version changed from [40] to [42]]
2015-05-12-10:06:35:149 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-10:06:35:165 - TRACE - Log4jESLogger - [Ecstasy] [mimos][3] writing shard state, reason [version changed from [40] to [42]]
2015-05-12-10:06:35:176 - DEBUG - Log4jESLogger - [Ecstasy] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-10:06:35:185 - INFO  - Log4jESLogger - [Jane Kincaid] version[0.90.5], pid[6140], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-10:06:35:186 - INFO  - Log4jESLogger - [Jane Kincaid] initializing ...
2015-05-12-10:06:35:186 - DEBUG - Log4jESLogger - [Jane Kincaid] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-10:06:35:186 - INFO  - Log4jESLogger - [Jane Kincaid] loaded [], sites []
2015-05-12-10:06:35:187 - TRACE - Log4jESLogger - [Jane Kincaid] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-10:06:35:187 - DEBUG - Log4jESLogger - [Jane Kincaid] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-10:06:35:188 - TRACE - Log4jESLogger - [Jane Kincaid] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-10:06:35:199 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] writing shard state, reason [version changed from [30] to [32]]
2015-05-12-10:06:35:231 - TRACE - Log4jESLogger - [Jane Kincaid] sigar loaded successfully
2015-05-12-10:06:35:233 - TRACE - Log4jESLogger - [Ecstasy] [mimos][1] writing shard state, reason [version changed from [26] to [28]]
2015-05-12-10:06:35:368 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-10:06:35:369 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:35:369 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:06:35:369 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:35:369 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:06:35:369 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:35:369 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][0], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:06:35:369 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-10:06:35:370 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][1], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-10:06:35:370 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-10:06:35:370 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][2], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-10:06:35:370 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-10:06:35:370 - DEBUG - Log4jESLogger - [Ecstasy] processing [shard-started ([mimos][3], node[cpWS9QRAR6iQLHKFfHDX3Q], [P], s[INITIALIZING]), reason [master [Ecstasy][cpWS9QRAR6iQLHKFfHDX3Q][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-10:06:35:370 - DEBUG - Log4jESLogger - [Ecstasy] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-10:06:35:384 - DEBUG - Log4jESLogger - [Ecstasy] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-10:06:35:431 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-10:06:35:432 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:35:432 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:35:432 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:35:433 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-10:06:35:433 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-10:06:35:433 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-10:06:35:434 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-10:06:35:435 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:35:435 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:35:436 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:35:436 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:35:436 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:35:437 - DEBUG - Log4jESLogger - [Jane Kincaid] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-10:06:35:449 - DEBUG - Log4jESLogger - [Jane Kincaid] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-10:06:35:450 - DEBUG - Log4jESLogger - [Jane Kincaid] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-10:06:35:450 - DEBUG - Log4jESLogger - [Jane Kincaid] using initial hosts [], with concurrent_connects [10]
2015-05-12-10:06:35:451 - DEBUG - Log4jESLogger - [Jane Kincaid] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-10:06:35:451 - DEBUG - Log4jESLogger - [Jane Kincaid] using minimum_master_nodes [-1]
2015-05-12-10:06:35:452 - DEBUG - Log4jESLogger - [Jane Kincaid] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:06:35:452 - DEBUG - Log4jESLogger - [Jane Kincaid] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:06:35:468 - DEBUG - Log4jESLogger - [Jane Kincaid] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-10:06:35:970 - DEBUG - Log4jESLogger - [Jane Kincaid] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@3c69362a] with refresh_interval [1s]
2015-05-12-10:06:35:971 - DEBUG - Log4jESLogger - [Jane Kincaid] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@29138d3a] with refresh_interval [1s]
2015-05-12-10:06:35:973 - DEBUG - Log4jESLogger - [Jane Kincaid] Using refresh_interval [1s]
2015-05-12-10:06:35:974 - DEBUG - Log4jESLogger - [Jane Kincaid] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@17d32e9b] with refresh_interval [5s]
2015-05-12-10:06:35:975 - DEBUG - Log4jESLogger - [Jane Kincaid] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-10:06:35:977 - TRACE - Log4jESLogger - [Jane Kincaid] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:12266 errors:0 dropped:0 overruns:0 frame:0
	TX packets:12266 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:4648645 (4.4M)  TX bytes:4648645 (4.4M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:227213 errors:0 dropped:0 overruns:0 frame:0
	TX packets:120651 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:262154271 (250M)  TX bytes:13033502 ( 12M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:236 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:235 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-10:06:35:978 - DEBUG - Log4jESLogger - [Jane Kincaid] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@1e86a5a7] with refresh_interval [1s]
2015-05-12-10:06:35:980 - DEBUG - Log4jESLogger - [Jane Kincaid] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-10:06:35:981 - DEBUG - Log4jESLogger - [Jane Kincaid] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-10:06:35:982 - DEBUG - Log4jESLogger - [Jane Kincaid] using script cache with max_size [500], expire [null]
2015-05-12-10:06:35:982 - DEBUG - Log4jESLogger - [Jane Kincaid] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:35:983 - DEBUG - Log4jESLogger - [Jane Kincaid] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:35:983 - DEBUG - Log4jESLogger - [Jane Kincaid] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:35:984 - DEBUG - Log4jESLogger - [Jane Kincaid] using initial_shards [quorum], list_timeout [30s]
2015-05-12-10:06:35:989 - DEBUG - Log4jESLogger - [Jane Kincaid] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-10:06:35:998 - DEBUG - Log4jESLogger - [Jane Kincaid] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-10:06:36:000 - DEBUG - Log4jESLogger - [Jane Kincaid] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-10:06:36:002 - DEBUG - Log4jESLogger - [Jane Kincaid] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-10:06:36:005 - DEBUG - Log4jESLogger - [Jane Kincaid] using size [-1] [-1b], expire [null]
2015-05-12-10:06:36:009 - DEBUG - Log4jESLogger - [Jane Kincaid] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-10:06:36:010 - TRACE - Log4jESLogger - [Jane Kincaid] [upgrade]: processing [global-14]
2015-05-12-10:06:36:011 - DEBUG - Log4jESLogger - [Jane Kincaid] took 1ms to load state
2015-05-12-10:06:36:012 - TRACE - Log4jESLogger - [Jane Kincaid] [find_latest_state]: processing [global-14]
2015-05-12-10:06:36:013 - DEBUG - Log4jESLogger - [Jane Kincaid] took 1ms to load started shards state
2015-05-12-10:06:36:014 - DEBUG - Log4jESLogger - [Jane Kincaid] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-10:06:36:017 - DEBUG - Log4jESLogger - [Jane Kincaid] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:36:019 - DEBUG - Log4jESLogger - [Jane Kincaid] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:36:020 - DEBUG - Log4jESLogger - [Jane Kincaid] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:36:021 - DEBUG - Log4jESLogger - [Jane Kincaid] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:36:022 - DEBUG - Log4jESLogger - [Jane Kincaid] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:36:022 - DEBUG - Log4jESLogger - [Jane Kincaid] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:36:025 - INFO  - Log4jESLogger - [Jane Kincaid] initialized
2015-05-12-10:06:36:026 - INFO  - Log4jESLogger - [Jane Kincaid] starting ...
2015-05-12-10:06:36:028 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] refresh with force[false]
2015-05-12-10:06:36:091 - DEBUG - Log4jESLogger - [Jane Kincaid] Bound to address [/0:0:0:0:0:0:0:0:9302]
2015-05-12-10:06:36:092 - INFO  - Log4jESLogger - [Jane Kincaid] bound_address {inet[/0:0:0:0:0:0:0:0:9302]}, publish_address {inet[/10.11.66.27:9302]}
2015-05-12-10:06:36:098 - TRACE - Log4jESLogger - [Jane Kincaid] waiting for 30s for the initial state to be set by the discovery
2015-05-12-10:06:36:107 - TRACE - Log4jESLogger - [Jane Kincaid] [1] sending ping request
2015-05-12-10:06:36:107 - TRACE - Log4jESLogger - [Ecstasy] [1] received ping_request from [[Jane Kincaid][McsSRJL3SCW2Ts-1xQt3uA][inet[/10.11.66.27:9302]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-10:06:36:175 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] warming [StandardDirectoryReader(segments_1:3:nrt _0(4.4):c1)], new [MultiReader(_0(4.4):c1)]
2015-05-12-10:06:36:175 - TRACE - Log4jESLogger - [Ecstasy] [mimos][2] warming took [188micros]
2015-05-12-10:06:37:610 - TRACE - Log4jESLogger - [Ecstasy] [1] received ping_request from [[Jane Kincaid][McsSRJL3SCW2Ts-1xQt3uA][inet[/10.11.66.27:9302]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-10:06:37:611 - TRACE - Log4jESLogger - [Jane Kincaid] [1] sending ping request
2015-05-12-10:06:39:110 - TRACE - Log4jESLogger - [Jane Kincaid] full ping responses: {none}
2015-05-12-10:06:39:110 - DEBUG - Log4jESLogger - [Jane Kincaid] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-10:06:39:111 - DEBUG - Log4jESLogger - [Jane Kincaid] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-10:06:39:111 - TRACE - Log4jESLogger - [Jane Kincaid] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Jane Kincaid][McsSRJL3SCW2Ts-1xQt3uA][inet[/10.11.66.27:9302]], local, master
routing_table:
routing_nodes:
-----node_id[McsSRJL3SCW2Ts-1xQt3uA][V]
---- unassigned

2015-05-12-10:06:39:112 - INFO  - Log4jESLogger - [Jane Kincaid] new_master [Jane Kincaid][McsSRJL3SCW2Ts-1xQt3uA][inet[/10.11.66.27:9302]], reason: zen-disco-join (elected_as_master)
2015-05-12-10:06:39:114 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0x7510f3bf, /10.11.66.27:41893 => /10.11.66.27:9302]
2015-05-12-10:06:39:115 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0x5c604be2, /10.11.66.27:41894 => /10.11.66.27:9302]
2015-05-12-10:06:39:115 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0x1e4180d3, /10.11.66.27:41895 => /10.11.66.27:9302]
2015-05-12-10:06:39:116 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0x86b4ade2, /10.11.66.27:41896 => /10.11.66.27:9302]
2015-05-12-10:06:39:116 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0x2eb21aa4, /10.11.66.27:41897 => /10.11.66.27:9302]
2015-05-12-10:06:39:119 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0xdc66ace1, /10.11.66.27:41898 => /10.11.66.27:9302]
2015-05-12-10:06:39:121 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0x2a75bd57, /10.11.66.27:41899 => /10.11.66.27:9302]
2015-05-12-10:06:39:122 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0xe0845ff8, /10.11.66.27:41900 => /10.11.66.27:9302]
2015-05-12-10:06:39:121 - DEBUG - Log4jESLogger - [Jane Kincaid] connected to node [[Jane Kincaid][McsSRJL3SCW2Ts-1xQt3uA][inet[/10.11.66.27:9302]]]
2015-05-12-10:06:39:125 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0xdcea11c5, /10.11.66.27:41901 => /10.11.66.27:9302]
2015-05-12-10:06:39:127 - TRACE - Log4jESLogger - [Jane Kincaid] channel opened: [id: 0xc887d5c4, /10.11.66.27:41902 => /10.11.66.27:9302]
2015-05-12-10:06:39:130 - DEBUG - Log4jESLogger - [Jane Kincaid] Publishing cluster state version 1
2015-05-12-10:06:39:130 - DEBUG - Log4jESLogger - [Jane Kincaid] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-10:06:39:131 - DEBUG - Log4jESLogger - [Jane Kincaid] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:39:131 - DEBUG - Log4jESLogger - [Jane Kincaid] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:39:132 - DEBUG - Log4jESLogger - [Jane Kincaid] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-10:06:39:133 - TRACE - Log4jESLogger - [Jane Kincaid] initial state set from discovery
2015-05-12-10:06:39:133 - INFO  - Log4jESLogger - [Jane Kincaid] kodcu/McsSRJL3SCW2Ts-1xQt3uA
2015-05-12-10:06:39:133 - TRACE - Log4jESLogger - [Jane Kincaid] performing state recovery...
2015-05-12-10:06:39:133 - TRACE - Log4jESLogger - [Jane Kincaid] performing state recovery from [McsSRJL3SCW2Ts-1xQt3uA]
2015-05-12-10:06:39:136 - TRACE - Log4jESLogger - [Jane Kincaid] successful state recovery, importing cluster state...
2015-05-12-10:06:39:136 - TRACE - Log4jESLogger - [Jane Kincaid] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-10:06:39:137 - DEBUG - Log4jESLogger - [Jane Kincaid] processing [local-gateway-elected-state]: execute
2015-05-12-10:06:39:140 - DEBUG - Log4jESLogger - [Jane Kincaid] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:06:39:141 - DEBUG - Log4jESLogger - [Jane Kincaid] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Jane Kincaid][McsSRJL3SCW2Ts-1xQt3uA][inet[/10.11.66.27:9302]]] on primary allocation
2015-05-12-10:06:39:143 - DEBUG - Log4jESLogger - [Jane Kincaid] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Jane Kincaid][McsSRJL3SCW2Ts-1xQt3uA][inet[/10.11.66.27:9302]]] on primary allocation
2015-05-12-10:06:39:144 - DEBUG - Log4jESLogger - [Jane Kincaid] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:06:39:145 - DEBUG - Log4jESLogger - [Jane Kincaid] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:06:39:145 - TRACE - Log4jESLogger - [Jane Kincaid] Start balancing cluster
2015-05-12-10:06:39:145 - TRACE - Log4jESLogger - [Jane Kincaid] Start distributing Shards
2015-05-12-10:06:39:145 - TRACE - Log4jESLogger - [Jane Kincaid] Assigned shard [[mimos][2], node[McsSRJL3SCW2Ts-1xQt3uA], [P], s[INITIALIZING]] to node [McsSRJL3SCW2Ts-1xQt3uA]
2015-05-12-10:06:39:146 - TRACE - Log4jESLogger - [Jane Kincaid] Assigned shard [[mimos][0], node[McsSRJL3SCW2Ts-1xQt3uA], [P], s[INITIALIZING]] to node [McsSRJL3SCW2Ts-1xQt3uA]
2015-05-12-10:06:39:146 - TRACE - Log4jESLogger - [Jane Kincaid] Start allocating unassigned shards
2015-05-12-10:06:39:146 - TRACE - Log4jESLogger - [Jane Kincaid] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:39:146 - TRACE - Log4jESLogger - [Jane Kincaid] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:39:146 - TRACE - Log4jESLogger - [Jane Kincaid] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:39:146 - TRACE - Log4jESLogger - [Jane Kincaid] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:39:147 - TRACE - Log4jESLogger - [Jane Kincaid] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:39:147 - TRACE - Log4jESLogger - [Jane Kincaid] Start balancing cluster
2015-05-12-10:06:39:147 - TRACE - Log4jESLogger - [Jane Kincaid] Start distributing Shards
2015-05-12-10:06:39:147 - TRACE - Log4jESLogger - [Jane Kincaid] Assigned shard [[mimos][2], node[McsSRJL3SCW2Ts-1xQt3uA], [P], s[INITIALIZING]] to node [McsSRJL3SCW2Ts-1xQt3uA]
2015-05-12-10:06:39:147 - TRACE - Log4jESLogger - [Jane Kincaid] Assigned shard [[mimos][0], node[McsSRJL3SCW2Ts-1xQt3uA], [P], s[INITIALIZING]] to node [McsSRJL3SCW2Ts-1xQt3uA]
2015-05-12-10:06:39:147 - TRACE - Log4jESLogger - [Jane Kincaid] Start allocating unassigned shards
2015-05-12-10:06:39:148 - TRACE - Log4jESLogger - [Jane Kincaid] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Jane Kincaid][McsSRJL3SCW2Ts-1xQt3uA][inet[/10.11.66.27:9302]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[McsSRJL3SCW2Ts-1xQt3uA], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[McsSRJL3SCW2Ts-1xQt3uA], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[McsSRJL3SCW2Ts-1xQt3uA][V]
--------[mimos][0], node[McsSRJL3SCW2Ts-1xQt3uA], [P], s[INITIALIZING]
--------[mimos][2], node[McsSRJL3SCW2Ts-1xQt3uA], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:06:39:149 - DEBUG - Log4jESLogger - [Jane Kincaid] Publishing cluster state version 2
2015-05-12-10:06:39:149 - DEBUG - Log4jESLogger - [Jane Kincaid] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-10:06:39:153 - DEBUG - Log4jESLogger - [Jane Kincaid] [mimos] creating index
2015-05-12-10:06:39:153 - DEBUG - Log4jESLogger - [Jane Kincaid] creating Index [mimos], shards [5]/[1]
2015-05-12-10:06:39:154 - DEBUG - Log4jESLogger - [Jane Kincaid] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:39:158 - DEBUG - Log4jESLogger - [Jane Kincaid] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:39:177 - INFO  - Log4jESLogger - [Jane Kincaid] bound_address {inet[/0:0:0:0:0:0:0:0:9202]}, publish_address {inet[/10.11.66.27:9202]}
2015-05-12-10:06:39:178 - INFO  - Log4jESLogger - [Jane Kincaid] started
2015-05-12-10:06:43:914 - INFO  - Log4jESLogger - [Smythe, Alistair] version[0.90.5], pid[6262], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-10:06:43:918 - INFO  - Log4jESLogger - [Smythe, Alistair] initializing ...
2015-05-12-10:06:43:919 - DEBUG - Log4jESLogger - [Smythe, Alistair] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-10:06:43:935 - INFO  - Log4jESLogger - [Smythe, Alistair] loaded [], sites []
2015-05-12-10:06:43:971 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-10:06:43:976 - TRACE - Log4jESLogger - [Smythe, Alistair] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-10:06:43:998 - DEBUG - Log4jESLogger - [Smythe, Alistair] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-10:06:44:006 - TRACE - Log4jESLogger - [Smythe, Alistair] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-10:06:44:646 - TRACE - Log4jESLogger - [Smythe, Alistair] sigar loaded successfully
2015-05-12-10:06:45:432 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-10:06:45:438 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:45:442 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:45:443 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:45:446 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-10:06:45:448 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-10:06:45:465 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-10:06:45:468 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-10:06:45:473 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:45:475 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:45:477 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:45:480 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:45:482 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:45:484 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-10:06:45:506 - DEBUG - Log4jESLogger - [Smythe, Alistair] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-10:06:45:519 - DEBUG - Log4jESLogger - [Smythe, Alistair] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-10:06:45:527 - DEBUG - Log4jESLogger - [Smythe, Alistair] using initial hosts [], with concurrent_connects [10]
2015-05-12-10:06:45:533 - DEBUG - Log4jESLogger - [Smythe, Alistair] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-10:06:45:536 - DEBUG - Log4jESLogger - [Smythe, Alistair] using minimum_master_nodes [-1]
2015-05-12-10:06:45:541 - DEBUG - Log4jESLogger - [Smythe, Alistair] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:06:45:549 - DEBUG - Log4jESLogger - [Smythe, Alistair] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:06:45:595 - DEBUG - Log4jESLogger - [Smythe, Alistair] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-10:06:46:116 - DEBUG - Log4jESLogger - [Smythe, Alistair] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-10:06:46:139 - DEBUG - Log4jESLogger - [Smythe, Alistair] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-10:06:46:151 - DEBUG - Log4jESLogger - [Smythe, Alistair] Using refresh_interval [1s]
2015-05-12-10:06:46:153 - DEBUG - Log4jESLogger - [Smythe, Alistair] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-10:06:46:171 - DEBUG - Log4jESLogger - [Smythe, Alistair] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-10:06:46:175 - TRACE - Log4jESLogger - [Smythe, Alistair] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:12584 errors:0 dropped:0 overruns:0 frame:0
	TX packets:12584 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:5932381 (5.7M)  TX bytes:5932381 (5.7M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:227276 errors:0 dropped:0 overruns:0 frame:0
	TX packets:120656 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:262161346 (250M)  TX bytes:13034332 ( 12M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:236 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:235 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-10:06:46:200 - DEBUG - Log4jESLogger - [Smythe, Alistair] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-10:06:46:856 - DEBUG - Log4jESLogger - [Smythe, Alistair] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-10:06:46:870 - DEBUG - Log4jESLogger - [Smythe, Alistair] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-10:06:46:879 - DEBUG - Log4jESLogger - [Smythe, Alistair] using script cache with max_size [500], expire [null]
2015-05-12-10:06:46:899 - DEBUG - Log4jESLogger - [Smythe, Alistair] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:46:906 - DEBUG - Log4jESLogger - [Smythe, Alistair] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:46:907 - DEBUG - Log4jESLogger - [Smythe, Alistair] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:46:945 - DEBUG - Log4jESLogger - [Smythe, Alistair] using initial_shards [quorum], list_timeout [30s]
2015-05-12-10:06:47:177 - DEBUG - Log4jESLogger - [Smythe, Alistair] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-10:06:47:318 - DEBUG - Log4jESLogger - [Smythe, Alistair] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-10:06:47:333 - DEBUG - Log4jESLogger - [Smythe, Alistair] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-10:06:47:336 - DEBUG - Log4jESLogger - [Smythe, Alistair] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-10:06:47:340 - DEBUG - Log4jESLogger - [Smythe, Alistair] using size [-1] [-1b], expire [null]
2015-05-12-10:06:47:383 - DEBUG - Log4jESLogger - [Smythe, Alistair] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-10:06:47:384 - TRACE - Log4jESLogger - [Smythe, Alistair] [upgrade]: processing [global-24]
2015-05-12-10:06:47:547 - DEBUG - Log4jESLogger - [Smythe, Alistair] took 163ms to load state
2015-05-12-10:06:47:550 - TRACE - Log4jESLogger - [Smythe, Alistair] [find_latest_state]: processing [global-24]
2015-05-12-10:06:47:556 - DEBUG - Log4jESLogger - [Smythe, Alistair] took 4ms to load started shards state
2015-05-12-10:06:47:560 - DEBUG - Log4jESLogger - [Smythe, Alistair] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-10:06:47:565 - DEBUG - Log4jESLogger - [Smythe, Alistair] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:47:567 - DEBUG - Log4jESLogger - [Smythe, Alistair] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:47:569 - DEBUG - Log4jESLogger - [Smythe, Alistair] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:47:572 - DEBUG - Log4jESLogger - [Smythe, Alistair] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:47:574 - DEBUG - Log4jESLogger - [Smythe, Alistair] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:47:575 - DEBUG - Log4jESLogger - [Smythe, Alistair] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:47:582 - INFO  - Log4jESLogger - [Smythe, Alistair] initialized
2015-05-12-10:06:47:584 - INFO  - Log4jESLogger - [Smythe, Alistair] starting ...
2015-05-12-10:06:47:615 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-10:06:47:616 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-10:06:47:736 - DEBUG - Log4jESLogger - [Smythe, Alistair] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-10:06:47:742 - INFO  - Log4jESLogger - [Smythe, Alistair] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-10:06:47:773 - TRACE - Log4jESLogger - [Smythe, Alistair] waiting for 30s for the initial state to be set by the discovery
2015-05-12-10:06:47:803 - TRACE - Log4jESLogger - [Smythe, Alistair] [1] sending ping request
2015-05-12-10:06:49:307 - TRACE - Log4jESLogger - [Smythe, Alistair] [1] sending ping request
2015-05-12-10:06:50:812 - TRACE - Log4jESLogger - [Smythe, Alistair] full ping responses: {none}
2015-05-12-10:06:50:813 - DEBUG - Log4jESLogger - [Smythe, Alistair] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-10:06:50:820 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-10:06:50:822 - TRACE - Log4jESLogger - [Smythe, Alistair] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[eDrw4f-TSNmstJAMrX3vrQ][V]
---- unassigned

2015-05-12-10:06:50:825 - INFO  - Log4jESLogger - [Smythe, Alistair] new_master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-10:06:50:847 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0x50038040, /10.11.66.27:49229 => /10.11.66.27:9301]
2015-05-12-10:06:50:864 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0xe94534fb, /10.11.66.27:49230 => /10.11.66.27:9301]
2015-05-12-10:06:50:865 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0x6501488d, /10.11.66.27:49231 => /10.11.66.27:9301]
2015-05-12-10:06:50:865 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0x09cd1d49, /10.11.66.27:49232 => /10.11.66.27:9301]
2015-05-12-10:06:50:866 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0xd8df9f9c, /10.11.66.27:49233 => /10.11.66.27:9301]
2015-05-12-10:06:50:867 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0x1ac0602d, /10.11.66.27:49234 => /10.11.66.27:9301]
2015-05-12-10:06:50:867 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0xe1d1a38b, /10.11.66.27:49235 => /10.11.66.27:9301]
2015-05-12-10:06:50:868 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0x32a09dc6, /10.11.66.27:49236 => /10.11.66.27:9301]
2015-05-12-10:06:50:881 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0xa301b569, /10.11.66.27:49237 => /10.11.66.27:9301]
2015-05-12-10:06:50:882 - TRACE - Log4jESLogger - [Smythe, Alistair] channel opened: [id: 0x1149ba7b, /10.11.66.27:49238 => /10.11.66.27:9301]
2015-05-12-10:06:50:900 - DEBUG - Log4jESLogger - [Smythe, Alistair] connected to node [[Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]]]
2015-05-12-10:06:50:903 - DEBUG - Log4jESLogger - [Smythe, Alistair] Publishing cluster state version 1
2015-05-12-10:06:50:905 - DEBUG - Log4jESLogger - [Smythe, Alistair] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-10:06:50:925 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:50:925 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:50:931 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-10:06:50:932 - TRACE - Log4jESLogger - [Smythe, Alistair] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-10:06:50:931 - TRACE - Log4jESLogger - [Smythe, Alistair] initial state set from discovery
2015-05-12-10:06:50:934 - INFO  - Log4jESLogger - [Smythe, Alistair] peansData/eDrw4f-TSNmstJAMrX3vrQ
2015-05-12-10:06:50:936 - TRACE - Log4jESLogger - [Smythe, Alistair] performing state recovery...
2015-05-12-10:06:50:936 - TRACE - Log4jESLogger - [Smythe, Alistair] performing state recovery from [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:50:954 - TRACE - Log4jESLogger - [Smythe, Alistair] successful state recovery, importing cluster state...
2015-05-12-10:06:50:957 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [local-gateway-elected-state]: execute
2015-05-12-10:06:50:990 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:50:997 - INFO  - Log4jESLogger - [Smythe, Alistair] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-10:06:51:002 - INFO  - Log4jESLogger - [Smythe, Alistair] started
2015-05-12-10:06:51:014 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:51:016 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:51:017 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:51:020 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2]: throttling allocation [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[[Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]]]] on primary allocation
2015-05-12-10:06:51:051 - TRACE - Log4jESLogger - [Smythe, Alistair] Start balancing cluster
2015-05-12-10:06:51:063 - TRACE - Log4jESLogger - [Smythe, Alistair] Start distributing Shards
2015-05-12-10:06:51:075 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:51:075 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:51:075 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:51:076 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:51:076 - TRACE - Log4jESLogger - [Smythe, Alistair] Start allocating unassigned shards
2015-05-12-10:06:51:077 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:51:078 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:51:078 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:51:078 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:51:079 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:51:099 - TRACE - Log4jESLogger - [Smythe, Alistair] Start balancing cluster
2015-05-12-10:06:51:103 - TRACE - Log4jESLogger - [Smythe, Alistair] Start distributing Shards
2015-05-12-10:06:51:104 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:51:105 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:51:105 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:51:106 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:51:107 - TRACE - Log4jESLogger - [Smythe, Alistair] Start allocating unassigned shards
2015-05-12-10:06:51:113 - TRACE - Log4jESLogger - [Smythe, Alistair] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[null], [P], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[eDrw4f-TSNmstJAMrX3vrQ][V]
--------[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [P], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:06:51:114 - DEBUG - Log4jESLogger - [Smythe, Alistair] Publishing cluster state version 2
2015-05-12-10:06:51:114 - DEBUG - Log4jESLogger - [Smythe, Alistair] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-10:06:51:115 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:51:121 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:51:116 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] creating index
2015-05-12-10:06:51:125 - DEBUG - Log4jESLogger - [Smythe, Alistair] creating Index [mimos], shards [5]/[1]
2015-05-12-10:06:51:810 - TRACE - Log4jESLogger - [Smythe, Alistair] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [null], scheduling a retry.
2015-05-12-10:06:51:841 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-10:06:51:845 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-10:06:51:869 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-10:06:52:057 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-10:06:52:176 - DEBUG - Log4jESLogger - [Smythe, Alistair] Sending mapping created for index mimos, type Programmer
2015-05-12-10:06:52:213 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] creating shard
2015-05-12-10:06:52:214 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] creating shard_id [0]
2015-05-12-10:06:52:375 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-10:06:52:381 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:52:383 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:52:391 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] state: [CREATED]
2015-05-12-10:06:52:394 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:52:408 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:52:410 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] creating shard
2015-05-12-10:06:52:411 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] creating shard_id [1]
2015-05-12-10:06:52:411 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] starting recovery from local ...
2015-05-12-10:06:52:422 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-10:06:52:423 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:52:423 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:52:427 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] state: [CREATED]
2015-05-12-10:06:52:429 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:52:442 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-10:06:52:443 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:52:444 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] starting recovery from local ...
2015-05-12-10:06:52:445 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-10:06:52:446 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] starting engine
2015-05-12-10:06:52:450 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] creating shard
2015-05-12-10:06:52:450 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] creating shard_id [3]
2015-05-12-10:06:52:448 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] starting engine
2015-05-12-10:06:52:463 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-10:06:52:464 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:52:464 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:52:465 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] state: [CREATED]
2015-05-12-10:06:52:466 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:52:467 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:52:467 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] creating shard
2015-05-12-10:06:52:468 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] creating shard_id [4]
2015-05-12-10:06:52:476 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-10:06:52:477 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:52:478 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:52:478 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] starting recovery from local ...
2015-05-12-10:06:52:480 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-10:06:52:480 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] starting engine
2015-05-12-10:06:52:481 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] state: [CREATED]
2015-05-12-10:06:52:482 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:52:483 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:52:487 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] starting recovery from local ...
2015-05-12-10:06:52:488 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-10:06:52:488 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] starting engine
2015-05-12-10:06:52:495 - TRACE - Log4jESLogger - [Smythe, Alistair] [_global] writing state, reason [changed]
2015-05-12-10:06:52:578 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:52:584 - INFO  - Log4jESLogger - [Smythe, Alistair] recovered [1] indices into cluster_state
2015-05-12-10:06:52:593 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-10:06:52:578 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:52:583 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:52:583 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:52:594 - TRACE - Log4jESLogger - [Smythe, Alistair] listener to cluster state added, trying to index again
2015-05-12-10:06:52:597 - TRACE - Log4jESLogger - [Smythe, Alistair] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [null], scheduling a retry.
2015-05-12-10:06:52:597 - TRACE - Log4jESLogger - [Smythe, Alistair] retry scheduling ignored as it as we already have a listener in place
2015-05-12-10:06:52:610 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][3] warming took [13.6ms]
2015-05-12-10:06:52:614 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][4] warming took [18.2ms]
2015-05-12-10:06:52:615 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:52:610 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][0] warming took [4.1ms]
2015-05-12-10:06:52:613 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:52:617 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] scheduling refresher every 1s
2015-05-12-10:06:52:617 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:52:618 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] scheduling refresher every 1s
2015-05-12-10:06:52:618 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-10:06:52:618 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] scheduling refresher every 1s
2015-05-12-10:06:52:619 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-10:06:52:619 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][3] refresh with force[true]
2015-05-12-10:06:52:620 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][3] recovery completed from [local], took [142ms]
2015-05-12-10:06:52:620 - DEBUG - Log4jESLogger - [Smythe, Alistair] sending shard started for [mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:618 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-10:06:52:619 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][0] refresh with force[true]
2015-05-12-10:06:52:621 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][1] warming took [24.5ms]
2015-05-12-10:06:52:625 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:52:625 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] scheduling refresher every 1s
2015-05-12-10:06:52:625 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-10:06:52:626 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][1] refresh with force[true]
2015-05-12-10:06:52:626 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][1] recovery completed from [local], took [182ms]
2015-05-12-10:06:52:626 - DEBUG - Log4jESLogger - [Smythe, Alistair] sending shard started for [mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:626 - DEBUG - Log4jESLogger - [Smythe, Alistair] received shard started for [mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:627 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:52:628 - DEBUG - Log4jESLogger - [Smythe, Alistair] applying started shards [[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-10:06:52:629 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-10:06:52:629 - TRACE - Log4jESLogger - [Smythe, Alistair] Start balancing cluster
2015-05-12-10:06:52:629 - TRACE - Log4jESLogger - [Smythe, Alistair] Start distributing Shards
2015-05-12-10:06:52:630 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:631 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:631 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:631 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:631 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:631 - TRACE - Log4jESLogger - [Smythe, Alistair] Start allocating unassigned shards
2015-05-12-10:06:52:621 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][4] refresh with force[true]
2015-05-12-10:06:52:633 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][4] recovery completed from [local], took [145ms]
2015-05-12-10:06:52:633 - DEBUG - Log4jESLogger - [Smythe, Alistair] sending shard started for [mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:633 - DEBUG - Log4jESLogger - [Smythe, Alistair] received shard started for [mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:621 - DEBUG - Log4jESLogger - [Smythe, Alistair] received shard started for [mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:632 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][0] recovery completed from [local], took [222ms]
2015-05-12-10:06:52:632 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:634 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:635 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:635 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:635 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:636 - TRACE - Log4jESLogger - [Smythe, Alistair] Start balancing cluster
2015-05-12-10:06:52:636 - TRACE - Log4jESLogger - [Smythe, Alistair] Start distributing Shards
2015-05-12-10:06:52:637 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:637 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:637 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:637 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:638 - DEBUG - Log4jESLogger - [Smythe, Alistair] sending shard started for [mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:638 - DEBUG - Log4jESLogger - [Smythe, Alistair] received shard started for [mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:638 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:639 - TRACE - Log4jESLogger - [Smythe, Alistair] Start allocating unassigned shards
2015-05-12-10:06:52:640 - TRACE - Log4jESLogger - [Smythe, Alistair] cluster state updated:
version [3], source [shard-started ([mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[eDrw4f-TSNmstJAMrX3vrQ][V]
--------[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
--------[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:06:52:640 - DEBUG - Log4jESLogger - [Smythe, Alistair] Publishing cluster state version 3
2015-05-12-10:06:52:640 - DEBUG - Log4jESLogger - [Smythe, Alistair] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-10:06:52:641 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:52:643 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:52:643 - TRACE - Log4jESLogger - [Smythe, Alistair] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-10:06:52:644 - DEBUG - Log4jESLogger - [Smythe, Alistair] sending shard started for [mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:52:644 - DEBUG - Log4jESLogger - [Smythe, Alistair] received shard started for [mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:52:647 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] creating shard
2015-05-12-10:06:52:648 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos] creating shard_id [2]
2015-05-12-10:06:52:669 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-10:06:52:670 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-10:06:52:671 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-10:06:52:674 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] state: [CREATED]
2015-05-12-10:06:52:675 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-10:06:52:676 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-10:06:52:676 - TRACE - Log4jESLogger - [Smythe, Alistair] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-10:06:52:677 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] starting recovery from local ...
2015-05-12-10:06:52:677 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-10:06:52:677 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] starting engine
2015-05-12-10:06:52:677 - DEBUG - Log4jESLogger - [Smythe, Alistair] sending shard started for [mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:52:680 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-10:06:52:681 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][2] warming took [173.9micros]
2015-05-12-10:06:52:680 - DEBUG - Log4jESLogger - [Smythe, Alistair] received shard started for [mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:52:682 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-10:06:52:682 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] scheduling refresher every 1s
2015-05-12-10:06:52:682 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-10:06:52:683 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][2] refresh with force[true]
2015-05-12-10:06:52:683 - DEBUG - Log4jESLogger - [Smythe, Alistair] [mimos][2] recovery completed from [local], took [7ms]
2015-05-12-10:06:52:683 - DEBUG - Log4jESLogger - [Smythe, Alistair] sending shard started for [mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:683 - DEBUG - Log4jESLogger - [Smythe, Alistair] received shard started for [mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-10:06:52:682 - TRACE - Log4jESLogger - [Smythe, Alistair] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-10:06:52:684 - DEBUG - Log4jESLogger - [Smythe, Alistair] sending shard started for [mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:52:684 - DEBUG - Log4jESLogger - [Smythe, Alistair] received shard started for [mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-10:06:52:685 - TRACE - Log4jESLogger - [Smythe, Alistair] cluster changed (version 3), trying to index again
2015-05-12-10:06:52:685 - TRACE - Log4jESLogger - [Smythe, Alistair] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [eDrw4f-TSNmstJAMrX3vrQ], scheduling a retry.
2015-05-12-10:06:52:685 - TRACE - Log4jESLogger - [Smythe, Alistair] retry scheduling ignored as it as we already have a listener in place
2015-05-12-10:06:52:686 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][1] writing shard state, reason [version changed from [28] to [30]]
2015-05-12-10:06:52:743 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-10:06:52:743 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:52:744 - DEBUG - Log4jESLogger - [Smythe, Alistair] applying started shards [[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], [mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], [mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], [mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], [mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], [mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING], [mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-10:06:52:744 - TRACE - Log4jESLogger - [Smythe, Alistair] Start balancing cluster
2015-05-12-10:06:52:745 - TRACE - Log4jESLogger - [Smythe, Alistair] Start distributing Shards
2015-05-12-10:06:52:745 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:745 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:745 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:745 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:746 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:746 - TRACE - Log4jESLogger - [Smythe, Alistair] Start allocating unassigned shards
2015-05-12-10:06:52:746 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:747 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:754 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:755 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:756 - TRACE - Log4jESLogger - [Smythe, Alistair] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:52:756 - TRACE - Log4jESLogger - [Smythe, Alistair] Start balancing cluster
2015-05-12-10:06:52:757 - TRACE - Log4jESLogger - [Smythe, Alistair] Start distributing Shards
2015-05-12-10:06:52:757 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:757 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:757 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:757 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:758 - TRACE - Log4jESLogger - [Smythe, Alistair] Assigned shard [[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]] to node [eDrw4f-TSNmstJAMrX3vrQ]
2015-05-12-10:06:52:758 - TRACE - Log4jESLogger - [Smythe, Alistair] Start allocating unassigned shards
2015-05-12-10:06:52:761 - TRACE - Log4jESLogger - [Smythe, Alistair] cluster state updated:
version [4], source [shard-started ([mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[eDrw4f-TSNmstJAMrX3vrQ][V]
--------[mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][1], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
--------[mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:06:52:761 - DEBUG - Log4jESLogger - [Smythe, Alistair] Publishing cluster state version 4
2015-05-12-10:06:52:762 - DEBUG - Log4jESLogger - [Smythe, Alistair] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-10:06:52:762 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:52:764 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:52:769 - TRACE - Log4jESLogger - [Smythe, Alistair] cluster changed (version 4), trying to index again
2015-05-12-10:06:52:777 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][0] writing shard state, reason [version changed from [42] to [44]]
2015-05-12-10:06:52:797 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-10:06:52:809 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][4] writing shard state, reason [version changed from [44] to [46]]
2015-05-12-10:06:52:834 - DEBUG - Log4jESLogger - [Smythe, Alistair] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-10:06:52:843 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][3] writing shard state, reason [version changed from [42] to [44]]
2015-05-12-10:06:52:877 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][2] delete [Programmer#1]
2015-05-12-10:06:52:885 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][2] writing shard state, reason [version changed from [32] to [34]]
2015-05-12-10:06:52:887 - INFO  - Log4jESLogger - [Dark Phoenix] version[0.90.5], pid[6262], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-10:06:52:888 - INFO  - Log4jESLogger - [Dark Phoenix] initializing ...
2015-05-12-10:06:52:888 - DEBUG - Log4jESLogger - [Dark Phoenix] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-10:06:52:888 - INFO  - Log4jESLogger - [Dark Phoenix] loaded [], sites []
2015-05-12-10:06:52:889 - TRACE - Log4jESLogger - [Dark Phoenix] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-10:06:52:889 - DEBUG - Log4jESLogger - [Dark Phoenix] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-10:06:52:889 - TRACE - Log4jESLogger - [Dark Phoenix] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-10:06:52:919 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-10:06:52:919 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:52:920 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:06:52:920 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:52:920 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:06:52:920 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-10:06:52:920 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][0], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-10:06:52:920 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-10:06:52:920 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][3], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-10:06:52:920 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-10:06:52:921 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][2], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-10:06:52:921 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-10:06:52:921 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [shard-started ([mimos][4], node[eDrw4f-TSNmstJAMrX3vrQ], [P], s[INITIALIZING]), reason [master [Smythe, Alistair][eDrw4f-TSNmstJAMrX3vrQ][inet[/10.11.66.27:9301]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-10:06:52:921 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-10:06:52:926 - DEBUG - Log4jESLogger - [Smythe, Alistair] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-10:06:52:934 - TRACE - Log4jESLogger - [Dark Phoenix] sigar loaded successfully
2015-05-12-10:06:53:155 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-10:06:53:155 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:53:155 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:53:156 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-10:06:53:156 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-10:06:53:156 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-10:06:53:156 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-10:06:53:156 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-10:06:53:157 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:53:157 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:53:157 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:53:157 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:53:157 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-10:06:53:158 - DEBUG - Log4jESLogger - [Dark Phoenix] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-10:06:53:158 - DEBUG - Log4jESLogger - [Dark Phoenix] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-10:06:53:159 - DEBUG - Log4jESLogger - [Dark Phoenix] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-10:06:53:159 - DEBUG - Log4jESLogger - [Dark Phoenix] using initial hosts [], with concurrent_connects [10]
2015-05-12-10:06:53:160 - DEBUG - Log4jESLogger - [Dark Phoenix] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-10:06:53:160 - DEBUG - Log4jESLogger - [Dark Phoenix] using minimum_master_nodes [-1]
2015-05-12-10:06:53:161 - DEBUG - Log4jESLogger - [Dark Phoenix] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:06:53:161 - DEBUG - Log4jESLogger - [Dark Phoenix] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-10:06:53:168 - DEBUG - Log4jESLogger - [Dark Phoenix] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-10:06:53:670 - DEBUG - Log4jESLogger - [Dark Phoenix] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@17d32e9b] with refresh_interval [1s]
2015-05-12-10:06:53:671 - DEBUG - Log4jESLogger - [Dark Phoenix] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@1e86a5a7] with refresh_interval [1s]
2015-05-12-10:06:53:672 - DEBUG - Log4jESLogger - [Dark Phoenix] Using refresh_interval [1s]
2015-05-12-10:06:53:672 - DEBUG - Log4jESLogger - [Dark Phoenix] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@a2ddf26] with refresh_interval [5s]
2015-05-12-10:06:53:673 - DEBUG - Log4jESLogger - [Dark Phoenix] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-10:06:53:674 - TRACE - Log4jESLogger - [Dark Phoenix] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:12700 errors:0 dropped:0 overruns:0 frame:0
	TX packets:12700 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:6026927 (5.7M)  TX bytes:6026927 (5.7M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:227345 errors:0 dropped:0 overruns:0 frame:0
	TX packets:120671 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:262167998 (250M)  TX bytes:13037037 ( 12M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:237 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:236 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-10:06:53:675 - DEBUG - Log4jESLogger - [Dark Phoenix] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@23a5818e] with refresh_interval [1s]
2015-05-12-10:06:53:678 - DEBUG - Log4jESLogger - [Dark Phoenix] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-10:06:53:678 - DEBUG - Log4jESLogger - [Dark Phoenix] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-10:06:53:680 - DEBUG - Log4jESLogger - [Dark Phoenix] using script cache with max_size [500], expire [null]
2015-05-12-10:06:53:680 - DEBUG - Log4jESLogger - [Dark Phoenix] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:53:681 - DEBUG - Log4jESLogger - [Dark Phoenix] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:53:681 - DEBUG - Log4jESLogger - [Dark Phoenix] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:53:682 - DEBUG - Log4jESLogger - [Dark Phoenix] using initial_shards [quorum], list_timeout [30s]
2015-05-12-10:06:53:686 - TRACE - Log4jESLogger - [Smythe, Alistair] [mimos][2] refresh with force[false]
2015-05-12-10:06:53:707 - DEBUG - Log4jESLogger - [Dark Phoenix] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-10:06:53:719 - DEBUG - Log4jESLogger - [Dark Phoenix] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-10:06:53:720 - DEBUG - Log4jESLogger - [Dark Phoenix] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-10:06:53:721 - DEBUG - Log4jESLogger - [Dark Phoenix] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-10:06:53:721 - DEBUG - Log4jESLogger - [Dark Phoenix] using size [-1] [-1b], expire [null]
2015-05-12-10:06:53:724 - DEBUG - Log4jESLogger - [Dark Phoenix] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-10:06:53:724 - TRACE - Log4jESLogger - [Dark Phoenix] [upgrade]: processing [global-14]
2015-05-12-10:06:53:726 - DEBUG - Log4jESLogger - [Dark Phoenix] took 2ms to load state
2015-05-12-10:06:53:727 - TRACE - Log4jESLogger - [Dark Phoenix] [find_latest_state]: processing [global-14]
2015-05-12-10:06:53:728 - DEBUG - Log4jESLogger - [Dark Phoenix] took 1ms to load started shards state
2015-05-12-10:06:53:739 - DEBUG - Log4jESLogger - [Dark Phoenix] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-10:06:53:742 - DEBUG - Log4jESLogger - [Dark Phoenix] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:53:744 - DEBUG - Log4jESLogger - [Dark Phoenix] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:53:744 - DEBUG - Log4jESLogger - [Dark Phoenix] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:53:745 - DEBUG - Log4jESLogger - [Dark Phoenix] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-10:06:53:745 - DEBUG - Log4jESLogger - [Dark Phoenix] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-10:06:53:745 - DEBUG - Log4jESLogger - [Dark Phoenix] using [cluster_concurrent_rebalance] with [2]
2015-05-12-10:06:53:750 - INFO  - Log4jESLogger - [Dark Phoenix] initialized
2015-05-12-10:06:53:750 - INFO  - Log4jESLogger - [Dark Phoenix] starting ...
2015-05-12-10:06:53:778 - DEBUG - Log4jESLogger - [Dark Phoenix] Bound to address [/0:0:0:0:0:0:0:0:9302]
2015-05-12-10:06:53:778 - INFO  - Log4jESLogger - [Dark Phoenix] bound_address {inet[/0:0:0:0:0:0:0:0:9302]}, publish_address {inet[/10.11.66.27:9302]}
2015-05-12-10:06:53:780 - TRACE - Log4jESLogger - [Dark Phoenix] waiting for 30s for the initial state to be set by the discovery
2015-05-12-10:06:53:789 - TRACE - Log4jESLogger - [Dark Phoenix] [1] sending ping request
2015-05-12-10:06:53:789 - TRACE - Log4jESLogger - [Smythe, Alistair] [1] received ping_request from [[Dark Phoenix][6n5f2M0NRnWnT8bC73zR-A][inet[/10.11.66.27:9302]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-10:06:55:290 - TRACE - Log4jESLogger - [Dark Phoenix] [1] sending ping request
2015-05-12-10:06:55:290 - TRACE - Log4jESLogger - [Smythe, Alistair] [1] received ping_request from [[Dark Phoenix][6n5f2M0NRnWnT8bC73zR-A][inet[/10.11.66.27:9302]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-10:06:56:790 - TRACE - Log4jESLogger - [Dark Phoenix] full ping responses: {none}
2015-05-12-10:06:56:790 - DEBUG - Log4jESLogger - [Dark Phoenix] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-10:06:56:791 - DEBUG - Log4jESLogger - [Dark Phoenix] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-10:06:56:791 - TRACE - Log4jESLogger - [Dark Phoenix] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Dark Phoenix][6n5f2M0NRnWnT8bC73zR-A][inet[/10.11.66.27:9302]], local, master
routing_table:
routing_nodes:
-----node_id[6n5f2M0NRnWnT8bC73zR-A][V]
---- unassigned

2015-05-12-10:06:56:792 - INFO  - Log4jESLogger - [Dark Phoenix] new_master [Dark Phoenix][6n5f2M0NRnWnT8bC73zR-A][inet[/10.11.66.27:9302]], reason: zen-disco-join (elected_as_master)
2015-05-12-10:06:56:792 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0xa392fb51, /10.11.66.27:41919 => /10.11.66.27:9302]
2015-05-12-10:06:56:793 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0xce474c2a, /10.11.66.27:41920 => /10.11.66.27:9302]
2015-05-12-10:06:56:793 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0x35d1cb3c, /10.11.66.27:41921 => /10.11.66.27:9302]
2015-05-12-10:06:56:794 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0x05671ed5, /10.11.66.27:41922 => /10.11.66.27:9302]
2015-05-12-10:06:56:794 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0xc75bc3ba, /10.11.66.27:41923 => /10.11.66.27:9302]
2015-05-12-10:06:56:797 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0x26b59599, /10.11.66.27:41924 => /10.11.66.27:9302]
2015-05-12-10:06:56:798 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0x836860cd, /10.11.66.27:41925 => /10.11.66.27:9302]
2015-05-12-10:06:56:799 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0x8ae5a7b6, /10.11.66.27:41926 => /10.11.66.27:9302]
2015-05-12-10:06:56:799 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0x9e82200f, /10.11.66.27:41927 => /10.11.66.27:9302]
2015-05-12-10:06:56:800 - TRACE - Log4jESLogger - [Dark Phoenix] channel opened: [id: 0xb504ef2e, /10.11.66.27:41928 => /10.11.66.27:9302]
2015-05-12-10:06:56:800 - DEBUG - Log4jESLogger - [Dark Phoenix] connected to node [[Dark Phoenix][6n5f2M0NRnWnT8bC73zR-A][inet[/10.11.66.27:9302]]]
2015-05-12-10:06:56:801 - DEBUG - Log4jESLogger - [Dark Phoenix] Publishing cluster state version 1
2015-05-12-10:06:56:801 - DEBUG - Log4jESLogger - [Dark Phoenix] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-10:06:56:802 - DEBUG - Log4jESLogger - [Dark Phoenix] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-10:06:56:802 - TRACE - Log4jESLogger - [Dark Phoenix] initial state set from discovery
2015-05-12-10:06:56:806 - TRACE - Log4jESLogger - [Dark Phoenix] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-10:06:56:801 - DEBUG - Log4jESLogger - [Dark Phoenix] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:56:806 - INFO  - Log4jESLogger - [Dark Phoenix] kodcu/6n5f2M0NRnWnT8bC73zR-A
2015-05-12-10:06:56:806 - DEBUG - Log4jESLogger - [Dark Phoenix] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:56:806 - TRACE - Log4jESLogger - [Dark Phoenix] performing state recovery...
2015-05-12-10:06:56:807 - TRACE - Log4jESLogger - [Dark Phoenix] performing state recovery from [6n5f2M0NRnWnT8bC73zR-A]
2015-05-12-10:06:56:808 - TRACE - Log4jESLogger - [Dark Phoenix] successful state recovery, importing cluster state...
2015-05-12-10:06:56:809 - DEBUG - Log4jESLogger - [Dark Phoenix] processing [local-gateway-elected-state]: execute
2015-05-12-10:06:56:810 - DEBUG - Log4jESLogger - [Dark Phoenix] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:06:56:811 - DEBUG - Log4jESLogger - [Dark Phoenix] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Dark Phoenix][6n5f2M0NRnWnT8bC73zR-A][inet[/10.11.66.27:9302]]] on primary allocation
2015-05-12-10:06:56:811 - DEBUG - Log4jESLogger - [Dark Phoenix] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:06:56:812 - DEBUG - Log4jESLogger - [Dark Phoenix] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Dark Phoenix][6n5f2M0NRnWnT8bC73zR-A][inet[/10.11.66.27:9302]]] on primary allocation
2015-05-12-10:06:56:812 - DEBUG - Log4jESLogger - [Dark Phoenix] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-10:06:56:812 - TRACE - Log4jESLogger - [Dark Phoenix] Start balancing cluster
2015-05-12-10:06:56:813 - TRACE - Log4jESLogger - [Dark Phoenix] Start distributing Shards
2015-05-12-10:06:56:813 - TRACE - Log4jESLogger - [Dark Phoenix] Assigned shard [[mimos][0], node[6n5f2M0NRnWnT8bC73zR-A], [P], s[INITIALIZING]] to node [6n5f2M0NRnWnT8bC73zR-A]
2015-05-12-10:06:56:813 - TRACE - Log4jESLogger - [Dark Phoenix] Assigned shard [[mimos][2], node[6n5f2M0NRnWnT8bC73zR-A], [P], s[INITIALIZING]] to node [6n5f2M0NRnWnT8bC73zR-A]
2015-05-12-10:06:56:813 - TRACE - Log4jESLogger - [Dark Phoenix] Start allocating unassigned shards
2015-05-12-10:06:56:813 - TRACE - Log4jESLogger - [Dark Phoenix] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:56:813 - TRACE - Log4jESLogger - [Dark Phoenix] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:56:813 - TRACE - Log4jESLogger - [Dark Phoenix] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:56:813 - TRACE - Log4jESLogger - [Dark Phoenix] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:56:814 - TRACE - Log4jESLogger - [Dark Phoenix] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-10:06:56:814 - TRACE - Log4jESLogger - [Dark Phoenix] Start balancing cluster
2015-05-12-10:06:56:814 - TRACE - Log4jESLogger - [Dark Phoenix] Start distributing Shards
2015-05-12-10:06:56:814 - TRACE - Log4jESLogger - [Dark Phoenix] Assigned shard [[mimos][0], node[6n5f2M0NRnWnT8bC73zR-A], [P], s[INITIALIZING]] to node [6n5f2M0NRnWnT8bC73zR-A]
2015-05-12-10:06:56:814 - TRACE - Log4jESLogger - [Dark Phoenix] Assigned shard [[mimos][2], node[6n5f2M0NRnWnT8bC73zR-A], [P], s[INITIALIZING]] to node [6n5f2M0NRnWnT8bC73zR-A]
2015-05-12-10:06:56:814 - TRACE - Log4jESLogger - [Dark Phoenix] Start allocating unassigned shards
2015-05-12-10:06:56:815 - TRACE - Log4jESLogger - [Dark Phoenix] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Dark Phoenix][6n5f2M0NRnWnT8bC73zR-A][inet[/10.11.66.27:9302]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[6n5f2M0NRnWnT8bC73zR-A], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[6n5f2M0NRnWnT8bC73zR-A], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[6n5f2M0NRnWnT8bC73zR-A][V]
--------[mimos][0], node[6n5f2M0NRnWnT8bC73zR-A], [P], s[INITIALIZING]
--------[mimos][2], node[6n5f2M0NRnWnT8bC73zR-A], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-10:06:56:816 - DEBUG - Log4jESLogger - [Dark Phoenix] Publishing cluster state version 2
2015-05-12-10:06:56:817 - DEBUG - Log4jESLogger - [Dark Phoenix] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-10:06:56:820 - DEBUG - Log4jESLogger - [Dark Phoenix] processing [reroute_rivers_node_changed]: execute
2015-05-12-10:06:56:822 - DEBUG - Log4jESLogger - [Dark Phoenix] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-10:06:56:820 - DEBUG - Log4jESLogger - [Dark Phoenix] [mimos] creating index
2015-05-12-10:06:56:822 - DEBUG - Log4jESLogger - [Dark Phoenix] creating Index [mimos], shards [5]/[1]
2015-05-12-10:06:56:827 - INFO  - Log4jESLogger - [Dark Phoenix] bound_address {inet[/0:0:0:0:0:0:0:0:9202]}, publish_address {inet[/10.11.66.27:9202]}
2015-05-12-10:06:56:827 - INFO  - Log4jESLogger - [Dark Phoenix] started
2015-05-12-11:31:29:643 - INFO  - Log4jESLogger - [Kro] version[0.90.5], pid[11741], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:31:29:669 - INFO  - Log4jESLogger - [Kro] initializing ...
2015-05-12-11:31:29:669 - DEBUG - Log4jESLogger - [Kro] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:31:29:682 - INFO  - Log4jESLogger - [Kro] loaded [], sites []
2015-05-12-11:31:29:708 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-11:31:29:711 - TRACE - Log4jESLogger - [Kro] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-11:31:29:719 - DEBUG - Log4jESLogger - [Kro] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-11:31:29:725 - TRACE - Log4jESLogger - [Kro] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:31:30:299 - TRACE - Log4jESLogger - [Kro] sigar loaded successfully
2015-05-12-11:31:30:901 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:31:30:906 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:31:30:911 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:31:30:911 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:31:30:913 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:31:30:915 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:31:30:926 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:31:30:928 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:31:30:929 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:30:930 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:30:930 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:30:931 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:30:931 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:30:932 - DEBUG - Log4jESLogger - [Kro] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:31:30:947 - DEBUG - Log4jESLogger - [Kro] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:31:30:957 - DEBUG - Log4jESLogger - [Kro] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:31:30:962 - DEBUG - Log4jESLogger - [Kro] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:31:30:964 - DEBUG - Log4jESLogger - [Kro] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:31:30:966 - DEBUG - Log4jESLogger - [Kro] using minimum_master_nodes [-1]
2015-05-12-11:31:30:968 - DEBUG - Log4jESLogger - [Kro] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:31:30:974 - DEBUG - Log4jESLogger - [Kro] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:31:31:012 - DEBUG - Log4jESLogger - [Kro] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:31:31:523 - DEBUG - Log4jESLogger - [Kro] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-11:31:31:553 - DEBUG - Log4jESLogger - [Kro] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-11:31:31:562 - DEBUG - Log4jESLogger - [Kro] Using refresh_interval [1s]
2015-05-12-11:31:31:562 - DEBUG - Log4jESLogger - [Kro] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-11:31:31:568 - DEBUG - Log4jESLogger - [Kro] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:31:31:571 - TRACE - Log4jESLogger - [Kro] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:49405 errors:0 dropped:0 overruns:0 frame:0
	TX packets:49405 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10356586 (9.9M)  TX bytes:10356586 (9.9M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:496808 errors:0 dropped:0 overruns:0 frame:0
	TX packets:251195 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:576132918 (549M)  TX bytes:26569060 ( 25M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:426 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:425 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:31:31:597 - DEBUG - Log4jESLogger - [Kro] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-11:31:31:850 - DEBUG - Log4jESLogger - [Kro] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:31:31:856 - DEBUG - Log4jESLogger - [Kro] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:31:31:864 - DEBUG - Log4jESLogger - [Kro] using script cache with max_size [500], expire [null]
2015-05-12-11:31:31:870 - DEBUG - Log4jESLogger - [Kro] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:31:31:871 - DEBUG - Log4jESLogger - [Kro] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:31:31:872 - DEBUG - Log4jESLogger - [Kro] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:31:31:878 - DEBUG - Log4jESLogger - [Kro] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:31:31:951 - DEBUG - Log4jESLogger - [Kro] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:31:32:036 - DEBUG - Log4jESLogger - [Kro] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:31:32:048 - DEBUG - Log4jESLogger - [Kro] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:31:32:052 - DEBUG - Log4jESLogger - [Kro] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:31:32:055 - DEBUG - Log4jESLogger - [Kro] using size [-1] [-1b], expire [null]
2015-05-12-11:31:32:069 - DEBUG - Log4jESLogger - [Kro] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:31:32:090 - TRACE - Log4jESLogger - [Kro] [upgrade]: processing [global-25]
2015-05-12-11:31:32:262 - DEBUG - Log4jESLogger - [Kro] took 172ms to load state
2015-05-12-11:31:32:263 - TRACE - Log4jESLogger - [Kro] [find_latest_state]: processing [global-25]
2015-05-12-11:31:32:361 - DEBUG - Log4jESLogger - [Kro] took 96ms to load started shards state
2015-05-12-11:31:32:363 - DEBUG - Log4jESLogger - [Kro] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:31:32:368 - DEBUG - Log4jESLogger - [Kro] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:31:32:369 - DEBUG - Log4jESLogger - [Kro] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:31:32:369 - DEBUG - Log4jESLogger - [Kro] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:31:32:370 - DEBUG - Log4jESLogger - [Kro] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:31:32:371 - DEBUG - Log4jESLogger - [Kro] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:31:32:371 - DEBUG - Log4jESLogger - [Kro] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:31:32:377 - INFO  - Log4jESLogger - [Kro] initialized
2015-05-12-11:31:32:378 - INFO  - Log4jESLogger - [Kro] starting ...
2015-05-12-11:31:32:404 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-11:31:32:405 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-11:31:32:472 - DEBUG - Log4jESLogger - [Kro] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-11:31:32:477 - INFO  - Log4jESLogger - [Kro] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-11:31:32:500 - TRACE - Log4jESLogger - [Kro] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:31:32:511 - TRACE - Log4jESLogger - [Kro] [1] sending ping request
2015-05-12-11:31:34:013 - TRACE - Log4jESLogger - [Kro] [1] sending ping request
2015-05-12-11:31:35:515 - TRACE - Log4jESLogger - [Kro] full ping responses: {none}
2015-05-12-11:31:35:516 - DEBUG - Log4jESLogger - [Kro] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-11:31:35:520 - DEBUG - Log4jESLogger - [Kro] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-11:31:35:521 - TRACE - Log4jESLogger - [Kro] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[kVFsXsCsRIqzUeqGeJNgCg][V]
---- unassigned

2015-05-12-11:31:35:523 - INFO  - Log4jESLogger - [Kro] new_master [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-12-11:31:35:539 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0x8d0df7ce, /10.11.66.27:50765 => /10.11.66.27:9300]
2015-05-12-11:31:35:543 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0xe7076aec, /10.11.66.27:50766 => /10.11.66.27:9300]
2015-05-12-11:31:35:547 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0x1de93803, /10.11.66.27:50767 => /10.11.66.27:9300]
2015-05-12-11:31:35:548 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0x9bc2bb9d, /10.11.66.27:50768 => /10.11.66.27:9300]
2015-05-12-11:31:35:551 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0xe63c4abd, /10.11.66.27:50769 => /10.11.66.27:9300]
2015-05-12-11:31:35:552 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0x8ce9b55c, /10.11.66.27:50770 => /10.11.66.27:9300]
2015-05-12-11:31:35:552 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0xda593e20, /10.11.66.27:50771 => /10.11.66.27:9300]
2015-05-12-11:31:35:553 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0xc45db3d3, /10.11.66.27:50772 => /10.11.66.27:9300]
2015-05-12-11:31:35:553 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0x1d001703, /10.11.66.27:50773 => /10.11.66.27:9300]
2015-05-12-11:31:35:553 - TRACE - Log4jESLogger - [Kro] channel opened: [id: 0xa2bd683a, /10.11.66.27:50774 => /10.11.66.27:9300]
2015-05-12-11:31:35:560 - DEBUG - Log4jESLogger - [Kro] connected to node [[Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]]]
2015-05-12-11:31:35:562 - DEBUG - Log4jESLogger - [Kro] Publishing cluster state version 1
2015-05-12-11:31:35:563 - DEBUG - Log4jESLogger - [Kro] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-11:31:35:567 - DEBUG - Log4jESLogger - [Kro] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:31:35:567 - DEBUG - Log4jESLogger - [Kro] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:31:35:568 - TRACE - Log4jESLogger - [Kro] initial state set from discovery
2015-05-12-11:31:35:568 - TRACE - Log4jESLogger - [Kro] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-11:31:35:568 - INFO  - Log4jESLogger - [Kro] peansData/kVFsXsCsRIqzUeqGeJNgCg
2015-05-12-11:31:35:568 - DEBUG - Log4jESLogger - [Kro] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-11:31:35:572 - TRACE - Log4jESLogger - [Kro] performing state recovery...
2015-05-12-11:31:35:573 - TRACE - Log4jESLogger - [Kro] performing state recovery from [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:585 - TRACE - Log4jESLogger - [Kro] successful state recovery, importing cluster state...
2015-05-12-11:31:35:586 - DEBUG - Log4jESLogger - [Kro] processing [local-gateway-elected-state]: execute
2015-05-12-11:31:35:606 - INFO  - Log4jESLogger - [Kro] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-12-11:31:35:606 - INFO  - Log4jESLogger - [Kro] started
2015-05-12-11:31:35:610 - DEBUG - Log4jESLogger - [Kro] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:31:35:611 - DEBUG - Log4jESLogger - [Kro] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:31:35:613 - DEBUG - Log4jESLogger - [Kro] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:31:35:613 - DEBUG - Log4jESLogger - [Kro] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:31:35:614 - DEBUG - Log4jESLogger - [Kro] [mimos][3]: throttling allocation [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[[Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-12-11:31:35:617 - TRACE - Log4jESLogger - [Kro] Start balancing cluster
2015-05-12-11:31:35:619 - TRACE - Log4jESLogger - [Kro] Start distributing Shards
2015-05-12-11:31:35:620 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:621 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:621 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:622 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:628 - TRACE - Log4jESLogger - [Kro] Start allocating unassigned shards
2015-05-12-11:31:35:630 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:35:631 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:35:631 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:35:632 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:35:632 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:35:634 - TRACE - Log4jESLogger - [Kro] Start balancing cluster
2015-05-12-11:31:35:639 - TRACE - Log4jESLogger - [Kro] Start distributing Shards
2015-05-12-11:31:35:639 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:639 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:640 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:648 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:35:648 - TRACE - Log4jESLogger - [Kro] Start allocating unassigned shards
2015-05-12-11:31:35:662 - TRACE - Log4jESLogger - [Kro] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[kVFsXsCsRIqzUeqGeJNgCg][V]
--------[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:31:35:663 - DEBUG - Log4jESLogger - [Kro] Publishing cluster state version 2
2015-05-12-11:31:35:664 - DEBUG - Log4jESLogger - [Kro] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-11:31:35:665 - DEBUG - Log4jESLogger - [Kro] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:31:35:666 - DEBUG - Log4jESLogger - [Kro] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:31:35:678 - DEBUG - Log4jESLogger - [Kro] [mimos] creating index
2015-05-12-11:31:35:678 - DEBUG - Log4jESLogger - [Kro] creating Index [mimos], shards [5]/[1]
2015-05-12-11:31:35:967 - TRACE - Log4jESLogger - [Kro] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [kVFsXsCsRIqzUeqGeJNgCg], scheduling a retry.
2015-05-12-11:31:36:096 - DEBUG - Log4jESLogger - [Kro] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-11:31:36:097 - DEBUG - Log4jESLogger - [Kro] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-11:31:36:113 - DEBUG - Log4jESLogger - [Kro] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-11:31:36:194 - DEBUG - Log4jESLogger - [Kro] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-11:31:36:266 - DEBUG - Log4jESLogger - [Kro] Sending mapping created for index mimos, type Programmer
2015-05-12-11:31:36:269 - DEBUG - Log4jESLogger - [Kro] [mimos][0] creating shard
2015-05-12-11:31:36:269 - DEBUG - Log4jESLogger - [Kro] [mimos] creating shard_id [0]
2015-05-12-11:31:36:422 - DEBUG - Log4jESLogger - [Kro] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-11:31:36:428 - DEBUG - Log4jESLogger - [Kro] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:31:36:429 - DEBUG - Log4jESLogger - [Kro] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:31:36:435 - DEBUG - Log4jESLogger - [Kro] [mimos][0] state: [CREATED]
2015-05-12-11:31:36:436 - DEBUG - Log4jESLogger - [Kro] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:31:36:445 - DEBUG - Log4jESLogger - [Kro] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:31:36:447 - DEBUG - Log4jESLogger - [Kro] [mimos][1] creating shard
2015-05-12-11:31:36:447 - DEBUG - Log4jESLogger - [Kro] [mimos][0] starting recovery from local ...
2015-05-12-11:31:36:447 - DEBUG - Log4jESLogger - [Kro] [mimos] creating shard_id [1]
2015-05-12-11:31:36:460 - DEBUG - Log4jESLogger - [Kro] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-11:31:36:462 - DEBUG - Log4jESLogger - [Kro] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:31:36:462 - DEBUG - Log4jESLogger - [Kro] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:31:36:463 - DEBUG - Log4jESLogger - [Kro] [mimos][1] state: [CREATED]
2015-05-12-11:31:36:464 - DEBUG - Log4jESLogger - [Kro] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:31:36:465 - DEBUG - Log4jESLogger - [Kro] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:31:36:465 - DEBUG - Log4jESLogger - [Kro] [mimos][2] creating shard
2015-05-12-11:31:36:465 - DEBUG - Log4jESLogger - [Kro] [mimos] creating shard_id [2]
2015-05-12-11:31:36:465 - DEBUG - Log4jESLogger - [Kro] [mimos][1] starting recovery from local ...
2015-05-12-11:31:36:483 - TRACE - Log4jESLogger - [Kro] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-11:31:36:483 - TRACE - Log4jESLogger - [Kro] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-11:31:36:484 - DEBUG - Log4jESLogger - [Kro] [mimos][0] starting engine
2015-05-12-11:31:36:485 - DEBUG - Log4jESLogger - [Kro] [mimos][1] starting engine
2015-05-12-11:31:36:502 - DEBUG - Log4jESLogger - [Kro] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-11:31:36:503 - DEBUG - Log4jESLogger - [Kro] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:31:36:503 - DEBUG - Log4jESLogger - [Kro] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:31:36:504 - DEBUG - Log4jESLogger - [Kro] [mimos][2] state: [CREATED]
2015-05-12-11:31:36:505 - DEBUG - Log4jESLogger - [Kro] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:31:36:506 - DEBUG - Log4jESLogger - [Kro] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:31:36:507 - DEBUG - Log4jESLogger - [Kro] [mimos][4] creating shard
2015-05-12-11:31:36:508 - DEBUG - Log4jESLogger - [Kro] [mimos] creating shard_id [4]
2015-05-12-11:31:36:514 - DEBUG - Log4jESLogger - [Kro] [mimos][2] starting recovery from local ...
2015-05-12-11:31:36:524 - DEBUG - Log4jESLogger - [Kro] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-11:31:36:528 - DEBUG - Log4jESLogger - [Kro] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:31:36:528 - DEBUG - Log4jESLogger - [Kro] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:31:36:529 - DEBUG - Log4jESLogger - [Kro] [mimos][4] state: [CREATED]
2015-05-12-11:31:36:530 - DEBUG - Log4jESLogger - [Kro] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:31:36:538 - TRACE - Log4jESLogger - [Kro] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-11:31:36:540 - DEBUG - Log4jESLogger - [Kro] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:31:36:541 - DEBUG - Log4jESLogger - [Kro] [mimos][2] starting engine
2015-05-12-11:31:36:564 - TRACE - Log4jESLogger - [Kro] [_global] writing state, reason [changed]
2015-05-12-11:31:36:568 - DEBUG - Log4jESLogger - [Kro] [mimos][4] starting recovery from local ...
2015-05-12-11:31:36:585 - TRACE - Log4jESLogger - [Kro] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-11:31:36:624 - TRACE - Log4jESLogger - [Kro] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:31:36:624 - TRACE - Log4jESLogger - [Kro] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:31:36:627 - TRACE - Log4jESLogger - [Kro] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:31:36:628 - TRACE - Log4jESLogger - [Kro] [mimos][1] warming took [1.2ms]
2015-05-12-11:31:36:631 - DEBUG - Log4jESLogger - [Kro] [mimos][4] starting engine
2015-05-12-11:31:36:636 - TRACE - Log4jESLogger - [Kro] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:31:36:636 - DEBUG - Log4jESLogger - [Kro] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:31:36:642 - TRACE - Log4jESLogger - [Kro] [mimos][4] warming took [5.3ms]
2015-05-12-11:31:36:643 - DEBUG - Log4jESLogger - [Kro] [mimos][1] scheduling refresher every 1s
2015-05-12-11:31:36:644 - DEBUG - Log4jESLogger - [Kro] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:31:36:644 - DEBUG - Log4jESLogger - [Kro] [mimos][4] scheduling refresher every 1s
2015-05-12-11:31:36:645 - DEBUG - Log4jESLogger - [Kro] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-11:31:36:645 - TRACE - Log4jESLogger - [Kro] [mimos][4] refresh with force[true]
2015-05-12-11:31:36:636 - TRACE - Log4jESLogger - [Kro] [mimos][0] warming took [8.6ms]
2015-05-12-11:31:36:646 - DEBUG - Log4jESLogger - [Kro] [mimos][4] recovery completed from [local], took [78ms]
2015-05-12-11:31:36:647 - DEBUG - Log4jESLogger - [Kro] sending shard started for [mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:647 - DEBUG - Log4jESLogger - [Kro] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:31:36:656 - DEBUG - Log4jESLogger - [Kro] [mimos][0] scheduling refresher every 1s
2015-05-12-11:31:36:645 - TRACE - Log4jESLogger - [Kro] [mimos][2] warming took [19.5ms]
2015-05-12-11:31:36:658 - DEBUG - Log4jESLogger - [Kro] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:31:36:658 - DEBUG - Log4jESLogger - [Kro] [mimos][2] scheduling refresher every 1s
2015-05-12-11:31:36:658 - DEBUG - Log4jESLogger - [Kro] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-11:31:36:658 - TRACE - Log4jESLogger - [Kro] [mimos][2] refresh with force[true]
2015-05-12-11:31:36:659 - DEBUG - Log4jESLogger - [Kro] [mimos][2] recovery completed from [local], took [145ms]
2015-05-12-11:31:36:659 - DEBUG - Log4jESLogger - [Kro] sending shard started for [mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:659 - DEBUG - Log4jESLogger - [Kro] received shard started for [mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:644 - DEBUG - Log4jESLogger - [Kro] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-11:31:36:657 - DEBUG - Log4jESLogger - [Kro] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-11:31:36:651 - INFO  - Log4jESLogger - [Kro] recovered [1] indices into cluster_state
2015-05-12-11:31:36:661 - DEBUG - Log4jESLogger - [Kro] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-11:31:36:648 - DEBUG - Log4jESLogger - [Kro] received shard started for [mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:661 - TRACE - Log4jESLogger - [Kro] [mimos][0] refresh with force[true]
2015-05-12-11:31:36:660 - TRACE - Log4jESLogger - [Kro] [mimos][1] refresh with force[true]
2015-05-12-11:31:36:662 - TRACE - Log4jESLogger - [Kro] listener to cluster state added, trying to index again
2015-05-12-11:31:36:662 - DEBUG - Log4jESLogger - [Kro] [mimos][0] recovery completed from [local], took [215ms]
2015-05-12-11:31:36:662 - DEBUG - Log4jESLogger - [Kro] [mimos][1] recovery completed from [local], took [197ms]
2015-05-12-11:31:36:663 - DEBUG - Log4jESLogger - [Kro] sending shard started for [mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:663 - DEBUG - Log4jESLogger - [Kro] received shard started for [mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:663 - DEBUG - Log4jESLogger - [Kro] sending shard started for [mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:662 - TRACE - Log4jESLogger - [Kro] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [kVFsXsCsRIqzUeqGeJNgCg], scheduling a retry.
2015-05-12-11:31:36:663 - TRACE - Log4jESLogger - [Kro] retry scheduling ignored as it as we already have a listener in place
2015-05-12-11:31:36:664 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:31:36:664 - DEBUG - Log4jESLogger - [Kro] applying started shards [[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], [mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], [mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-11:31:36:665 - DEBUG - Log4jESLogger - [Kro] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:31:36:665 - TRACE - Log4jESLogger - [Kro] Start balancing cluster
2015-05-12-11:31:36:665 - TRACE - Log4jESLogger - [Kro] Start distributing Shards
2015-05-12-11:31:36:665 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:665 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:666 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:666 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:666 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:666 - TRACE - Log4jESLogger - [Kro] Start allocating unassigned shards
2015-05-12-11:31:36:666 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:666 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:667 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:667 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:667 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:667 - TRACE - Log4jESLogger - [Kro] Start balancing cluster
2015-05-12-11:31:36:667 - TRACE - Log4jESLogger - [Kro] Start distributing Shards
2015-05-12-11:31:36:667 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:668 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:668 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:668 - DEBUG - Log4jESLogger - [Kro] received shard started for [mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:668 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:669 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:669 - TRACE - Log4jESLogger - [Kro] Start allocating unassigned shards
2015-05-12-11:31:36:670 - TRACE - Log4jESLogger - [Kro] cluster state updated:
version [3], source [shard-started ([mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[kVFsXsCsRIqzUeqGeJNgCg][V]
--------[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]
--------[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:31:36:670 - DEBUG - Log4jESLogger - [Kro] Publishing cluster state version 3
2015-05-12-11:31:36:670 - DEBUG - Log4jESLogger - [Kro] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-11:31:36:670 - DEBUG - Log4jESLogger - [Kro] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:31:36:671 - DEBUG - Log4jESLogger - [Kro] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:31:36:671 - TRACE - Log4jESLogger - [Kro] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-11:31:36:672 - DEBUG - Log4jESLogger - [Kro] sending shard started for [mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [master [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:31:36:673 - DEBUG - Log4jESLogger - [Kro] received shard started for [mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [master [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:31:36:674 - DEBUG - Log4jESLogger - [Kro] [mimos][3] creating shard
2015-05-12-11:31:36:675 - DEBUG - Log4jESLogger - [Kro] [mimos] creating shard_id [3]
2015-05-12-11:31:36:686 - DEBUG - Log4jESLogger - [Kro] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-11:31:36:687 - DEBUG - Log4jESLogger - [Kro] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:31:36:688 - DEBUG - Log4jESLogger - [Kro] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:31:36:689 - DEBUG - Log4jESLogger - [Kro] [mimos][3] state: [CREATED]
2015-05-12-11:31:36:691 - DEBUG - Log4jESLogger - [Kro] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:31:36:692 - DEBUG - Log4jESLogger - [Kro] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:31:36:693 - DEBUG - Log4jESLogger - [Kro] [mimos][3] starting recovery from local ...
2015-05-12-11:31:36:695 - TRACE - Log4jESLogger - [Kro] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-11:31:36:696 - DEBUG - Log4jESLogger - [Kro] [mimos][3] starting engine
2015-05-12-11:31:36:699 - TRACE - Log4jESLogger - [Kro] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:31:36:700 - TRACE - Log4jESLogger - [Kro] [mimos][3] warming took [170.9micros]
2015-05-12-11:31:36:704 - TRACE - Log4jESLogger - [Kro] cluster changed (version 3), trying to index again
2015-05-12-11:31:36:705 - DEBUG - Log4jESLogger - [Kro] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:31:36:705 - DEBUG - Log4jESLogger - [Kro] [mimos][3] scheduling refresher every 1s
2015-05-12-11:31:36:706 - DEBUG - Log4jESLogger - [Kro] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-11:31:36:706 - TRACE - Log4jESLogger - [Kro] [mimos][3] refresh with force[true]
2015-05-12-11:31:36:706 - DEBUG - Log4jESLogger - [Kro] [mimos][3] recovery completed from [local], took [13ms]
2015-05-12-11:31:36:706 - DEBUG - Log4jESLogger - [Kro] sending shard started for [mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:706 - DEBUG - Log4jESLogger - [Kro] received shard started for [mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:31:36:713 - TRACE - Log4jESLogger - [Kro] [mimos][4] writing shard state, reason [version changed from [46] to [48]]
2015-05-12-11:31:36:740 - TRACE - Log4jESLogger - [Kro] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-11:31:36:765 - TRACE - Log4jESLogger - [Kro] [mimos][2] writing shard state, reason [version changed from [34] to [36]]
2015-05-12-11:31:36:773 - DEBUG - Log4jESLogger - [Kro] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-11:31:36:795 - TRACE - Log4jESLogger - [Kro] [mimos][2] delete [Programmer#1]
2015-05-12-11:31:36:804 - INFO  - Log4jESLogger - [Moonhunter] version[0.90.5], pid[11741], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:31:36:804 - INFO  - Log4jESLogger - [Moonhunter] initializing ...
2015-05-12-11:31:36:804 - DEBUG - Log4jESLogger - [Moonhunter] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:31:36:805 - INFO  - Log4jESLogger - [Moonhunter] loaded [], sites []
2015-05-12-11:31:36:805 - TRACE - Log4jESLogger - [Moonhunter] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-11:31:36:807 - DEBUG - Log4jESLogger - [Moonhunter] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-11:31:36:807 - TRACE - Log4jESLogger - [Moonhunter] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:31:36:807 - TRACE - Log4jESLogger - [Kro] [mimos][1] writing shard state, reason [version changed from [30] to [32]]
2015-05-12-11:31:36:841 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-11:31:36:842 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:31:36:842 - DEBUG - Log4jESLogger - [Kro] applying started shards [[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], [mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING], [mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-11:31:36:842 - TRACE - Log4jESLogger - [Kro] Start balancing cluster
2015-05-12-11:31:36:843 - TRACE - Log4jESLogger - [Kro] Start distributing Shards
2015-05-12-11:31:36:843 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:843 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:843 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:843 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:844 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:844 - TRACE - Log4jESLogger - [Kro] Start allocating unassigned shards
2015-05-12-11:31:36:844 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:844 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:845 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:869 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:870 - TRACE - Log4jESLogger - [Kro] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:36:870 - TRACE - Log4jESLogger - [Kro] Start balancing cluster
2015-05-12-11:31:36:871 - TRACE - Log4jESLogger - [Kro] Start distributing Shards
2015-05-12-11:31:36:871 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:871 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:871 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:871 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:871 - TRACE - Log4jESLogger - [Kro] Assigned shard [[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]] to node [kVFsXsCsRIqzUeqGeJNgCg]
2015-05-12-11:31:36:871 - TRACE - Log4jESLogger - [Kro] Start allocating unassigned shards
2015-05-12-11:31:36:872 - TRACE - Log4jESLogger - [Kro] cluster state updated:
version [4], source [shard-started ([mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[kVFsXsCsRIqzUeqGeJNgCg][V]
--------[mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][2], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
--------[mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:31:36:873 - DEBUG - Log4jESLogger - [Kro] Publishing cluster state version 4
2015-05-12-11:31:36:873 - DEBUG - Log4jESLogger - [Kro] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-11:31:36:873 - DEBUG - Log4jESLogger - [Kro] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:31:36:883 - DEBUG - Log4jESLogger - [Kro] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:31:36:886 - TRACE - Log4jESLogger - [Kro] [mimos][0] writing shard state, reason [version changed from [44] to [46]]
2015-05-12-11:31:36:918 - TRACE - Log4jESLogger - [Moonhunter] sigar loaded successfully
2015-05-12-11:31:36:925 - TRACE - Log4jESLogger - [Kro] [mimos][3] writing shard state, reason [version changed from [44] to [46]]
2015-05-12-11:31:37:126 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][4], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-11:31:37:127 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:31:37:127 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][1], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:31:37:127 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:31:37:127 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:31:37:127 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [master [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-11:31:37:127 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][0], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [master [Kro][kVFsXsCsRIqzUeqGeJNgCg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-11:31:37:127 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:31:37:127 - DEBUG - Log4jESLogger - [Kro] processing [shard-started ([mimos][3], node[kVFsXsCsRIqzUeqGeJNgCg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:31:37:128 - DEBUG - Log4jESLogger - [Kro] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-11:31:37:130 - DEBUG - Log4jESLogger - [Kro] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-11:31:37:170 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:31:37:171 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:31:37:171 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:31:37:171 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:31:37:172 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:31:37:172 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:31:37:172 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:31:37:173 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:31:37:173 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:37:173 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:37:174 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:37:174 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:37:174 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:31:37:175 - DEBUG - Log4jESLogger - [Moonhunter] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:31:37:176 - DEBUG - Log4jESLogger - [Moonhunter] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:31:37:177 - DEBUG - Log4jESLogger - [Moonhunter] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:31:37:178 - DEBUG - Log4jESLogger - [Moonhunter] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:31:37:179 - DEBUG - Log4jESLogger - [Moonhunter] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:31:37:179 - DEBUG - Log4jESLogger - [Moonhunter] using minimum_master_nodes [-1]
2015-05-12-11:31:37:180 - DEBUG - Log4jESLogger - [Moonhunter] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:31:37:180 - DEBUG - Log4jESLogger - [Moonhunter] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:31:37:186 - DEBUG - Log4jESLogger - [Moonhunter] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:31:37:659 - TRACE - Log4jESLogger - [Kro] [mimos][2] refresh with force[false]
2015-05-12-11:31:37:689 - DEBUG - Log4jESLogger - [Moonhunter] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@17d32e9b] with refresh_interval [1s]
2015-05-12-11:31:37:691 - DEBUG - Log4jESLogger - [Moonhunter] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@1e86a5a7] with refresh_interval [1s]
2015-05-12-11:31:37:693 - DEBUG - Log4jESLogger - [Moonhunter] Using refresh_interval [1s]
2015-05-12-11:31:37:694 - DEBUG - Log4jESLogger - [Moonhunter] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4715ae33] with refresh_interval [5s]
2015-05-12-11:31:37:695 - DEBUG - Log4jESLogger - [Moonhunter] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:31:37:696 - TRACE - Log4jESLogger - [Moonhunter] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:49435 errors:0 dropped:0 overruns:0 frame:0
	TX packets:49435 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10358306 (9.9M)  TX bytes:10358306 (9.9M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:496883 errors:0 dropped:0 overruns:0 frame:0
	TX packets:251221 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:576140446 (549M)  TX bytes:26571335 ( 25M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:426 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:425 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:31:37:698 - DEBUG - Log4jESLogger - [Moonhunter] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@108a46d6] with refresh_interval [1s]
2015-05-12-11:31:37:700 - DEBUG - Log4jESLogger - [Moonhunter] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:31:37:701 - DEBUG - Log4jESLogger - [Moonhunter] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:31:37:702 - DEBUG - Log4jESLogger - [Moonhunter] using script cache with max_size [500], expire [null]
2015-05-12-11:31:37:703 - DEBUG - Log4jESLogger - [Moonhunter] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:31:37:704 - DEBUG - Log4jESLogger - [Moonhunter] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:31:37:704 - DEBUG - Log4jESLogger - [Moonhunter] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:31:37:705 - DEBUG - Log4jESLogger - [Moonhunter] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:31:37:712 - DEBUG - Log4jESLogger - [Moonhunter] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:31:37:721 - DEBUG - Log4jESLogger - [Moonhunter] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:31:37:723 - DEBUG - Log4jESLogger - [Moonhunter] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:31:37:723 - DEBUG - Log4jESLogger - [Moonhunter] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:31:37:724 - DEBUG - Log4jESLogger - [Moonhunter] using size [-1] [-1b], expire [null]
2015-05-12-11:31:37:726 - DEBUG - Log4jESLogger - [Moonhunter] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:31:37:744 - TRACE - Log4jESLogger - [Moonhunter] [upgrade]: processing [global-14]
2015-05-12-11:31:37:804 - DEBUG - Log4jESLogger - [Moonhunter] took 60ms to load state
2015-05-12-11:31:37:805 - TRACE - Log4jESLogger - [Moonhunter] [find_latest_state]: processing [global-14]
2015-05-12-11:31:37:855 - DEBUG - Log4jESLogger - [Moonhunter] took 50ms to load started shards state
2015-05-12-11:31:37:856 - DEBUG - Log4jESLogger - [Moonhunter] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:31:37:858 - DEBUG - Log4jESLogger - [Moonhunter] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:31:37:858 - DEBUG - Log4jESLogger - [Moonhunter] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:31:37:859 - DEBUG - Log4jESLogger - [Moonhunter] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:31:37:859 - DEBUG - Log4jESLogger - [Moonhunter] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:31:37:860 - DEBUG - Log4jESLogger - [Moonhunter] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:31:37:860 - DEBUG - Log4jESLogger - [Moonhunter] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:31:37:863 - INFO  - Log4jESLogger - [Moonhunter] initialized
2015-05-12-11:31:37:863 - INFO  - Log4jESLogger - [Moonhunter] starting ...
2015-05-12-11:31:37:885 - DEBUG - Log4jESLogger - [Moonhunter] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-11:31:37:886 - INFO  - Log4jESLogger - [Moonhunter] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-11:31:37:888 - TRACE - Log4jESLogger - [Moonhunter] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:31:37:890 - TRACE - Log4jESLogger - [Moonhunter] [1] sending ping request
2015-05-12-11:31:37:890 - TRACE - Log4jESLogger - [Kro] [1] received ping_request from [[Moonhunter][tIvHLCWFQoyFQC-zgysT7A][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-11:31:39:391 - TRACE - Log4jESLogger - [Kro] [1] received ping_request from [[Moonhunter][tIvHLCWFQoyFQC-zgysT7A][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-11:31:39:391 - TRACE - Log4jESLogger - [Moonhunter] [1] sending ping request
2015-05-12-11:31:40:892 - TRACE - Log4jESLogger - [Moonhunter] full ping responses: {none}
2015-05-12-11:31:40:893 - DEBUG - Log4jESLogger - [Moonhunter] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-11:31:40:893 - DEBUG - Log4jESLogger - [Moonhunter] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-11:31:40:893 - TRACE - Log4jESLogger - [Moonhunter] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Moonhunter][tIvHLCWFQoyFQC-zgysT7A][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[tIvHLCWFQoyFQC-zgysT7A][V]
---- unassigned

2015-05-12-11:31:40:893 - INFO  - Log4jESLogger - [Moonhunter] new_master [Moonhunter][tIvHLCWFQoyFQC-zgysT7A][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-11:31:40:896 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0xa588525b, /10.11.66.27:52239 => /10.11.66.27:9301]
2015-05-12-11:31:40:898 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0x8e0e4f99, /10.11.66.27:52240 => /10.11.66.27:9301]
2015-05-12-11:31:40:898 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0xdc0bfd38, /10.11.66.27:52241 => /10.11.66.27:9301]
2015-05-12-11:31:40:900 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0x1392005f, /10.11.66.27:52242 => /10.11.66.27:9301]
2015-05-12-11:31:40:900 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0x9addd9ce, /10.11.66.27:52243 => /10.11.66.27:9301]
2015-05-12-11:31:40:901 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0xeb65842e, /10.11.66.27:52244 => /10.11.66.27:9301]
2015-05-12-11:31:40:901 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0xa005d02c, /10.11.66.27:52245 => /10.11.66.27:9301]
2015-05-12-11:31:40:902 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0xb555360e, /10.11.66.27:52246 => /10.11.66.27:9301]
2015-05-12-11:31:40:902 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0x45ee9059, /10.11.66.27:52247 => /10.11.66.27:9301]
2015-05-12-11:31:40:903 - TRACE - Log4jESLogger - [Moonhunter] channel opened: [id: 0x6f45df9c, /10.11.66.27:52248 => /10.11.66.27:9301]
2015-05-12-11:31:40:906 - DEBUG - Log4jESLogger - [Moonhunter] connected to node [[Moonhunter][tIvHLCWFQoyFQC-zgysT7A][inet[/10.11.66.27:9301]]]
2015-05-12-11:31:40:906 - DEBUG - Log4jESLogger - [Moonhunter] Publishing cluster state version 1
2015-05-12-11:31:40:906 - DEBUG - Log4jESLogger - [Moonhunter] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-11:31:40:907 - DEBUG - Log4jESLogger - [Moonhunter] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:31:40:907 - TRACE - Log4jESLogger - [Moonhunter] initial state set from discovery
2015-05-12-11:31:40:907 - TRACE - Log4jESLogger - [Moonhunter] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-11:31:40:907 - DEBUG - Log4jESLogger - [Moonhunter] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:31:40:907 - DEBUG - Log4jESLogger - [Moonhunter] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-11:31:40:907 - INFO  - Log4jESLogger - [Moonhunter] kodcu/tIvHLCWFQoyFQC-zgysT7A
2015-05-12-11:31:40:908 - TRACE - Log4jESLogger - [Moonhunter] performing state recovery...
2015-05-12-11:31:40:908 - TRACE - Log4jESLogger - [Moonhunter] performing state recovery from [tIvHLCWFQoyFQC-zgysT7A]
2015-05-12-11:31:40:909 - TRACE - Log4jESLogger - [Moonhunter] successful state recovery, importing cluster state...
2015-05-12-11:31:40:910 - DEBUG - Log4jESLogger - [Moonhunter] processing [local-gateway-elected-state]: execute
2015-05-12-11:31:40:912 - DEBUG - Log4jESLogger - [Moonhunter] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Moonhunter][tIvHLCWFQoyFQC-zgysT7A][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-11:31:40:913 - DEBUG - Log4jESLogger - [Moonhunter] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:31:40:913 - DEBUG - Log4jESLogger - [Moonhunter] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:31:40:917 - DEBUG - Log4jESLogger - [Moonhunter] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Moonhunter][tIvHLCWFQoyFQC-zgysT7A][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-11:31:40:920 - DEBUG - Log4jESLogger - [Moonhunter] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:31:40:920 - TRACE - Log4jESLogger - [Moonhunter] Start balancing cluster
2015-05-12-11:31:40:920 - TRACE - Log4jESLogger - [Moonhunter] Start distributing Shards
2015-05-12-11:31:40:921 - TRACE - Log4jESLogger - [Moonhunter] Assigned shard [[mimos][0], node[tIvHLCWFQoyFQC-zgysT7A], [P], s[INITIALIZING]] to node [tIvHLCWFQoyFQC-zgysT7A]
2015-05-12-11:31:40:921 - TRACE - Log4jESLogger - [Moonhunter] Assigned shard [[mimos][2], node[tIvHLCWFQoyFQC-zgysT7A], [P], s[INITIALIZING]] to node [tIvHLCWFQoyFQC-zgysT7A]
2015-05-12-11:31:40:921 - TRACE - Log4jESLogger - [Moonhunter] Start allocating unassigned shards
2015-05-12-11:31:40:921 - TRACE - Log4jESLogger - [Moonhunter] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:40:921 - TRACE - Log4jESLogger - [Moonhunter] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:40:921 - TRACE - Log4jESLogger - [Moonhunter] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:40:921 - TRACE - Log4jESLogger - [Moonhunter] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:40:921 - TRACE - Log4jESLogger - [Moonhunter] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:31:40:922 - TRACE - Log4jESLogger - [Moonhunter] Start balancing cluster
2015-05-12-11:31:40:922 - TRACE - Log4jESLogger - [Moonhunter] Start distributing Shards
2015-05-12-11:31:40:922 - TRACE - Log4jESLogger - [Moonhunter] Assigned shard [[mimos][0], node[tIvHLCWFQoyFQC-zgysT7A], [P], s[INITIALIZING]] to node [tIvHLCWFQoyFQC-zgysT7A]
2015-05-12-11:31:40:922 - TRACE - Log4jESLogger - [Moonhunter] Assigned shard [[mimos][2], node[tIvHLCWFQoyFQC-zgysT7A], [P], s[INITIALIZING]] to node [tIvHLCWFQoyFQC-zgysT7A]
2015-05-12-11:31:40:922 - TRACE - Log4jESLogger - [Moonhunter] Start allocating unassigned shards
2015-05-12-11:31:40:923 - TRACE - Log4jESLogger - [Moonhunter] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Moonhunter][tIvHLCWFQoyFQC-zgysT7A][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[tIvHLCWFQoyFQC-zgysT7A], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[tIvHLCWFQoyFQC-zgysT7A], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[tIvHLCWFQoyFQC-zgysT7A][V]
--------[mimos][0], node[tIvHLCWFQoyFQC-zgysT7A], [P], s[INITIALIZING]
--------[mimos][2], node[tIvHLCWFQoyFQC-zgysT7A], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:31:40:923 - DEBUG - Log4jESLogger - [Moonhunter] Publishing cluster state version 2
2015-05-12-11:31:40:923 - DEBUG - Log4jESLogger - [Moonhunter] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-11:31:40:923 - DEBUG - Log4jESLogger - [Moonhunter] [mimos] creating index
2015-05-12-11:31:40:923 - DEBUG - Log4jESLogger - [Moonhunter] creating Index [mimos], shards [5]/[1]
2015-05-12-11:31:40:923 - DEBUG - Log4jESLogger - [Moonhunter] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:31:40:931 - DEBUG - Log4jESLogger - [Moonhunter] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:31:40:938 - INFO  - Log4jESLogger - [Moonhunter] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-11:31:40:939 - INFO  - Log4jESLogger - [Moonhunter] started
2015-05-12-11:36:26:739 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] version[0.90.5], pid[12040], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:36:26:742 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] initializing ...
2015-05-12-11:36:26:742 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:36:26:754 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] loaded [], sites []
2015-05-12-11:36:26:782 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-11:36:26:786 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-11:36:26:795 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-11:36:26:802 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:36:27:395 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] sigar loaded successfully
2015-05-12-11:36:28:031 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:36:28:038 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:36:28:043 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:36:28:044 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:36:28:046 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:36:28:047 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:36:28:059 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:36:28:061 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:36:28:063 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:28:064 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:28:065 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:28:065 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:28:066 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:28:066 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:36:28:087 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:36:28:099 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:36:28:104 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:36:28:106 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:36:28:108 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using minimum_master_nodes [-1]
2015-05-12-11:36:28:110 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:36:28:115 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:36:28:164 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:36:28:675 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-11:36:28:680 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-11:36:28:688 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Using refresh_interval [1s]
2015-05-12-11:36:28:688 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-11:36:28:693 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:36:28:697 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:49606 errors:0 dropped:0 overruns:0 frame:0
	TX packets:49606 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10372999 (9.9M)  TX bytes:10372999 (9.9M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:509213 errors:0 dropped:0 overruns:0 frame:0
	TX packets:257783 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:589619284 (562M)  TX bytes:27209216 ( 26M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:435 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:434 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:36:28:703 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-11:36:28:984 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:36:28:991 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:36:29:000 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using script cache with max_size [500], expire [null]
2015-05-12-11:36:29:006 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:36:29:007 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:36:29:009 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:36:29:014 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:36:29:090 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:36:29:182 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:36:29:198 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:36:29:201 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:36:29:205 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using size [-1] [-1b], expire [null]
2015-05-12-11:36:29:227 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:36:29:237 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [upgrade]: processing [global-26]
2015-05-12-11:36:29:379 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] took 142ms to load state
2015-05-12-11:36:29:380 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [find_latest_state]: processing [global-26]
2015-05-12-11:36:29:385 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] took 5ms to load started shards state
2015-05-12-11:36:29:387 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:36:29:392 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:36:29:392 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:36:29:393 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:36:29:394 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:36:29:394 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:36:29:395 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:36:29:400 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] initialized
2015-05-12-11:36:29:401 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] starting ...
2015-05-12-11:36:29:425 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-11:36:29:425 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-11:36:29:503 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-11:36:29:509 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-11:36:29:533 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:36:29:545 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [1] sending ping request
2015-05-12-11:36:31:048 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [1] sending ping request
2015-05-12-11:36:32:551 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] full ping responses: {none}
2015-05-12-11:36:32:551 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-11:36:32:555 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-11:36:32:557 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[z4d5K4e9T2eVTJTAy-6ivA][V]
---- unassigned

2015-05-12-11:36:32:559 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] new_master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-12-11:36:32:575 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0x8fc1923a, /10.11.66.27:50811 => /10.11.66.27:9300]
2015-05-12-11:36:32:585 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0x55fd06ad, /10.11.66.27:50812 => /10.11.66.27:9300]
2015-05-12-11:36:32:592 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0xcfc291ad, /10.11.66.27:50813 => /10.11.66.27:9300]
2015-05-12-11:36:32:593 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0x7245dd54, /10.11.66.27:50814 => /10.11.66.27:9300]
2015-05-12-11:36:32:594 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0xa94d9061, /10.11.66.27:50815 => /10.11.66.27:9300]
2015-05-12-11:36:32:595 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0x15e7485b, /10.11.66.27:50816 => /10.11.66.27:9300]
2015-05-12-11:36:32:595 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0xb452365a, /10.11.66.27:50817 => /10.11.66.27:9300]
2015-05-12-11:36:32:596 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0xf2858784, /10.11.66.27:50818 => /10.11.66.27:9300]
2015-05-12-11:36:32:596 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0x4068c490, /10.11.66.27:50819 => /10.11.66.27:9300]
2015-05-12-11:36:32:597 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] channel opened: [id: 0x85fa7479, /10.11.66.27:50820 => /10.11.66.27:9300]
2015-05-12-11:36:32:610 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] connected to node [[Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]]]
2015-05-12-11:36:32:611 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Publishing cluster state version 1
2015-05-12-11:36:32:612 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-11:36:32:617 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:36:32:617 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] initial state set from discovery
2015-05-12-11:36:32:617 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:36:32:617 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-11:36:32:618 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] peansData/z4d5K4e9T2eVTJTAy-6ivA
2015-05-12-11:36:32:619 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] performing state recovery...
2015-05-12-11:36:32:620 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] performing state recovery from [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:622 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-11:36:32:632 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] successful state recovery, importing cluster state...
2015-05-12-11:36:32:634 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [local-gateway-elected-state]: execute
2015-05-12-11:36:32:653 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-12-11:36:32:654 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] started
2015-05-12-11:36:32:659 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:36:32:661 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:36:32:664 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:36:32:665 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:36:32:667 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2]: throttling allocation [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[[Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-12-11:36:32:673 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start balancing cluster
2015-05-12-11:36:32:676 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start distributing Shards
2015-05-12-11:36:32:677 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:678 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:678 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:679 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:694 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start allocating unassigned shards
2015-05-12-11:36:32:697 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:32:699 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:32:700 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:32:707 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:32:709 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:32:711 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start balancing cluster
2015-05-12-11:36:32:713 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start distributing Shards
2015-05-12-11:36:32:713 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:713 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:713 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:714 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:32:714 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start allocating unassigned shards
2015-05-12-11:36:32:717 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[null], [P], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[z4d5K4e9T2eVTJTAy-6ivA][V]
--------[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [P], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:36:32:718 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Publishing cluster state version 2
2015-05-12-11:36:32:721 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-11:36:32:723 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:36:32:724 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:36:32:726 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] creating index
2015-05-12-11:36:32:726 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] creating Index [mimos], shards [5]/[1]
2015-05-12-11:36:32:974 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [null], scheduling a retry.
2015-05-12-11:36:33:075 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-11:36:33:076 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-11:36:33:090 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-11:36:33:172 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-11:36:33:262 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Sending mapping created for index mimos, type Programmer
2015-05-12-11:36:33:265 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] creating shard
2015-05-12-11:36:33:265 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] creating shard_id [0]
2015-05-12-11:36:33:399 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-11:36:33:403 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:36:33:404 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:36:33:412 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] state: [CREATED]
2015-05-12-11:36:33:413 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:36:33:418 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:36:33:420 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] starting recovery from local ...
2015-05-12-11:36:33:421 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] creating shard
2015-05-12-11:36:33:423 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] creating shard_id [1]
2015-05-12-11:36:33:432 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-11:36:33:437 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] starting engine
2015-05-12-11:36:33:436 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-11:36:33:444 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:36:33:445 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:36:33:447 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] state: [CREATED]
2015-05-12-11:36:33:448 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:36:33:449 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:36:33:450 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] creating shard
2015-05-12-11:36:33:450 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] starting recovery from local ...
2015-05-12-11:36:33:460 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-11:36:33:459 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] creating shard_id [3]
2015-05-12-11:36:33:461 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] starting engine
2015-05-12-11:36:33:472 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-11:36:33:475 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:36:33:475 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:36:33:477 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] state: [CREATED]
2015-05-12-11:36:33:478 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:36:33:479 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:36:33:479 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] creating shard
2015-05-12-11:36:33:487 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] creating shard_id [4]
2015-05-12-11:36:33:497 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-11:36:33:505 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] starting recovery from local ...
2015-05-12-11:36:33:506 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-11:36:33:507 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] starting engine
2015-05-12-11:36:33:507 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:36:33:509 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:36:33:509 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] state: [CREATED]
2015-05-12-11:36:33:510 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:36:33:511 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:36:33:524 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] starting recovery from local ...
2015-05-12-11:36:33:525 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [_global] writing state, reason [changed]
2015-05-12-11:36:33:527 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-11:36:33:527 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] starting engine
2015-05-12-11:36:33:577 - INFO  - Log4jESLogger - [Kohl Harder Boulder Man] recovered [1] indices into cluster_state
2015-05-12-11:36:33:577 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-11:36:33:578 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] listener to cluster state added, trying to index again
2015-05-12-11:36:33:579 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [null], scheduling a retry.
2015-05-12-11:36:33:579 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] retry scheduling ignored as it as we already have a listener in place
2015-05-12-11:36:33:618 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:36:33:619 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:36:33:618 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:36:33:621 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:36:33:625 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] warming took [5.5ms]
2015-05-12-11:36:33:628 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:36:33:634 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] scheduling refresher every 1s
2015-05-12-11:36:33:636 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] warming took [15.4ms]
2015-05-12-11:36:33:634 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] warming took [9.2ms]
2015-05-12-11:36:33:638 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:36:33:639 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] scheduling refresher every 1s
2015-05-12-11:36:33:639 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:36:33:639 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] scheduling refresher every 1s
2015-05-12-11:36:33:639 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-11:36:33:640 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] refresh with force[true]
2015-05-12-11:36:33:637 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] warming took [16.7ms]
2015-05-12-11:36:33:641 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] recovery completed from [local], took [191ms]
2015-05-12-11:36:33:641 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] sending shard started for [mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:639 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-11:36:33:642 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] refresh with force[true]
2015-05-12-11:36:33:642 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] recovery completed from [local], took [222ms]
2015-05-12-11:36:33:643 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] sending shard started for [mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:643 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] received shard started for [mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:639 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-11:36:33:644 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] refresh with force[true]
2015-05-12-11:36:33:644 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] recovery completed from [local], took [120ms]
2015-05-12-11:36:33:644 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] sending shard started for [mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:645 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] received shard started for [mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:646 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:36:33:646 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] applying started shards [[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-11:36:33:643 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:36:33:648 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] scheduling refresher every 1s
2015-05-12-11:36:33:648 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-11:36:33:648 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] refresh with force[true]
2015-05-12-11:36:33:641 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] received shard started for [mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:649 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] recovery completed from [local], took [144ms]
2015-05-12-11:36:33:650 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:36:33:651 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start balancing cluster
2015-05-12-11:36:33:652 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start distributing Shards
2015-05-12-11:36:33:652 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:652 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:652 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:653 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:653 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:653 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start allocating unassigned shards
2015-05-12-11:36:33:653 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:653 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:654 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:654 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:654 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:655 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start balancing cluster
2015-05-12-11:36:33:655 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start distributing Shards
2015-05-12-11:36:33:655 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:656 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:656 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:656 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:656 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:657 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start allocating unassigned shards
2015-05-12-11:36:33:658 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] cluster state updated:
version [3], source [shard-started ([mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[z4d5K4e9T2eVTJTAy-6ivA][V]
--------[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]
--------[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:36:33:658 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Publishing cluster state version 3
2015-05-12-11:36:33:658 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-11:36:33:659 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:36:33:660 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:36:33:659 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] sending shard started for [mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:660 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-11:36:33:662 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] sending shard started for [mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:36:33:663 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] received shard started for [mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:36:33:663 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-11:36:33:665 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] sending shard started for [mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:36:33:665 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] received shard started for [mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:36:33:667 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] creating shard
2015-05-12-11:36:33:667 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos] creating shard_id [2]
2015-05-12-11:36:33:662 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] received shard started for [mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:677 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-11:36:33:679 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:36:33:681 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:36:33:683 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] state: [CREATED]
2015-05-12-11:36:33:685 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:36:33:686 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:36:33:686 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-11:36:33:687 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] starting recovery from local ...
2015-05-12-11:36:33:687 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] sending shard started for [mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:36:33:688 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-11:36:33:688 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] received shard started for [mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:36:33:688 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] starting engine
2015-05-12-11:36:33:691 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] cluster changed (version 3), trying to index again
2015-05-12-11:36:33:692 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [z4d5K4e9T2eVTJTAy-6ivA], scheduling a retry.
2015-05-12-11:36:33:692 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] retry scheduling ignored as it as we already have a listener in place
2015-05-12-11:36:33:694 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:36:33:695 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][4] writing shard state, reason [version changed from [48] to [50]]
2015-05-12-11:36:33:695 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] warming took [447.1micros]
2015-05-12-11:36:33:701 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:36:33:702 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] scheduling refresher every 1s
2015-05-12-11:36:33:702 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-11:36:33:702 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] refresh with force[true]
2015-05-12-11:36:33:702 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] recovery completed from [local], took [16ms]
2015-05-12-11:36:33:702 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] sending shard started for [mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:702 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] received shard started for [mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:36:33:761 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-11:36:33:761 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:36:33:761 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] applying started shards [[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], [mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], [mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], [mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], [mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], [mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING], [mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-11:36:33:762 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start balancing cluster
2015-05-12-11:36:33:762 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start distributing Shards
2015-05-12-11:36:33:763 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:763 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:763 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:763 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:763 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:764 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start allocating unassigned shards
2015-05-12-11:36:33:764 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:764 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:765 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:765 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:765 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:33:766 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start balancing cluster
2015-05-12-11:36:33:766 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start distributing Shards
2015-05-12-11:36:33:766 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:767 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:767 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:767 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:768 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Assigned shard [[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]] to node [z4d5K4e9T2eVTJTAy-6ivA]
2015-05-12-11:36:33:772 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] Start allocating unassigned shards
2015-05-12-11:36:33:773 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] cluster state updated:
version [4], source [shard-started ([mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[z4d5K4e9T2eVTJTAy-6ivA][V]
--------[mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
--------[mimos][4], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:36:33:773 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Publishing cluster state version 4
2015-05-12-11:36:33:774 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-11:36:33:774 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:36:33:775 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:36:33:782 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] cluster changed (version 4), trying to index again
2015-05-12-11:36:33:784 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][0] writing shard state, reason [version changed from [46] to [48]]
2015-05-12-11:36:33:802 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-11:36:33:819 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][3] writing shard state, reason [version changed from [46] to [48]]
2015-05-12-11:36:33:838 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-11:36:33:853 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] delete [Programmer#1]
2015-05-12-11:36:33:862 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] writing shard state, reason [version changed from [36] to [38]]
2015-05-12-11:36:33:865 - INFO  - Log4jESLogger - [Jessica Jones] version[0.90.5], pid[12040], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:36:33:865 - INFO  - Log4jESLogger - [Jessica Jones] initializing ...
2015-05-12-11:36:33:865 - DEBUG - Log4jESLogger - [Jessica Jones] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:36:33:865 - INFO  - Log4jESLogger - [Jessica Jones] loaded [], sites []
2015-05-12-11:36:33:866 - TRACE - Log4jESLogger - [Jessica Jones] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-11:36:33:866 - DEBUG - Log4jESLogger - [Jessica Jones] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-11:36:33:866 - TRACE - Log4jESLogger - [Jessica Jones] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:36:33:903 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][1] writing shard state, reason [version changed from [32] to [34]]
2015-05-12-11:36:33:916 - TRACE - Log4jESLogger - [Jessica Jones] sigar loaded successfully
2015-05-12-11:36:33:937 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-11:36:33:937 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][0], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][1], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-11:36:33:938 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][3], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [master [Kohl Harder Boulder Man][z4d5K4e9T2eVTJTAy-6ivA][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-11:36:33:939 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:36:33:939 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [shard-started ([mimos][2], node[z4d5K4e9T2eVTJTAy-6ivA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:36:33:941 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-11:36:33:943 - DEBUG - Log4jESLogger - [Kohl Harder Boulder Man] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-11:36:33:993 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:36:33:993 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:36:33:994 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:36:33:994 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:36:33:995 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:36:33:995 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:36:33:996 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:36:33:997 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:36:33:997 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:33:997 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:33:998 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:34:003 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:34:003 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:36:34:003 - DEBUG - Log4jESLogger - [Jessica Jones] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:36:34:005 - DEBUG - Log4jESLogger - [Jessica Jones] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:36:34:008 - DEBUG - Log4jESLogger - [Jessica Jones] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:36:34:010 - DEBUG - Log4jESLogger - [Jessica Jones] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:36:34:011 - DEBUG - Log4jESLogger - [Jessica Jones] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:36:34:012 - DEBUG - Log4jESLogger - [Jessica Jones] using minimum_master_nodes [-1]
2015-05-12-11:36:34:012 - DEBUG - Log4jESLogger - [Jessica Jones] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:36:34:013 - DEBUG - Log4jESLogger - [Jessica Jones] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:36:34:023 - DEBUG - Log4jESLogger - [Jessica Jones] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:36:34:526 - DEBUG - Log4jESLogger - [Jessica Jones] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@17d32e9b] with refresh_interval [1s]
2015-05-12-11:36:34:527 - DEBUG - Log4jESLogger - [Jessica Jones] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@1e86a5a7] with refresh_interval [1s]
2015-05-12-11:36:34:529 - DEBUG - Log4jESLogger - [Jessica Jones] Using refresh_interval [1s]
2015-05-12-11:36:34:530 - DEBUG - Log4jESLogger - [Jessica Jones] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4715ae33] with refresh_interval [5s]
2015-05-12-11:36:34:531 - DEBUG - Log4jESLogger - [Jessica Jones] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:36:34:533 - TRACE - Log4jESLogger - [Jessica Jones] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:49638 errors:0 dropped:0 overruns:0 frame:0
	TX packets:49638 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10375048 (9.9M)  TX bytes:10375048 (9.9M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:509266 errors:0 dropped:0 overruns:0 frame:0
	TX packets:257801 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:589625665 (562M)  TX bytes:27212732 ( 26M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:436 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:435 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:36:34:534 - DEBUG - Log4jESLogger - [Jessica Jones] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@108a46d6] with refresh_interval [1s]
2015-05-12-11:36:34:537 - DEBUG - Log4jESLogger - [Jessica Jones] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:36:34:538 - DEBUG - Log4jESLogger - [Jessica Jones] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:36:34:539 - DEBUG - Log4jESLogger - [Jessica Jones] using script cache with max_size [500], expire [null]
2015-05-12-11:36:34:540 - DEBUG - Log4jESLogger - [Jessica Jones] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:36:34:540 - DEBUG - Log4jESLogger - [Jessica Jones] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:36:34:541 - DEBUG - Log4jESLogger - [Jessica Jones] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:36:34:541 - DEBUG - Log4jESLogger - [Jessica Jones] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:36:34:546 - DEBUG - Log4jESLogger - [Jessica Jones] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:36:34:557 - DEBUG - Log4jESLogger - [Jessica Jones] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:36:34:558 - DEBUG - Log4jESLogger - [Jessica Jones] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:36:34:559 - DEBUG - Log4jESLogger - [Jessica Jones] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:36:34:560 - DEBUG - Log4jESLogger - [Jessica Jones] using size [-1] [-1b], expire [null]
2015-05-12-11:36:34:562 - DEBUG - Log4jESLogger - [Jessica Jones] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:36:34:562 - TRACE - Log4jESLogger - [Jessica Jones] [upgrade]: processing [global-14]
2015-05-12-11:36:34:564 - DEBUG - Log4jESLogger - [Jessica Jones] took 1ms to load state
2015-05-12-11:36:34:564 - TRACE - Log4jESLogger - [Jessica Jones] [find_latest_state]: processing [global-14]
2015-05-12-11:36:34:566 - DEBUG - Log4jESLogger - [Jessica Jones] took 1ms to load started shards state
2015-05-12-11:36:34:567 - DEBUG - Log4jESLogger - [Jessica Jones] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:36:34:571 - DEBUG - Log4jESLogger - [Jessica Jones] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:36:34:572 - DEBUG - Log4jESLogger - [Jessica Jones] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:36:34:572 - DEBUG - Log4jESLogger - [Jessica Jones] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:36:34:573 - DEBUG - Log4jESLogger - [Jessica Jones] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:36:34:574 - DEBUG - Log4jESLogger - [Jessica Jones] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:36:34:574 - DEBUG - Log4jESLogger - [Jessica Jones] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:36:34:578 - INFO  - Log4jESLogger - [Jessica Jones] initialized
2015-05-12-11:36:34:578 - INFO  - Log4jESLogger - [Jessica Jones] starting ...
2015-05-12-11:36:34:721 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [mimos][2] refresh with force[false]
2015-05-12-11:36:34:747 - DEBUG - Log4jESLogger - [Jessica Jones] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-11:36:34:748 - INFO  - Log4jESLogger - [Jessica Jones] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-11:36:34:750 - TRACE - Log4jESLogger - [Jessica Jones] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:36:34:751 - TRACE - Log4jESLogger - [Jessica Jones] [1] sending ping request
2015-05-12-11:36:34:752 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [1] received ping_request from [[Jessica Jones][2Sj21Td1SBysHZR0q1YGiQ][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-11:36:36:252 - TRACE - Log4jESLogger - [Kohl Harder Boulder Man] [1] received ping_request from [[Jessica Jones][2Sj21Td1SBysHZR0q1YGiQ][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-11:36:36:253 - TRACE - Log4jESLogger - [Jessica Jones] [1] sending ping request
2015-05-12-11:36:37:752 - TRACE - Log4jESLogger - [Jessica Jones] full ping responses: {none}
2015-05-12-11:36:37:753 - DEBUG - Log4jESLogger - [Jessica Jones] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-11:36:37:753 - DEBUG - Log4jESLogger - [Jessica Jones] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-11:36:37:754 - TRACE - Log4jESLogger - [Jessica Jones] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Jessica Jones][2Sj21Td1SBysHZR0q1YGiQ][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[2Sj21Td1SBysHZR0q1YGiQ][V]
---- unassigned

2015-05-12-11:36:37:754 - INFO  - Log4jESLogger - [Jessica Jones] new_master [Jessica Jones][2Sj21Td1SBysHZR0q1YGiQ][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-11:36:37:759 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x3a683198, /10.11.66.27:52285 => /10.11.66.27:9301]
2015-05-12-11:36:37:761 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x7a9dd010, /10.11.66.27:52286 => /10.11.66.27:9301]
2015-05-12-11:36:37:764 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x4ce423b7, /10.11.66.27:52287 => /10.11.66.27:9301]
2015-05-12-11:36:37:766 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x72db360c, /10.11.66.27:52288 => /10.11.66.27:9301]
2015-05-12-11:36:37:766 - DEBUG - Log4jESLogger - [Jessica Jones] connected to node [[Jessica Jones][2Sj21Td1SBysHZR0q1YGiQ][inet[/10.11.66.27:9301]]]
2015-05-12-11:36:37:767 - DEBUG - Log4jESLogger - [Jessica Jones] Publishing cluster state version 1
2015-05-12-11:36:37:767 - DEBUG - Log4jESLogger - [Jessica Jones] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-11:36:37:767 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x8e9d664f, /10.11.66.27:52289 => /10.11.66.27:9301]
2015-05-12-11:36:37:768 - DEBUG - Log4jESLogger - [Jessica Jones] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:36:37:768 - DEBUG - Log4jESLogger - [Jessica Jones] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-11:36:37:768 - DEBUG - Log4jESLogger - [Jessica Jones] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:36:37:769 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x29801151, /10.11.66.27:52290 => /10.11.66.27:9301]
2015-05-12-11:36:37:769 - TRACE - Log4jESLogger - [Jessica Jones] initial state set from discovery
2015-05-12-11:36:37:770 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x9ea42ef0, /10.11.66.27:52291 => /10.11.66.27:9301]
2015-05-12-11:36:37:770 - INFO  - Log4jESLogger - [Jessica Jones] kodcu/2Sj21Td1SBysHZR0q1YGiQ
2015-05-12-11:36:37:770 - TRACE - Log4jESLogger - [Jessica Jones] performing state recovery...
2015-05-12-11:36:37:770 - TRACE - Log4jESLogger - [Jessica Jones] performing state recovery from [2Sj21Td1SBysHZR0q1YGiQ]
2015-05-12-11:36:37:770 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x365e150e, /10.11.66.27:52292 => /10.11.66.27:9301]
2015-05-12-11:36:37:771 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x1841c709, /10.11.66.27:52293 => /10.11.66.27:9301]
2015-05-12-11:36:37:771 - TRACE - Log4jESLogger - [Jessica Jones] channel opened: [id: 0x151f8c6d, /10.11.66.27:52294 => /10.11.66.27:9301]
2015-05-12-11:36:37:772 - TRACE - Log4jESLogger - [Jessica Jones] successful state recovery, importing cluster state...
2015-05-12-11:36:37:772 - DEBUG - Log4jESLogger - [Jessica Jones] processing [local-gateway-elected-state]: execute
2015-05-12-11:36:37:776 - DEBUG - Log4jESLogger - [Jessica Jones] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:36:37:777 - TRACE - Log4jESLogger - [Jessica Jones] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-11:36:37:778 - DEBUG - Log4jESLogger - [Jessica Jones] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Jessica Jones][2Sj21Td1SBysHZR0q1YGiQ][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-11:36:37:780 - DEBUG - Log4jESLogger - [Jessica Jones] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Jessica Jones][2Sj21Td1SBysHZR0q1YGiQ][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-11:36:37:786 - DEBUG - Log4jESLogger - [Jessica Jones] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:36:37:787 - DEBUG - Log4jESLogger - [Jessica Jones] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:36:37:787 - TRACE - Log4jESLogger - [Jessica Jones] Start balancing cluster
2015-05-12-11:36:37:788 - TRACE - Log4jESLogger - [Jessica Jones] Start distributing Shards
2015-05-12-11:36:37:788 - TRACE - Log4jESLogger - [Jessica Jones] Assigned shard [[mimos][0], node[2Sj21Td1SBysHZR0q1YGiQ], [P], s[INITIALIZING]] to node [2Sj21Td1SBysHZR0q1YGiQ]
2015-05-12-11:36:37:788 - TRACE - Log4jESLogger - [Jessica Jones] Assigned shard [[mimos][2], node[2Sj21Td1SBysHZR0q1YGiQ], [P], s[INITIALIZING]] to node [2Sj21Td1SBysHZR0q1YGiQ]
2015-05-12-11:36:37:788 - TRACE - Log4jESLogger - [Jessica Jones] Start allocating unassigned shards
2015-05-12-11:36:37:788 - TRACE - Log4jESLogger - [Jessica Jones] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:37:788 - TRACE - Log4jESLogger - [Jessica Jones] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:37:788 - TRACE - Log4jESLogger - [Jessica Jones] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:37:789 - TRACE - Log4jESLogger - [Jessica Jones] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:37:789 - TRACE - Log4jESLogger - [Jessica Jones] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:36:37:789 - TRACE - Log4jESLogger - [Jessica Jones] Start balancing cluster
2015-05-12-11:36:37:789 - TRACE - Log4jESLogger - [Jessica Jones] Start distributing Shards
2015-05-12-11:36:37:789 - TRACE - Log4jESLogger - [Jessica Jones] Assigned shard [[mimos][0], node[2Sj21Td1SBysHZR0q1YGiQ], [P], s[INITIALIZING]] to node [2Sj21Td1SBysHZR0q1YGiQ]
2015-05-12-11:36:37:789 - TRACE - Log4jESLogger - [Jessica Jones] Assigned shard [[mimos][2], node[2Sj21Td1SBysHZR0q1YGiQ], [P], s[INITIALIZING]] to node [2Sj21Td1SBysHZR0q1YGiQ]
2015-05-12-11:36:37:789 - TRACE - Log4jESLogger - [Jessica Jones] Start allocating unassigned shards
2015-05-12-11:36:37:790 - TRACE - Log4jESLogger - [Jessica Jones] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Jessica Jones][2Sj21Td1SBysHZR0q1YGiQ][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[2Sj21Td1SBysHZR0q1YGiQ], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[2Sj21Td1SBysHZR0q1YGiQ], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[2Sj21Td1SBysHZR0q1YGiQ][V]
--------[mimos][0], node[2Sj21Td1SBysHZR0q1YGiQ], [P], s[INITIALIZING]
--------[mimos][2], node[2Sj21Td1SBysHZR0q1YGiQ], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:36:37:790 - DEBUG - Log4jESLogger - [Jessica Jones] Publishing cluster state version 2
2015-05-12-11:36:37:790 - DEBUG - Log4jESLogger - [Jessica Jones] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-11:36:37:791 - DEBUG - Log4jESLogger - [Jessica Jones] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:36:37:791 - DEBUG - Log4jESLogger - [Jessica Jones] [mimos] creating index
2015-05-12-11:36:37:797 - DEBUG - Log4jESLogger - [Jessica Jones] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:36:37:797 - DEBUG - Log4jESLogger - [Jessica Jones] creating Index [mimos], shards [5]/[1]
2015-05-12-11:36:37:809 - INFO  - Log4jESLogger - [Jessica Jones] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-11:36:37:810 - INFO  - Log4jESLogger - [Jessica Jones] started
2015-05-12-11:43:07:163 - INFO  - Log4jESLogger - [Jackal] version[0.90.5], pid[12488], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:43:07:166 - INFO  - Log4jESLogger - [Jackal] initializing ...
2015-05-12-11:43:07:167 - DEBUG - Log4jESLogger - [Jackal] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:43:07:177 - INFO  - Log4jESLogger - [Jackal] loaded [], sites []
2015-05-12-11:43:07:202 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-11:43:07:205 - TRACE - Log4jESLogger - [Jackal] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-11:43:07:212 - DEBUG - Log4jESLogger - [Jackal] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-11:43:07:217 - TRACE - Log4jESLogger - [Jackal] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:43:07:778 - TRACE - Log4jESLogger - [Jackal] sigar loaded successfully
2015-05-12-11:43:08:374 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:43:08:380 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:43:08:384 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:43:08:384 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:43:08:387 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:43:08:389 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:43:08:399 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:43:08:400 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:43:08:402 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:08:403 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:08:403 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:08:404 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:08:404 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:08:404 - DEBUG - Log4jESLogger - [Jackal] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:43:08:421 - DEBUG - Log4jESLogger - [Jackal] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:43:08:432 - DEBUG - Log4jESLogger - [Jackal] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:43:08:438 - DEBUG - Log4jESLogger - [Jackal] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:43:08:441 - DEBUG - Log4jESLogger - [Jackal] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:43:08:442 - DEBUG - Log4jESLogger - [Jackal] using minimum_master_nodes [-1]
2015-05-12-11:43:08:444 - DEBUG - Log4jESLogger - [Jackal] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:43:08:449 - DEBUG - Log4jESLogger - [Jackal] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:43:08:495 - DEBUG - Log4jESLogger - [Jackal] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:43:09:006 - DEBUG - Log4jESLogger - [Jackal] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-11:43:09:010 - DEBUG - Log4jESLogger - [Jackal] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-11:43:09:017 - DEBUG - Log4jESLogger - [Jackal] Using refresh_interval [1s]
2015-05-12-11:43:09:018 - DEBUG - Log4jESLogger - [Jackal] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-11:43:09:023 - DEBUG - Log4jESLogger - [Jackal] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:43:09:026 - TRACE - Log4jESLogger - [Jackal] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:50210 errors:0 dropped:0 overruns:0 frame:0
	TX packets:50210 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10422186 (9.9M)  TX bytes:10422186 (9.9M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:528915 errors:0 dropped:0 overruns:0 frame:0
	TX packets:268443 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:610588653 (582M)  TX bytes:28413971 ( 27M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:451 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:450 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:43:09:031 - DEBUG - Log4jESLogger - [Jackal] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-11:43:09:263 - DEBUG - Log4jESLogger - [Jackal] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:43:09:271 - DEBUG - Log4jESLogger - [Jackal] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:43:09:279 - DEBUG - Log4jESLogger - [Jackal] using script cache with max_size [500], expire [null]
2015-05-12-11:43:09:286 - DEBUG - Log4jESLogger - [Jackal] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:43:09:289 - DEBUG - Log4jESLogger - [Jackal] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:43:09:291 - DEBUG - Log4jESLogger - [Jackal] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:43:09:297 - DEBUG - Log4jESLogger - [Jackal] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:43:09:382 - DEBUG - Log4jESLogger - [Jackal] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:43:09:462 - DEBUG - Log4jESLogger - [Jackal] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:43:09:470 - DEBUG - Log4jESLogger - [Jackal] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:43:09:472 - DEBUG - Log4jESLogger - [Jackal] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:43:09:474 - DEBUG - Log4jESLogger - [Jackal] using size [-1] [-1b], expire [null]
2015-05-12-11:43:09:487 - DEBUG - Log4jESLogger - [Jackal] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:43:09:487 - TRACE - Log4jESLogger - [Jackal] [upgrade]: processing [global-27]
2015-05-12-11:43:09:601 - DEBUG - Log4jESLogger - [Jackal] took 112ms to load state
2015-05-12-11:43:09:601 - TRACE - Log4jESLogger - [Jackal] [find_latest_state]: processing [global-27]
2015-05-12-11:43:09:622 - DEBUG - Log4jESLogger - [Jackal] took 20ms to load started shards state
2015-05-12-11:43:09:624 - DEBUG - Log4jESLogger - [Jackal] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:43:09:628 - DEBUG - Log4jESLogger - [Jackal] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:43:09:629 - DEBUG - Log4jESLogger - [Jackal] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:43:09:629 - DEBUG - Log4jESLogger - [Jackal] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:43:09:630 - DEBUG - Log4jESLogger - [Jackal] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:43:09:630 - DEBUG - Log4jESLogger - [Jackal] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:43:09:631 - DEBUG - Log4jESLogger - [Jackal] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:43:09:638 - INFO  - Log4jESLogger - [Jackal] initialized
2015-05-12-11:43:09:638 - INFO  - Log4jESLogger - [Jackal] starting ...
2015-05-12-11:43:09:658 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-11:43:09:658 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-11:43:09:720 - DEBUG - Log4jESLogger - [Jackal] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-11:43:09:724 - INFO  - Log4jESLogger - [Jackal] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-11:43:09:744 - TRACE - Log4jESLogger - [Jackal] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:43:09:754 - TRACE - Log4jESLogger - [Jackal] [1] sending ping request
2015-05-12-11:43:11:255 - TRACE - Log4jESLogger - [Jackal] [1] sending ping request
2015-05-12-11:43:12:758 - TRACE - Log4jESLogger - [Jackal] full ping responses: {none}
2015-05-12-11:43:12:758 - DEBUG - Log4jESLogger - [Jackal] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-11:43:12:762 - DEBUG - Log4jESLogger - [Jackal] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-11:43:12:764 - TRACE - Log4jESLogger - [Jackal] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[cO4E8MptQdSk4w7Zfz-6XA][V]
---- unassigned

2015-05-12-11:43:12:766 - INFO  - Log4jESLogger - [Jackal] new_master [Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-12-11:43:12:781 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0x887ead77, /10.11.66.27:51007 => /10.11.66.27:9300]
2015-05-12-11:43:12:788 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0xca3e1e66, /10.11.66.27:51008 => /10.11.66.27:9300]
2015-05-12-11:43:12:790 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0x1e4e9767, /10.11.66.27:51009 => /10.11.66.27:9300]
2015-05-12-11:43:12:793 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0x7342da56, /10.11.66.27:51010 => /10.11.66.27:9300]
2015-05-12-11:43:12:794 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0xaed1fbfd, /10.11.66.27:51011 => /10.11.66.27:9300]
2015-05-12-11:43:12:794 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0x73ef1ec9, /10.11.66.27:51012 => /10.11.66.27:9300]
2015-05-12-11:43:12:795 - DEBUG - Log4jESLogger - [Jackal] connected to node [[Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]]]
2015-05-12-11:43:12:795 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0x0b637f96, /10.11.66.27:51013 => /10.11.66.27:9300]
2015-05-12-11:43:12:797 - DEBUG - Log4jESLogger - [Jackal] Publishing cluster state version 1
2015-05-12-11:43:12:797 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0xda12eb3a, /10.11.66.27:51014 => /10.11.66.27:9300]
2015-05-12-11:43:12:797 - DEBUG - Log4jESLogger - [Jackal] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-11:43:12:798 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0x16bb1172, /10.11.66.27:51015 => /10.11.66.27:9300]
2015-05-12-11:43:12:798 - TRACE - Log4jESLogger - [Jackal] channel opened: [id: 0x7e3cd534, /10.11.66.27:51016 => /10.11.66.27:9300]
2015-05-12-11:43:12:801 - DEBUG - Log4jESLogger - [Jackal] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:43:12:801 - DEBUG - Log4jESLogger - [Jackal] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:43:12:801 - TRACE - Log4jESLogger - [Jackal] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-11:43:12:802 - DEBUG - Log4jESLogger - [Jackal] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-11:43:12:801 - TRACE - Log4jESLogger - [Jackal] initial state set from discovery
2015-05-12-11:43:12:806 - INFO  - Log4jESLogger - [Jackal] peansData/cO4E8MptQdSk4w7Zfz-6XA
2015-05-12-11:43:12:807 - TRACE - Log4jESLogger - [Jackal] performing state recovery...
2015-05-12-11:43:12:807 - TRACE - Log4jESLogger - [Jackal] performing state recovery from [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:816 - TRACE - Log4jESLogger - [Jackal] successful state recovery, importing cluster state...
2015-05-12-11:43:12:818 - DEBUG - Log4jESLogger - [Jackal] processing [local-gateway-elected-state]: execute
2015-05-12-11:43:12:830 - INFO  - Log4jESLogger - [Jackal] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-12-11:43:12:831 - INFO  - Log4jESLogger - [Jackal] started
2015-05-12-11:43:12:838 - DEBUG - Log4jESLogger - [Jackal] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:43:12:839 - DEBUG - Log4jESLogger - [Jackal] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:43:12:840 - DEBUG - Log4jESLogger - [Jackal] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:43:12:841 - DEBUG - Log4jESLogger - [Jackal] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:43:12:842 - DEBUG - Log4jESLogger - [Jackal] [mimos][1]: throttling allocation [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[[Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-12-11:43:12:846 - TRACE - Log4jESLogger - [Jackal] Start balancing cluster
2015-05-12-11:43:12:847 - TRACE - Log4jESLogger - [Jackal] Start distributing Shards
2015-05-12-11:43:12:849 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:849 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:849 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:850 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:850 - TRACE - Log4jESLogger - [Jackal] Start allocating unassigned shards
2015-05-12-11:43:12:851 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:12:852 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:12:852 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:12:852 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:12:853 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:12:854 - TRACE - Log4jESLogger - [Jackal] Start balancing cluster
2015-05-12-11:43:12:854 - TRACE - Log4jESLogger - [Jackal] Start distributing Shards
2015-05-12-11:43:12:854 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:855 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:855 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:855 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:12:855 - TRACE - Log4jESLogger - [Jackal] Start allocating unassigned shards
2015-05-12-11:43:12:857 - TRACE - Log4jESLogger - [Jackal] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[cO4E8MptQdSk4w7Zfz-6XA][V]
--------[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:43:12:858 - DEBUG - Log4jESLogger - [Jackal] Publishing cluster state version 2
2015-05-12-11:43:12:858 - DEBUG - Log4jESLogger - [Jackal] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-11:43:12:860 - DEBUG - Log4jESLogger - [Jackal] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:43:12:860 - DEBUG - Log4jESLogger - [Jackal] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:43:12:861 - DEBUG - Log4jESLogger - [Jackal] [mimos] creating index
2015-05-12-11:43:12:861 - DEBUG - Log4jESLogger - [Jackal] creating Index [mimos], shards [5]/[1]
2015-05-12-11:43:13:081 - TRACE - Log4jESLogger - [Jackal] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [cO4E8MptQdSk4w7Zfz-6XA], scheduling a retry.
2015-05-12-11:43:13:129 - DEBUG - Log4jESLogger - [Jackal] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-11:43:13:130 - DEBUG - Log4jESLogger - [Jackal] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-11:43:13:145 - DEBUG - Log4jESLogger - [Jackal] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-11:43:13:240 - DEBUG - Log4jESLogger - [Jackal] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-11:43:13:322 - DEBUG - Log4jESLogger - [Jackal] Sending mapping created for index mimos, type Programmer
2015-05-12-11:43:13:326 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] creating shard
2015-05-12-11:43:13:326 - DEBUG - Log4jESLogger - [Jackal] [mimos] creating shard_id [0]
2015-05-12-11:43:13:469 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-11:43:13:473 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:43:13:473 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:43:13:479 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] state: [CREATED]
2015-05-12-11:43:13:480 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:43:13:486 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:43:13:488 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] creating shard
2015-05-12-11:43:13:489 - DEBUG - Log4jESLogger - [Jackal] [mimos] creating shard_id [2]
2015-05-12-11:43:13:488 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] starting recovery from local ...
2015-05-12-11:43:13:498 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-11:43:13:504 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:43:13:504 - TRACE - Log4jESLogger - [Jackal] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-11:43:13:506 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] starting engine
2015-05-12-11:43:13:507 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:43:13:510 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] state: [CREATED]
2015-05-12-11:43:13:512 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:43:13:514 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:43:13:515 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] creating shard
2015-05-12-11:43:13:515 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] starting recovery from local ...
2015-05-12-11:43:13:522 - DEBUG - Log4jESLogger - [Jackal] [mimos] creating shard_id [3]
2015-05-12-11:43:13:523 - TRACE - Log4jESLogger - [Jackal] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-11:43:13:524 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] starting engine
2015-05-12-11:43:13:536 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-11:43:13:540 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:43:13:547 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:43:13:548 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] state: [CREATED]
2015-05-12-11:43:13:548 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:43:13:552 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:43:13:553 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] creating shard
2015-05-12-11:43:13:553 - DEBUG - Log4jESLogger - [Jackal] [mimos] creating shard_id [4]
2015-05-12-11:43:13:570 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] starting recovery from local ...
2015-05-12-11:43:13:577 - TRACE - Log4jESLogger - [Jackal] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-11:43:13:578 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] starting engine
2015-05-12-11:43:13:580 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-11:43:13:581 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:43:13:582 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:43:13:582 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] state: [CREATED]
2015-05-12-11:43:13:583 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:43:13:584 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:43:13:592 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] starting recovery from local ...
2015-05-12-11:43:13:595 - TRACE - Log4jESLogger - [Jackal] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-11:43:13:595 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] starting engine
2015-05-12-11:43:13:618 - TRACE - Log4jESLogger - [Jackal] [_global] writing state, reason [changed]
2015-05-12-11:43:13:649 - TRACE - Log4jESLogger - [Jackal] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:43:13:650 - TRACE - Log4jESLogger - [Jackal] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:43:13:649 - TRACE - Log4jESLogger - [Jackal] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:43:13:651 - TRACE - Log4jESLogger - [Jackal] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:43:13:656 - TRACE - Log4jESLogger - [Jackal] [mimos][0] warming took [4.9ms]
2015-05-12-11:43:13:658 - TRACE - Log4jESLogger - [Jackal] [mimos][2] warming took [7.2ms]
2015-05-12-11:43:13:662 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:43:13:663 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] scheduling refresher every 1s
2015-05-12-11:43:13:659 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:43:13:668 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] scheduling refresher every 1s
2015-05-12-11:43:13:673 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-11:43:13:674 - TRACE - Log4jESLogger - [Jackal] [mimos][0] refresh with force[true]
2015-05-12-11:43:13:674 - DEBUG - Log4jESLogger - [Jackal] [mimos][0] recovery completed from [local], took [186ms]
2015-05-12-11:43:13:674 - DEBUG - Log4jESLogger - [Jackal] sending shard started for [mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:675 - DEBUG - Log4jESLogger - [Jackal] received shard started for [mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:661 - TRACE - Log4jESLogger - [Jackal] [mimos][4] warming took [10.9ms]
2015-05-12-11:43:13:677 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:43:13:677 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] scheduling refresher every 1s
2015-05-12-11:43:13:678 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-11:43:13:678 - TRACE - Log4jESLogger - [Jackal] [mimos][4] refresh with force[true]
2015-05-12-11:43:13:678 - DEBUG - Log4jESLogger - [Jackal] [mimos][4] recovery completed from [local], took [87ms]
2015-05-12-11:43:13:678 - DEBUG - Log4jESLogger - [Jackal] sending shard started for [mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:678 - DEBUG - Log4jESLogger - [Jackal] received shard started for [mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:673 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-11:43:13:679 - TRACE - Log4jESLogger - [Jackal] [mimos][3] warming took [26.8ms]
2015-05-12-11:43:13:679 - TRACE - Log4jESLogger - [Jackal] [mimos][2] refresh with force[true]
2015-05-12-11:43:13:680 - DEBUG - Log4jESLogger - [Jackal] [mimos][2] recovery completed from [local], took [165ms]
2015-05-12-11:43:13:680 - DEBUG - Log4jESLogger - [Jackal] sending shard started for [mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:681 - DEBUG - Log4jESLogger - [Jackal] received shard started for [mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:681 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:43:13:681 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] scheduling refresher every 1s
2015-05-12-11:43:13:682 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-11:43:13:682 - TRACE - Log4jESLogger - [Jackal] [mimos][3] refresh with force[true]
2015-05-12-11:43:13:682 - DEBUG - Log4jESLogger - [Jackal] [mimos][3] recovery completed from [local], took [112ms]
2015-05-12-11:43:13:682 - DEBUG - Log4jESLogger - [Jackal] sending shard started for [mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:683 - DEBUG - Log4jESLogger - [Jackal] received shard started for [mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:693 - INFO  - Log4jESLogger - [Jackal] recovered [1] indices into cluster_state
2015-05-12-11:43:13:693 - DEBUG - Log4jESLogger - [Jackal] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-11:43:13:694 - TRACE - Log4jESLogger - [Jackal] listener to cluster state added, trying to index again
2015-05-12-11:43:13:695 - TRACE - Log4jESLogger - [Jackal] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [cO4E8MptQdSk4w7Zfz-6XA], scheduling a retry.
2015-05-12-11:43:13:696 - TRACE - Log4jESLogger - [Jackal] retry scheduling ignored as it as we already have a listener in place
2015-05-12-11:43:13:696 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:43:13:697 - DEBUG - Log4jESLogger - [Jackal] applying started shards [[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], [mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], [mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], [mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-11:43:13:697 - DEBUG - Log4jESLogger - [Jackal] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:43:13:698 - TRACE - Log4jESLogger - [Jackal] Start balancing cluster
2015-05-12-11:43:13:698 - TRACE - Log4jESLogger - [Jackal] Start distributing Shards
2015-05-12-11:43:13:699 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:699 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:699 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:699 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:699 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:699 - TRACE - Log4jESLogger - [Jackal] Start allocating unassigned shards
2015-05-12-11:43:13:700 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:700 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:701 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:701 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:702 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:702 - TRACE - Log4jESLogger - [Jackal] Start balancing cluster
2015-05-12-11:43:13:702 - TRACE - Log4jESLogger - [Jackal] Start distributing Shards
2015-05-12-11:43:13:703 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:703 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:703 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:703 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:704 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:704 - TRACE - Log4jESLogger - [Jackal] Start allocating unassigned shards
2015-05-12-11:43:13:708 - TRACE - Log4jESLogger - [Jackal] cluster state updated:
version [3], source [shard-started ([mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[cO4E8MptQdSk4w7Zfz-6XA][V]
--------[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]
--------[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:43:13:709 - DEBUG - Log4jESLogger - [Jackal] Publishing cluster state version 3
2015-05-12-11:43:13:709 - DEBUG - Log4jESLogger - [Jackal] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-11:43:13:709 - DEBUG - Log4jESLogger - [Jackal] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:43:13:710 - DEBUG - Log4jESLogger - [Jackal] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:43:13:711 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] creating shard
2015-05-12-11:43:13:712 - DEBUG - Log4jESLogger - [Jackal] [mimos] creating shard_id [1]
2015-05-12-11:43:13:723 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-11:43:13:728 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:43:13:729 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:43:13:730 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] state: [CREATED]
2015-05-12-11:43:13:731 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:43:13:732 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:43:13:733 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] starting recovery from local ...
2015-05-12-11:43:13:733 - TRACE - Log4jESLogger - [Jackal] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-11:43:13:734 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] starting engine
2015-05-12-11:43:13:736 - TRACE - Log4jESLogger - [Jackal] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:43:13:744 - TRACE - Log4jESLogger - [Jackal] [mimos][1] warming took [340.5micros]
2015-05-12-11:43:13:746 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:43:13:746 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] scheduling refresher every 1s
2015-05-12-11:43:13:746 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-11:43:13:751 - TRACE - Log4jESLogger - [Jackal] [mimos][1] refresh with force[true]
2015-05-12-11:43:13:751 - DEBUG - Log4jESLogger - [Jackal] [mimos][1] recovery completed from [local], took [18ms]
2015-05-12-11:43:13:752 - DEBUG - Log4jESLogger - [Jackal] sending shard started for [mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:752 - DEBUG - Log4jESLogger - [Jackal] received shard started for [mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:43:13:747 - TRACE - Log4jESLogger - [Jackal] cluster changed (version 3), trying to index again
2015-05-12-11:43:13:756 - TRACE - Log4jESLogger - [Jackal] [mimos][0] writing shard state, reason [version changed from [48] to [50]]
2015-05-12-11:43:13:774 - TRACE - Log4jESLogger - [Jackal] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-11:43:13:819 - DEBUG - Log4jESLogger - [Jackal] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-11:43:13:832 - TRACE - Log4jESLogger - [Jackal] [mimos][2] delete [Programmer#1]
2015-05-12-11:43:13:834 - TRACE - Log4jESLogger - [Jackal] [mimos][4] writing shard state, reason [version changed from [50] to [52]]
2015-05-12-11:43:13:844 - INFO  - Log4jESLogger - [Amanda Sefton] version[0.90.5], pid[12488], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:43:13:845 - INFO  - Log4jESLogger - [Amanda Sefton] initializing ...
2015-05-12-11:43:13:845 - DEBUG - Log4jESLogger - [Amanda Sefton] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:43:13:845 - INFO  - Log4jESLogger - [Amanda Sefton] loaded [], sites []
2015-05-12-11:43:13:846 - TRACE - Log4jESLogger - [Amanda Sefton] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-11:43:13:846 - DEBUG - Log4jESLogger - [Amanda Sefton] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-11:43:13:847 - TRACE - Log4jESLogger - [Amanda Sefton] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:43:13:868 - TRACE - Log4jESLogger - [Jackal] [mimos][3] writing shard state, reason [version changed from [48] to [50]]
2015-05-12-11:43:13:887 - TRACE - Log4jESLogger - [Amanda Sefton] sigar loaded successfully
2015-05-12-11:43:13:901 - TRACE - Log4jESLogger - [Jackal] [mimos][2] writing shard state, reason [version changed from [38] to [40]]
2015-05-12-11:43:13:936 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-11:43:13:936 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:43:13:936 - DEBUG - Log4jESLogger - [Jackal] applying started shards [[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-11:43:13:937 - TRACE - Log4jESLogger - [Jackal] Start balancing cluster
2015-05-12-11:43:13:937 - TRACE - Log4jESLogger - [Jackal] Start distributing Shards
2015-05-12-11:43:13:937 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:937 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:937 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:938 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:938 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:938 - TRACE - Log4jESLogger - [Jackal] Start allocating unassigned shards
2015-05-12-11:43:13:938 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:939 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:944 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:944 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:944 - TRACE - Log4jESLogger - [Jackal] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:43:13:945 - TRACE - Log4jESLogger - [Jackal] Start balancing cluster
2015-05-12-11:43:13:945 - TRACE - Log4jESLogger - [Jackal] Start distributing Shards
2015-05-12-11:43:13:945 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:946 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:946 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:946 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:946 - TRACE - Log4jESLogger - [Jackal] Assigned shard [[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]] to node [cO4E8MptQdSk4w7Zfz-6XA]
2015-05-12-11:43:13:946 - TRACE - Log4jESLogger - [Jackal] Start allocating unassigned shards
2015-05-12-11:43:13:947 - TRACE - Log4jESLogger - [Jackal] cluster state updated:
version [4], source [shard-started ([mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Jackal][cO4E8MptQdSk4w7Zfz-6XA][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[cO4E8MptQdSk4w7Zfz-6XA][V]
--------[mimos][0], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
--------[mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:43:13:947 - DEBUG - Log4jESLogger - [Jackal] Publishing cluster state version 4
2015-05-12-11:43:13:948 - DEBUG - Log4jESLogger - [Jackal] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-11:43:13:948 - DEBUG - Log4jESLogger - [Jackal] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:43:13:949 - DEBUG - Log4jESLogger - [Jackal] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:43:13:950 - TRACE - Log4jESLogger - [Jackal] [mimos][1] writing shard state, reason [version changed from [34] to [36]]
2015-05-12-11:43:13:959 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:43:13:960 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:43:13:960 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:43:13:961 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:43:13:961 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:43:13:961 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:43:13:961 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:43:13:962 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:43:13:962 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:13:962 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:13:963 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:13:963 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:13:963 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:43:13:963 - DEBUG - Log4jESLogger - [Amanda Sefton] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:43:13:964 - DEBUG - Log4jESLogger - [Amanda Sefton] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:43:13:965 - DEBUG - Log4jESLogger - [Amanda Sefton] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:43:13:965 - DEBUG - Log4jESLogger - [Amanda Sefton] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:43:13:966 - DEBUG - Log4jESLogger - [Amanda Sefton] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:43:13:966 - DEBUG - Log4jESLogger - [Amanda Sefton] using minimum_master_nodes [-1]
2015-05-12-11:43:13:966 - DEBUG - Log4jESLogger - [Amanda Sefton] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:43:13:966 - DEBUG - Log4jESLogger - [Amanda Sefton] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:43:13:972 - DEBUG - Log4jESLogger - [Amanda Sefton] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:43:13:986 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][4], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-11:43:13:986 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:43:13:986 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][2], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:43:13:986 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:43:13:987 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][3], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:43:13:987 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:43:13:987 - DEBUG - Log4jESLogger - [Jackal] processing [shard-started ([mimos][1], node[cO4E8MptQdSk4w7Zfz-6XA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:43:13:987 - DEBUG - Log4jESLogger - [Jackal] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-11:43:13:991 - DEBUG - Log4jESLogger - [Jackal] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-11:43:14:474 - DEBUG - Log4jESLogger - [Amanda Sefton] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@17d32e9b] with refresh_interval [1s]
2015-05-12-11:43:14:476 - DEBUG - Log4jESLogger - [Amanda Sefton] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@1e86a5a7] with refresh_interval [1s]
2015-05-12-11:43:14:477 - DEBUG - Log4jESLogger - [Amanda Sefton] Using refresh_interval [1s]
2015-05-12-11:43:14:477 - DEBUG - Log4jESLogger - [Amanda Sefton] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@a2ddf26] with refresh_interval [5s]
2015-05-12-11:43:14:478 - DEBUG - Log4jESLogger - [Amanda Sefton] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:43:14:479 - TRACE - Log4jESLogger - [Amanda Sefton] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:50240 errors:0 dropped:0 overruns:0 frame:0
	TX packets:50240 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10423906 (9.9M)  TX bytes:10423906 (9.9M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:528999 errors:0 dropped:0 overruns:0 frame:0
	TX packets:268530 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:610596018 (582M)  TX bytes:28420697 ( 27M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:451 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:450 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:43:14:480 - DEBUG - Log4jESLogger - [Amanda Sefton] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@23a5818e] with refresh_interval [1s]
2015-05-12-11:43:14:483 - DEBUG - Log4jESLogger - [Amanda Sefton] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:43:14:483 - DEBUG - Log4jESLogger - [Amanda Sefton] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:43:14:484 - DEBUG - Log4jESLogger - [Amanda Sefton] using script cache with max_size [500], expire [null]
2015-05-12-11:43:14:485 - DEBUG - Log4jESLogger - [Amanda Sefton] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:43:14:485 - DEBUG - Log4jESLogger - [Amanda Sefton] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:43:14:486 - DEBUG - Log4jESLogger - [Amanda Sefton] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:43:14:487 - DEBUG - Log4jESLogger - [Amanda Sefton] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:43:14:492 - DEBUG - Log4jESLogger - [Amanda Sefton] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:43:14:500 - DEBUG - Log4jESLogger - [Amanda Sefton] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:43:14:501 - DEBUG - Log4jESLogger - [Amanda Sefton] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:43:14:502 - DEBUG - Log4jESLogger - [Amanda Sefton] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:43:14:503 - DEBUG - Log4jESLogger - [Amanda Sefton] using size [-1] [-1b], expire [null]
2015-05-12-11:43:14:506 - DEBUG - Log4jESLogger - [Amanda Sefton] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:43:14:507 - TRACE - Log4jESLogger - [Amanda Sefton] [upgrade]: processing [global-14]
2015-05-12-11:43:14:508 - DEBUG - Log4jESLogger - [Amanda Sefton] took 1ms to load state
2015-05-12-11:43:14:509 - TRACE - Log4jESLogger - [Amanda Sefton] [find_latest_state]: processing [global-14]
2015-05-12-11:43:14:510 - DEBUG - Log4jESLogger - [Amanda Sefton] took 1ms to load started shards state
2015-05-12-11:43:14:511 - DEBUG - Log4jESLogger - [Amanda Sefton] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:43:14:514 - DEBUG - Log4jESLogger - [Amanda Sefton] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:43:14:515 - DEBUG - Log4jESLogger - [Amanda Sefton] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:43:14:515 - DEBUG - Log4jESLogger - [Amanda Sefton] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:43:14:516 - DEBUG - Log4jESLogger - [Amanda Sefton] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:43:14:516 - DEBUG - Log4jESLogger - [Amanda Sefton] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:43:14:516 - DEBUG - Log4jESLogger - [Amanda Sefton] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:43:14:520 - INFO  - Log4jESLogger - [Amanda Sefton] initialized
2015-05-12-11:43:14:521 - INFO  - Log4jESLogger - [Amanda Sefton] starting ...
2015-05-12-11:43:14:547 - DEBUG - Log4jESLogger - [Amanda Sefton] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-11:43:14:548 - INFO  - Log4jESLogger - [Amanda Sefton] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-11:43:14:550 - TRACE - Log4jESLogger - [Amanda Sefton] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:43:14:551 - TRACE - Log4jESLogger - [Jackal] [1] received ping_request from [[Amanda Sefton][wW4V72X9QHW9u6Ww-HS83Q][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-11:43:14:552 - TRACE - Log4jESLogger - [Amanda Sefton] [1] sending ping request
2015-05-12-11:43:14:665 - TRACE - Log4jESLogger - [Jackal] [mimos][2] refresh with force[false]
2015-05-12-11:50:48:988 - INFO  - Log4jESLogger - [Wind Warrior] version[0.90.5], pid[13121], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:50:48:991 - INFO  - Log4jESLogger - [Wind Warrior] initializing ...
2015-05-12-11:50:48:992 - DEBUG - Log4jESLogger - [Wind Warrior] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:50:49:002 - INFO  - Log4jESLogger - [Wind Warrior] loaded [], sites []
2015-05-12-11:50:49:027 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-11:50:49:030 - TRACE - Log4jESLogger - [Wind Warrior] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-11:50:49:039 - DEBUG - Log4jESLogger - [Wind Warrior] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-11:50:49:044 - TRACE - Log4jESLogger - [Wind Warrior] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:50:49:602 - TRACE - Log4jESLogger - [Wind Warrior] sigar loaded successfully
2015-05-12-11:50:50:213 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:50:50:219 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:50:50:223 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:50:50:223 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:50:50:225 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:50:50:227 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:50:50:237 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:50:50:239 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:50:50:241 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:50:242 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:50:242 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:50:243 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:50:243 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:50:243 - DEBUG - Log4jESLogger - [Wind Warrior] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:50:50:261 - DEBUG - Log4jESLogger - [Wind Warrior] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:50:50:272 - DEBUG - Log4jESLogger - [Wind Warrior] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:50:50:278 - DEBUG - Log4jESLogger - [Wind Warrior] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:50:50:281 - DEBUG - Log4jESLogger - [Wind Warrior] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:50:50:282 - DEBUG - Log4jESLogger - [Wind Warrior] using minimum_master_nodes [-1]
2015-05-12-11:50:50:284 - DEBUG - Log4jESLogger - [Wind Warrior] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:50:50:290 - DEBUG - Log4jESLogger - [Wind Warrior] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:50:50:330 - DEBUG - Log4jESLogger - [Wind Warrior] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:50:50:841 - DEBUG - Log4jESLogger - [Wind Warrior] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-11:50:50:845 - DEBUG - Log4jESLogger - [Wind Warrior] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-11:50:50:852 - DEBUG - Log4jESLogger - [Wind Warrior] Using refresh_interval [1s]
2015-05-12-11:50:50:853 - DEBUG - Log4jESLogger - [Wind Warrior] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-11:50:50:858 - DEBUG - Log4jESLogger - [Wind Warrior] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:50:50:861 - TRACE - Log4jESLogger - [Wind Warrior] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:51753 errors:0 dropped:0 overruns:0 frame:0
	TX packets:51753 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10548576 ( 10M)  TX bytes:10548576 ( 10M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:547023 errors:0 dropped:0 overruns:0 frame:0
	TX packets:276915 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:630757230 (602M)  TX bytes:29327871 ( 28M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:466 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:465 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:50:50:866 - DEBUG - Log4jESLogger - [Wind Warrior] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-11:50:51:118 - DEBUG - Log4jESLogger - [Wind Warrior] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:50:51:127 - DEBUG - Log4jESLogger - [Wind Warrior] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:50:51:135 - DEBUG - Log4jESLogger - [Wind Warrior] using script cache with max_size [500], expire [null]
2015-05-12-11:50:51:141 - DEBUG - Log4jESLogger - [Wind Warrior] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:50:51:142 - DEBUG - Log4jESLogger - [Wind Warrior] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:50:51:143 - DEBUG - Log4jESLogger - [Wind Warrior] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:50:51:148 - DEBUG - Log4jESLogger - [Wind Warrior] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:50:51:244 - DEBUG - Log4jESLogger - [Wind Warrior] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:50:51:344 - DEBUG - Log4jESLogger - [Wind Warrior] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:50:51:355 - DEBUG - Log4jESLogger - [Wind Warrior] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:50:51:357 - DEBUG - Log4jESLogger - [Wind Warrior] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:50:51:359 - DEBUG - Log4jESLogger - [Wind Warrior] using size [-1] [-1b], expire [null]
2015-05-12-11:50:51:375 - DEBUG - Log4jESLogger - [Wind Warrior] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:50:51:376 - TRACE - Log4jESLogger - [Wind Warrior] [upgrade]: processing [global-28]
2015-05-12-11:50:51:492 - DEBUG - Log4jESLogger - [Wind Warrior] took 115ms to load state
2015-05-12-11:50:51:494 - TRACE - Log4jESLogger - [Wind Warrior] [find_latest_state]: processing [global-28]
2015-05-12-11:50:51:498 - DEBUG - Log4jESLogger - [Wind Warrior] took 4ms to load started shards state
2015-05-12-11:50:51:500 - DEBUG - Log4jESLogger - [Wind Warrior] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:50:51:509 - DEBUG - Log4jESLogger - [Wind Warrior] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:50:51:510 - DEBUG - Log4jESLogger - [Wind Warrior] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:50:51:510 - DEBUG - Log4jESLogger - [Wind Warrior] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:50:51:511 - DEBUG - Log4jESLogger - [Wind Warrior] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:50:51:511 - DEBUG - Log4jESLogger - [Wind Warrior] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:50:51:512 - DEBUG - Log4jESLogger - [Wind Warrior] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:50:51:518 - INFO  - Log4jESLogger - [Wind Warrior] initialized
2015-05-12-11:50:51:521 - INFO  - Log4jESLogger - [Wind Warrior] starting ...
2015-05-12-11:50:51:542 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-11:50:51:543 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-11:50:51:621 - DEBUG - Log4jESLogger - [Wind Warrior] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-11:50:51:625 - INFO  - Log4jESLogger - [Wind Warrior] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-11:50:51:651 - TRACE - Log4jESLogger - [Wind Warrior] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:50:51:668 - TRACE - Log4jESLogger - [Wind Warrior] [1] sending ping request
2015-05-12-11:50:53:171 - TRACE - Log4jESLogger - [Wind Warrior] [1] sending ping request
2015-05-12-11:50:54:677 - TRACE - Log4jESLogger - [Wind Warrior] full ping responses: {none}
2015-05-12-11:50:54:678 - DEBUG - Log4jESLogger - [Wind Warrior] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-11:50:54:682 - DEBUG - Log4jESLogger - [Wind Warrior] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-11:50:54:684 - TRACE - Log4jESLogger - [Wind Warrior] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[iGGh3woiQQ26eEgACm-t0A][V]
---- unassigned

2015-05-12-11:50:54:685 - INFO  - Log4jESLogger - [Wind Warrior] new_master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-12-11:50:54:700 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0x6bd7e696, /10.11.66.27:51179 => /10.11.66.27:9300]
2015-05-12-11:50:54:703 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0x8abf45ac, /10.11.66.27:51180 => /10.11.66.27:9300]
2015-05-12-11:50:54:706 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0x6033fbe5, /10.11.66.27:51181 => /10.11.66.27:9300]
2015-05-12-11:50:54:708 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0x92ef43b3, /10.11.66.27:51182 => /10.11.66.27:9300]
2015-05-12-11:50:54:709 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0xdae73598, /10.11.66.27:51183 => /10.11.66.27:9300]
2015-05-12-11:50:54:709 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0x3788654d, /10.11.66.27:51184 => /10.11.66.27:9300]
2015-05-12-11:50:54:710 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0x119036f9, /10.11.66.27:51185 => /10.11.66.27:9300]
2015-05-12-11:50:54:714 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0x4017989b, /10.11.66.27:51186 => /10.11.66.27:9300]
2015-05-12-11:50:54:715 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0xae4780d5, /10.11.66.27:51187 => /10.11.66.27:9300]
2015-05-12-11:50:54:716 - TRACE - Log4jESLogger - [Wind Warrior] channel opened: [id: 0x058bb1c9, /10.11.66.27:51188 => /10.11.66.27:9300]
2015-05-12-11:50:54:720 - DEBUG - Log4jESLogger - [Wind Warrior] connected to node [[Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]]]
2015-05-12-11:50:54:721 - DEBUG - Log4jESLogger - [Wind Warrior] Publishing cluster state version 1
2015-05-12-11:50:54:721 - DEBUG - Log4jESLogger - [Wind Warrior] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-11:50:54:724 - DEBUG - Log4jESLogger - [Wind Warrior] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:50:54:725 - DEBUG - Log4jESLogger - [Wind Warrior] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:50:54:725 - TRACE - Log4jESLogger - [Wind Warrior] initial state set from discovery
2015-05-12-11:50:54:725 - DEBUG - Log4jESLogger - [Wind Warrior] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-11:50:54:725 - TRACE - Log4jESLogger - [Wind Warrior] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-11:50:54:726 - INFO  - Log4jESLogger - [Wind Warrior] peansData/iGGh3woiQQ26eEgACm-t0A
2015-05-12-11:50:54:727 - TRACE - Log4jESLogger - [Wind Warrior] performing state recovery...
2015-05-12-11:50:54:728 - TRACE - Log4jESLogger - [Wind Warrior] performing state recovery from [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:737 - TRACE - Log4jESLogger - [Wind Warrior] successful state recovery, importing cluster state...
2015-05-12-11:50:54:739 - DEBUG - Log4jESLogger - [Wind Warrior] processing [local-gateway-elected-state]: execute
2015-05-12-11:50:54:758 - INFO  - Log4jESLogger - [Wind Warrior] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-12-11:50:54:758 - INFO  - Log4jESLogger - [Wind Warrior] started
2015-05-12-11:50:54:764 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:50:54:765 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:50:54:766 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:50:54:767 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:50:54:768 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1]: throttling allocation [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[[Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-12-11:50:54:772 - TRACE - Log4jESLogger - [Wind Warrior] Start balancing cluster
2015-05-12-11:50:54:774 - TRACE - Log4jESLogger - [Wind Warrior] Start distributing Shards
2015-05-12-11:50:54:779 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:779 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:781 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:781 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:782 - TRACE - Log4jESLogger - [Wind Warrior] Start allocating unassigned shards
2015-05-12-11:50:54:783 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:54:784 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:54:784 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:54:784 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:54:784 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:54:785 - TRACE - Log4jESLogger - [Wind Warrior] Start balancing cluster
2015-05-12-11:50:54:786 - TRACE - Log4jESLogger - [Wind Warrior] Start distributing Shards
2015-05-12-11:50:54:786 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:786 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:787 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:787 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:54:787 - TRACE - Log4jESLogger - [Wind Warrior] Start allocating unassigned shards
2015-05-12-11:50:54:797 - TRACE - Log4jESLogger - [Wind Warrior] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[iGGh3woiQQ26eEgACm-t0A][V]
--------[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:50:54:797 - DEBUG - Log4jESLogger - [Wind Warrior] Publishing cluster state version 2
2015-05-12-11:50:54:798 - DEBUG - Log4jESLogger - [Wind Warrior] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-11:50:54:799 - DEBUG - Log4jESLogger - [Wind Warrior] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:50:54:799 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] creating index
2015-05-12-11:50:54:800 - DEBUG - Log4jESLogger - [Wind Warrior] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:50:54:801 - DEBUG - Log4jESLogger - [Wind Warrior] creating Index [mimos], shards [5]/[1]
2015-05-12-11:50:55:078 - TRACE - Log4jESLogger - [Wind Warrior] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [iGGh3woiQQ26eEgACm-t0A], scheduling a retry.
2015-05-12-11:50:55:103 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-11:50:55:105 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-11:50:55:123 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-11:50:55:185 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-11:50:55:255 - DEBUG - Log4jESLogger - [Wind Warrior] Sending mapping created for index mimos, type Programmer
2015-05-12-11:50:55:259 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] creating shard
2015-05-12-11:50:55:259 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] creating shard_id [0]
2015-05-12-11:50:55:386 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-11:50:55:391 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:50:55:391 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:50:55:397 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] state: [CREATED]
2015-05-12-11:50:55:399 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:50:55:405 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:50:55:406 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] creating shard
2015-05-12-11:50:55:406 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] starting recovery from local ...
2015-05-12-11:50:55:406 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] creating shard_id [2]
2015-05-12-11:50:55:413 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-11:50:55:414 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] starting engine
2015-05-12-11:50:55:416 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-11:50:55:419 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:50:55:420 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:50:55:421 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] state: [CREATED]
2015-05-12-11:50:55:421 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:50:55:422 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:50:55:422 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] starting recovery from local ...
2015-05-12-11:50:55:426 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-11:50:55:427 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] starting engine
2015-05-12-11:50:55:427 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] creating shard
2015-05-12-11:50:55:429 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] creating shard_id [3]
2015-05-12-11:50:55:439 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-11:50:55:441 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:50:55:441 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:50:55:442 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] state: [CREATED]
2015-05-12-11:50:55:442 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:50:55:444 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:50:55:464 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] creating shard
2015-05-12-11:50:55:464 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] creating shard_id [4]
2015-05-12-11:50:55:477 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-11:50:55:483 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] starting recovery from local ...
2015-05-12-11:50:55:485 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-11:50:55:486 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] starting engine
2015-05-12-11:50:55:493 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:50:55:508 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:50:55:510 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] state: [CREATED]
2015-05-12-11:50:55:510 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:50:55:511 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:50:55:519 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] starting recovery from local ...
2015-05-12-11:50:55:522 - TRACE - Log4jESLogger - [Wind Warrior] [_global] writing state, reason [changed]
2015-05-12-11:50:55:524 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-11:50:55:525 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] starting engine
2015-05-12-11:50:55:562 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:50:55:564 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:50:55:565 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:50:55:566 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:50:55:571 - INFO  - Log4jESLogger - [Wind Warrior] recovered [1] indices into cluster_state
2015-05-12-11:50:55:572 - DEBUG - Log4jESLogger - [Wind Warrior] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-11:50:55:573 - TRACE - Log4jESLogger - [Wind Warrior] listener to cluster state added, trying to index again
2015-05-12-11:50:55:573 - TRACE - Log4jESLogger - [Wind Warrior] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [iGGh3woiQQ26eEgACm-t0A], scheduling a retry.
2015-05-12-11:50:55:574 - TRACE - Log4jESLogger - [Wind Warrior] retry scheduling ignored as it as we already have a listener in place
2015-05-12-11:50:55:576 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][4] warming took [13ms]
2015-05-12-11:50:55:576 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][3] warming took [9.3ms]
2015-05-12-11:50:55:587 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][0] warming took [21.8ms]
2015-05-12-11:50:55:579 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:50:55:589 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:50:55:590 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] scheduling refresher every 1s
2015-05-12-11:50:55:590 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] warming took [25.5ms]
2015-05-12-11:50:55:591 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-11:50:55:592 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][4] refresh with force[true]
2015-05-12-11:50:55:588 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:50:55:591 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:50:55:593 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] scheduling refresher every 1s
2015-05-12-11:50:55:593 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-11:50:55:593 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] refresh with force[true]
2015-05-12-11:50:55:594 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][2] recovery completed from [local], took [171ms]
2015-05-12-11:50:55:594 - DEBUG - Log4jESLogger - [Wind Warrior] sending shard started for [mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:594 - DEBUG - Log4jESLogger - [Wind Warrior] received shard started for [mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:590 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] scheduling refresher every 1s
2015-05-12-11:50:55:592 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][4] recovery completed from [local], took [73ms]
2015-05-12-11:50:55:592 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] scheduling refresher every 1s
2015-05-12-11:50:55:598 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-11:50:55:598 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][3] refresh with force[true]
2015-05-12-11:50:55:599 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][3] recovery completed from [local], took [116ms]
2015-05-12-11:50:55:599 - DEBUG - Log4jESLogger - [Wind Warrior] sending shard started for [mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:599 - DEBUG - Log4jESLogger - [Wind Warrior] received shard started for [mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:597 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:50:55:597 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-11:50:55:605 - DEBUG - Log4jESLogger - [Wind Warrior] applying started shards [[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], [mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-11:50:55:607 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-11:50:55:607 - TRACE - Log4jESLogger - [Wind Warrior] Start balancing cluster
2015-05-12-11:50:55:607 - TRACE - Log4jESLogger - [Wind Warrior] Start distributing Shards
2015-05-12-11:50:55:600 - DEBUG - Log4jESLogger - [Wind Warrior] sending shard started for [mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:608 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:605 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][0] refresh with force[true]
2015-05-12-11:50:55:608 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:609 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:609 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:609 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:609 - TRACE - Log4jESLogger - [Wind Warrior] Start allocating unassigned shards
2015-05-12-11:50:55:610 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:610 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:610 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:610 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:608 - DEBUG - Log4jESLogger - [Wind Warrior] received shard started for [mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:609 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][0] recovery completed from [local], took [203ms]
2015-05-12-11:50:55:611 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:611 - DEBUG - Log4jESLogger - [Wind Warrior] sending shard started for [mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:611 - TRACE - Log4jESLogger - [Wind Warrior] Start balancing cluster
2015-05-12-11:50:55:612 - TRACE - Log4jESLogger - [Wind Warrior] Start distributing Shards
2015-05-12-11:50:55:611 - DEBUG - Log4jESLogger - [Wind Warrior] received shard started for [mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:612 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:612 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:612 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:613 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:613 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:613 - TRACE - Log4jESLogger - [Wind Warrior] Start allocating unassigned shards
2015-05-12-11:50:55:614 - TRACE - Log4jESLogger - [Wind Warrior] cluster state updated:
version [3], source [shard-started ([mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[iGGh3woiQQ26eEgACm-t0A][V]
--------[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
--------[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:50:55:614 - DEBUG - Log4jESLogger - [Wind Warrior] Publishing cluster state version 3
2015-05-12-11:50:55:614 - DEBUG - Log4jESLogger - [Wind Warrior] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-11:50:55:614 - DEBUG - Log4jESLogger - [Wind Warrior] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:50:55:615 - DEBUG - Log4jESLogger - [Wind Warrior] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:50:55:615 - TRACE - Log4jESLogger - [Wind Warrior] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-11:50:55:616 - DEBUG - Log4jESLogger - [Wind Warrior] sending shard started for [mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:50:55:616 - DEBUG - Log4jESLogger - [Wind Warrior] received shard started for [mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:50:55:617 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] creating shard
2015-05-12-11:50:55:617 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos] creating shard_id [1]
2015-05-12-11:50:55:625 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-11:50:55:633 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-11:50:55:635 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-11:50:55:653 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] state: [CREATED]
2015-05-12-11:50:55:654 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-11:50:55:655 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-11:50:55:656 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] starting recovery from local ...
2015-05-12-11:50:55:657 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-11:50:55:657 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] starting engine
2015-05-12-11:50:55:659 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-11:50:55:660 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][1] warming took [270.9micros]
2015-05-12-11:50:55:661 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-11:50:55:662 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] scheduling refresher every 1s
2015-05-12-11:50:55:662 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-11:50:55:662 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][1] refresh with force[true]
2015-05-12-11:50:55:663 - DEBUG - Log4jESLogger - [Wind Warrior] [mimos][1] recovery completed from [local], took [7ms]
2015-05-12-11:50:55:664 - DEBUG - Log4jESLogger - [Wind Warrior] sending shard started for [mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:665 - DEBUG - Log4jESLogger - [Wind Warrior] received shard started for [mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-11:50:55:669 - TRACE - Log4jESLogger - [Wind Warrior] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-11:50:55:669 - DEBUG - Log4jESLogger - [Wind Warrior] sending shard started for [mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:50:55:670 - DEBUG - Log4jESLogger - [Wind Warrior] received shard started for [mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], reason [master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-11:50:55:670 - TRACE - Log4jESLogger - [Wind Warrior] cluster changed (version 3), trying to index again
2015-05-12-11:50:55:673 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][3] writing shard state, reason [version changed from [50] to [52]]
2015-05-12-11:50:55:704 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-11:50:55:729 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] writing shard state, reason [version changed from [40] to [42]]
2015-05-12-11:50:55:746 - DEBUG - Log4jESLogger - [Wind Warrior] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-11:50:55:754 - INFO  - Log4jESLogger - [Bloodlust] version[0.90.5], pid[13121], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:50:55:755 - INFO  - Log4jESLogger - [Bloodlust] initializing ...
2015-05-12-11:50:55:755 - DEBUG - Log4jESLogger - [Bloodlust] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:50:55:756 - INFO  - Log4jESLogger - [Bloodlust] loaded [], sites []
2015-05-12-11:50:55:757 - TRACE - Log4jESLogger - [Bloodlust] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-11:50:55:757 - DEBUG - Log4jESLogger - [Bloodlust] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-11:50:55:759 - TRACE - Log4jESLogger - [Bloodlust] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:50:55:762 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-11:50:55:763 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:50:55:763 - DEBUG - Log4jESLogger - [Wind Warrior] applying started shards [[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], [mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], [mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], [mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING], [mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-11:50:55:764 - TRACE - Log4jESLogger - [Wind Warrior] Start balancing cluster
2015-05-12-11:50:55:764 - TRACE - Log4jESLogger - [Wind Warrior] Start distributing Shards
2015-05-12-11:50:55:765 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:765 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:765 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:765 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:765 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:765 - TRACE - Log4jESLogger - [Wind Warrior] Start allocating unassigned shards
2015-05-12-11:50:55:766 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:766 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:766 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:766 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:766 - TRACE - Log4jESLogger - [Wind Warrior] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:55:767 - TRACE - Log4jESLogger - [Wind Warrior] Start balancing cluster
2015-05-12-11:50:55:768 - TRACE - Log4jESLogger - [Wind Warrior] Start distributing Shards
2015-05-12-11:50:55:770 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:771 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:773 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:773 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:773 - TRACE - Log4jESLogger - [Wind Warrior] Assigned shard [[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]] to node [iGGh3woiQQ26eEgACm-t0A]
2015-05-12-11:50:55:773 - TRACE - Log4jESLogger - [Wind Warrior] Start allocating unassigned shards
2015-05-12-11:50:55:774 - TRACE - Log4jESLogger - [Wind Warrior] cluster state updated:
version [4], source [shard-started ([mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[iGGh3woiQQ26eEgACm-t0A][V]
--------[mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][2], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
--------[mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:50:55:774 - DEBUG - Log4jESLogger - [Wind Warrior] Publishing cluster state version 4
2015-05-12-11:50:55:775 - DEBUG - Log4jESLogger - [Wind Warrior] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-11:50:55:775 - DEBUG - Log4jESLogger - [Wind Warrior] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:50:55:776 - DEBUG - Log4jESLogger - [Wind Warrior] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:50:55:792 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][0] writing shard state, reason [version changed from [50] to [52]]
2015-05-12-11:50:55:826 - TRACE - Log4jESLogger - [Bloodlust] sigar loaded successfully
2015-05-12-11:50:55:838 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][4] writing shard state, reason [version changed from [52] to [54]]
2015-05-12-11:50:55:981 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][1] writing shard state, reason [version changed from [36] to [38]]
2015-05-12-11:50:56:022 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][3], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-11:50:56:023 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:50:56:023 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:50:56:023 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:50:56:023 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:50:56:023 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-11:50:56:023 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][0], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-11:50:56:024 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-11:50:56:024 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][1], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-11:50:56:024 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-11:50:56:024 - DEBUG - Log4jESLogger - [Wind Warrior] processing [shard-started ([mimos][4], node[iGGh3woiQQ26eEgACm-t0A], [P], s[INITIALIZING]), reason [master [Wind Warrior][iGGh3woiQQ26eEgACm-t0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-11:50:56:024 - DEBUG - Log4jESLogger - [Wind Warrior] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-11:50:56:026 - DEBUG - Log4jESLogger - [Wind Warrior] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-11:50:56:033 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:50:56:034 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:50:56:034 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:50:56:034 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:50:56:034 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:50:56:035 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:50:56:035 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:50:56:036 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:50:56:036 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:56:036 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:56:036 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:56:036 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:56:037 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:50:56:037 - DEBUG - Log4jESLogger - [Bloodlust] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:50:56:038 - DEBUG - Log4jESLogger - [Bloodlust] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:50:56:038 - DEBUG - Log4jESLogger - [Bloodlust] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:50:56:039 - DEBUG - Log4jESLogger - [Bloodlust] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:50:56:039 - DEBUG - Log4jESLogger - [Bloodlust] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:50:56:040 - DEBUG - Log4jESLogger - [Bloodlust] using minimum_master_nodes [-1]
2015-05-12-11:50:56:040 - DEBUG - Log4jESLogger - [Bloodlust] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:50:56:040 - DEBUG - Log4jESLogger - [Bloodlust] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:50:56:046 - DEBUG - Log4jESLogger - [Bloodlust] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:50:56:549 - DEBUG - Log4jESLogger - [Bloodlust] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@45404d5] with refresh_interval [1s]
2015-05-12-11:50:56:549 - DEBUG - Log4jESLogger - [Bloodlust] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@6dbcf214] with refresh_interval [1s]
2015-05-12-11:50:56:551 - DEBUG - Log4jESLogger - [Bloodlust] Using refresh_interval [1s]
2015-05-12-11:50:56:552 - DEBUG - Log4jESLogger - [Bloodlust] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@2e6f610d] with refresh_interval [5s]
2015-05-12-11:50:56:553 - DEBUG - Log4jESLogger - [Bloodlust] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:50:56:554 - TRACE - Log4jESLogger - [Bloodlust] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:51785 errors:0 dropped:0 overruns:0 frame:0
	TX packets:51785 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10550625 ( 10M)  TX bytes:10550625 ( 10M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:547078 errors:0 dropped:0 overruns:0 frame:0
	TX packets:276947 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:630762498 (602M)  TX bytes:29332570 ( 28M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:466 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:465 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:50:56:555 - DEBUG - Log4jESLogger - [Bloodlust] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@741f8dbe] with refresh_interval [1s]
2015-05-12-11:50:56:558 - DEBUG - Log4jESLogger - [Bloodlust] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:50:56:559 - DEBUG - Log4jESLogger - [Bloodlust] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:50:56:560 - DEBUG - Log4jESLogger - [Bloodlust] using script cache with max_size [500], expire [null]
2015-05-12-11:50:56:560 - DEBUG - Log4jESLogger - [Bloodlust] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:50:56:561 - DEBUG - Log4jESLogger - [Bloodlust] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:50:56:561 - DEBUG - Log4jESLogger - [Bloodlust] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:50:56:562 - DEBUG - Log4jESLogger - [Bloodlust] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:50:56:567 - DEBUG - Log4jESLogger - [Bloodlust] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:50:56:575 - DEBUG - Log4jESLogger - [Bloodlust] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:50:56:576 - DEBUG - Log4jESLogger - [Bloodlust] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:50:56:577 - DEBUG - Log4jESLogger - [Bloodlust] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:50:56:577 - DEBUG - Log4jESLogger - [Bloodlust] using size [-1] [-1b], expire [null]
2015-05-12-11:50:56:579 - DEBUG - Log4jESLogger - [Bloodlust] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:50:56:579 - TRACE - Log4jESLogger - [Bloodlust] [upgrade]: processing [global-14]
2015-05-12-11:50:56:581 - DEBUG - Log4jESLogger - [Bloodlust] took 1ms to load state
2015-05-12-11:50:56:581 - TRACE - Log4jESLogger - [Bloodlust] [find_latest_state]: processing [global-14]
2015-05-12-11:50:56:582 - DEBUG - Log4jESLogger - [Bloodlust] took 0s to load started shards state
2015-05-12-11:50:56:583 - DEBUG - Log4jESLogger - [Bloodlust] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:50:56:586 - DEBUG - Log4jESLogger - [Bloodlust] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:50:56:586 - DEBUG - Log4jESLogger - [Bloodlust] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:50:56:587 - DEBUG - Log4jESLogger - [Bloodlust] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:50:56:587 - DEBUG - Log4jESLogger - [Bloodlust] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:50:56:587 - DEBUG - Log4jESLogger - [Bloodlust] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:50:56:588 - DEBUG - Log4jESLogger - [Bloodlust] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:50:56:591 - INFO  - Log4jESLogger - [Bloodlust] initialized
2015-05-12-11:50:56:591 - INFO  - Log4jESLogger - [Bloodlust] starting ...
2015-05-12-11:50:56:613 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] refresh with force[false]
2015-05-12-11:50:56:640 - DEBUG - Log4jESLogger - [Bloodlust] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-11:50:56:640 - INFO  - Log4jESLogger - [Bloodlust] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-11:50:56:643 - TRACE - Log4jESLogger - [Bloodlust] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:50:56:645 - TRACE - Log4jESLogger - [Wind Warrior] [1] received ping_request from [[Bloodlust][2HGFn68KQ6q_jPXu3gkVAg][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-11:50:56:646 - TRACE - Log4jESLogger - [Bloodlust] [1] sending ping request
2015-05-12-11:50:56:698 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] warming [StandardDirectoryReader(segments_1:3:nrt _0(4.4):c1)], new [MultiReader(_0(4.4):c1)]
2015-05-12-11:50:56:699 - TRACE - Log4jESLogger - [Wind Warrior] [mimos][2] warming took [79.3micros]
2015-05-12-11:50:58:147 - TRACE - Log4jESLogger - [Bloodlust] [1] sending ping request
2015-05-12-11:50:58:147 - TRACE - Log4jESLogger - [Wind Warrior] [1] received ping_request from [[Bloodlust][2HGFn68KQ6q_jPXu3gkVAg][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-11:50:59:647 - TRACE - Log4jESLogger - [Bloodlust] full ping responses: {none}
2015-05-12-11:50:59:647 - DEBUG - Log4jESLogger - [Bloodlust] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-11:50:59:648 - DEBUG - Log4jESLogger - [Bloodlust] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-11:50:59:648 - TRACE - Log4jESLogger - [Bloodlust] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Bloodlust][2HGFn68KQ6q_jPXu3gkVAg][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[2HGFn68KQ6q_jPXu3gkVAg][V]
---- unassigned

2015-05-12-11:50:59:649 - INFO  - Log4jESLogger - [Bloodlust] new_master [Bloodlust][2HGFn68KQ6q_jPXu3gkVAg][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-11:50:59:650 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0x6cd6a5a0, /10.11.66.27:52653 => /10.11.66.27:9301]
2015-05-12-11:50:59:651 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0x470fd1c5, /10.11.66.27:52654 => /10.11.66.27:9301]
2015-05-12-11:50:59:655 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0x0863bcf8, /10.11.66.27:52655 => /10.11.66.27:9301]
2015-05-12-11:50:59:656 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0xc2fb07e2, /10.11.66.27:52656 => /10.11.66.27:9301]
2015-05-12-11:50:59:657 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0x6d1e1305, /10.11.66.27:52657 => /10.11.66.27:9301]
2015-05-12-11:50:59:657 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0x0fa208dd, /10.11.66.27:52658 => /10.11.66.27:9301]
2015-05-12-11:50:59:658 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0x83031e89, /10.11.66.27:52659 => /10.11.66.27:9301]
2015-05-12-11:50:59:658 - DEBUG - Log4jESLogger - [Bloodlust] connected to node [[Bloodlust][2HGFn68KQ6q_jPXu3gkVAg][inet[/10.11.66.27:9301]]]
2015-05-12-11:50:59:658 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0xe19ce008, /10.11.66.27:52660 => /10.11.66.27:9301]
2015-05-12-11:50:59:659 - DEBUG - Log4jESLogger - [Bloodlust] Publishing cluster state version 1
2015-05-12-11:50:59:659 - DEBUG - Log4jESLogger - [Bloodlust] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-11:50:59:660 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0xa540f451, /10.11.66.27:52661 => /10.11.66.27:9301]
2015-05-12-11:50:59:660 - DEBUG - Log4jESLogger - [Bloodlust] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:50:59:660 - DEBUG - Log4jESLogger - [Bloodlust] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:50:59:661 - TRACE - Log4jESLogger - [Bloodlust] channel opened: [id: 0x94784403, /10.11.66.27:52662 => /10.11.66.27:9301]
2015-05-12-11:50:59:661 - TRACE - Log4jESLogger - [Bloodlust] initial state set from discovery
2015-05-12-11:50:59:661 - TRACE - Log4jESLogger - [Bloodlust] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-11:50:59:662 - DEBUG - Log4jESLogger - [Bloodlust] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-11:50:59:661 - INFO  - Log4jESLogger - [Bloodlust] kodcu/2HGFn68KQ6q_jPXu3gkVAg
2015-05-12-11:50:59:662 - TRACE - Log4jESLogger - [Bloodlust] performing state recovery...
2015-05-12-11:50:59:662 - TRACE - Log4jESLogger - [Bloodlust] performing state recovery from [2HGFn68KQ6q_jPXu3gkVAg]
2015-05-12-11:50:59:664 - TRACE - Log4jESLogger - [Bloodlust] successful state recovery, importing cluster state...
2015-05-12-11:50:59:664 - DEBUG - Log4jESLogger - [Bloodlust] processing [local-gateway-elected-state]: execute
2015-05-12-11:50:59:673 - DEBUG - Log4jESLogger - [Bloodlust] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:50:59:673 - DEBUG - Log4jESLogger - [Bloodlust] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:50:59:674 - DEBUG - Log4jESLogger - [Bloodlust] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-11:50:59:677 - DEBUG - Log4jESLogger - [Bloodlust] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Bloodlust][2HGFn68KQ6q_jPXu3gkVAg][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-11:50:59:678 - DEBUG - Log4jESLogger - [Bloodlust] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Bloodlust][2HGFn68KQ6q_jPXu3gkVAg][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-11:50:59:678 - TRACE - Log4jESLogger - [Bloodlust] Start balancing cluster
2015-05-12-11:50:59:678 - TRACE - Log4jESLogger - [Bloodlust] Start distributing Shards
2015-05-12-11:50:59:678 - TRACE - Log4jESLogger - [Bloodlust] Assigned shard [[mimos][2], node[2HGFn68KQ6q_jPXu3gkVAg], [P], s[INITIALIZING]] to node [2HGFn68KQ6q_jPXu3gkVAg]
2015-05-12-11:50:59:678 - TRACE - Log4jESLogger - [Bloodlust] Assigned shard [[mimos][0], node[2HGFn68KQ6q_jPXu3gkVAg], [P], s[INITIALIZING]] to node [2HGFn68KQ6q_jPXu3gkVAg]
2015-05-12-11:50:59:678 - TRACE - Log4jESLogger - [Bloodlust] Start allocating unassigned shards
2015-05-12-11:50:59:679 - TRACE - Log4jESLogger - [Bloodlust] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:59:680 - TRACE - Log4jESLogger - [Bloodlust] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:59:680 - TRACE - Log4jESLogger - [Bloodlust] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:59:680 - TRACE - Log4jESLogger - [Bloodlust] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:59:681 - TRACE - Log4jESLogger - [Bloodlust] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-11:50:59:681 - TRACE - Log4jESLogger - [Bloodlust] Start balancing cluster
2015-05-12-11:50:59:681 - TRACE - Log4jESLogger - [Bloodlust] Start distributing Shards
2015-05-12-11:50:59:681 - TRACE - Log4jESLogger - [Bloodlust] Assigned shard [[mimos][2], node[2HGFn68KQ6q_jPXu3gkVAg], [P], s[INITIALIZING]] to node [2HGFn68KQ6q_jPXu3gkVAg]
2015-05-12-11:50:59:681 - TRACE - Log4jESLogger - [Bloodlust] Assigned shard [[mimos][0], node[2HGFn68KQ6q_jPXu3gkVAg], [P], s[INITIALIZING]] to node [2HGFn68KQ6q_jPXu3gkVAg]
2015-05-12-11:50:59:681 - TRACE - Log4jESLogger - [Bloodlust] Start allocating unassigned shards
2015-05-12-11:50:59:682 - TRACE - Log4jESLogger - [Bloodlust] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Bloodlust][2HGFn68KQ6q_jPXu3gkVAg][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[2HGFn68KQ6q_jPXu3gkVAg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[2HGFn68KQ6q_jPXu3gkVAg], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[2HGFn68KQ6q_jPXu3gkVAg][V]
--------[mimos][0], node[2HGFn68KQ6q_jPXu3gkVAg], [P], s[INITIALIZING]
--------[mimos][2], node[2HGFn68KQ6q_jPXu3gkVAg], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-11:50:59:683 - DEBUG - Log4jESLogger - [Bloodlust] Publishing cluster state version 2
2015-05-12-11:50:59:683 - DEBUG - Log4jESLogger - [Bloodlust] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-11:50:59:683 - DEBUG - Log4jESLogger - [Bloodlust] processing [reroute_rivers_node_changed]: execute
2015-05-12-11:50:59:684 - DEBUG - Log4jESLogger - [Bloodlust] [mimos] creating index
2015-05-12-11:50:59:684 - DEBUG - Log4jESLogger - [Bloodlust] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-11:50:59:684 - DEBUG - Log4jESLogger - [Bloodlust] creating Index [mimos], shards [5]/[1]
2015-05-12-11:50:59:689 - INFO  - Log4jESLogger - [Bloodlust] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-11:50:59:689 - INFO  - Log4jESLogger - [Bloodlust] started
2015-05-12-11:52:34:049 - INFO  - Log4jESLogger - [Yith] version[0.90.5], pid[13265], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-11:52:34:052 - INFO  - Log4jESLogger - [Yith] initializing ...
2015-05-12-11:52:34:052 - DEBUG - Log4jESLogger - [Yith] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-11:52:34:063 - INFO  - Log4jESLogger - [Yith] loaded [], sites []
2015-05-12-11:52:34:089 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-11:52:34:092 - TRACE - Log4jESLogger - [Yith] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-11:52:34:099 - DEBUG - Log4jESLogger - [Yith] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-11:52:34:104 - TRACE - Log4jESLogger - [Yith] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.5gb]

2015-05-12-11:52:34:650 - TRACE - Log4jESLogger - [Yith] sigar loaded successfully
2015-05-12-11:52:35:276 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-11:52:35:292 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-11:52:35:296 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-11:52:35:296 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-11:52:35:298 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-11:52:35:300 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-11:52:35:311 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-11:52:35:313 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-11:52:35:314 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:52:35:314 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:52:35:315 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:52:35:315 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:52:35:315 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-11:52:35:316 - DEBUG - Log4jESLogger - [Yith] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-11:52:35:332 - DEBUG - Log4jESLogger - [Yith] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-11:52:35:343 - DEBUG - Log4jESLogger - [Yith] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-11:52:35:348 - DEBUG - Log4jESLogger - [Yith] using initial hosts [], with concurrent_connects [10]
2015-05-12-11:52:35:350 - DEBUG - Log4jESLogger - [Yith] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-11:52:35:351 - DEBUG - Log4jESLogger - [Yith] using minimum_master_nodes [-1]
2015-05-12-11:52:35:353 - DEBUG - Log4jESLogger - [Yith] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:52:35:359 - DEBUG - Log4jESLogger - [Yith] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-11:52:35:398 - DEBUG - Log4jESLogger - [Yith] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-11:52:35:909 - DEBUG - Log4jESLogger - [Yith] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-11:52:35:914 - DEBUG - Log4jESLogger - [Yith] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-11:52:35:921 - DEBUG - Log4jESLogger - [Yith] Using refresh_interval [1s]
2015-05-12-11:52:35:921 - DEBUG - Log4jESLogger - [Yith] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-11:52:35:926 - DEBUG - Log4jESLogger - [Yith] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-11:52:35:929 - TRACE - Log4jESLogger - [Yith] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:51881 errors:0 dropped:0 overruns:0 frame:0
	TX packets:51881 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10556190 ( 10M)  TX bytes:10556190 ( 10M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:551345 errors:0 dropped:0 overruns:0 frame:0
	TX packets:279113 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:636029396 (607M)  TX bytes:29531430 ( 28M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:470 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:469 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
eth1	Link encap:Ethernet HWaddr 3A:48:4C:3A:F8:C5
	inet addr:0.0.0.0  Bcast:0.0.0.0  Mask:0.0.0.0
	UP BROADCAST MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-11:52:35:934 - DEBUG - Log4jESLogger - [Yith] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-11:52:36:188 - DEBUG - Log4jESLogger - [Yith] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-11:52:36:198 - DEBUG - Log4jESLogger - [Yith] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-11:52:36:209 - DEBUG - Log4jESLogger - [Yith] using script cache with max_size [500], expire [null]
2015-05-12-11:52:36:234 - DEBUG - Log4jESLogger - [Yith] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:52:36:236 - DEBUG - Log4jESLogger - [Yith] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:52:36:237 - DEBUG - Log4jESLogger - [Yith] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:52:36:245 - DEBUG - Log4jESLogger - [Yith] using initial_shards [quorum], list_timeout [30s]
2015-05-12-11:52:36:360 - DEBUG - Log4jESLogger - [Yith] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-11:52:36:445 - DEBUG - Log4jESLogger - [Yith] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-11:52:36:452 - DEBUG - Log4jESLogger - [Yith] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-11:52:36:453 - DEBUG - Log4jESLogger - [Yith] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-11:52:36:456 - DEBUG - Log4jESLogger - [Yith] using size [-1] [-1b], expire [null]
2015-05-12-11:52:36:473 - DEBUG - Log4jESLogger - [Yith] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-11:52:36:476 - TRACE - Log4jESLogger - [Yith] [upgrade]: processing [global-29]
2015-05-12-11:52:36:608 - DEBUG - Log4jESLogger - [Yith] took 132ms to load state
2015-05-12-11:52:36:609 - TRACE - Log4jESLogger - [Yith] [find_latest_state]: processing [global-29]
2015-05-12-11:52:36:614 - DEBUG - Log4jESLogger - [Yith] took 4ms to load started shards state
2015-05-12-11:52:36:619 - DEBUG - Log4jESLogger - [Yith] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-11:52:36:625 - DEBUG - Log4jESLogger - [Yith] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:52:36:626 - DEBUG - Log4jESLogger - [Yith] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:52:36:626 - DEBUG - Log4jESLogger - [Yith] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:52:36:627 - DEBUG - Log4jESLogger - [Yith] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-11:52:36:627 - DEBUG - Log4jESLogger - [Yith] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-11:52:36:628 - DEBUG - Log4jESLogger - [Yith] using [cluster_concurrent_rebalance] with [2]
2015-05-12-11:52:36:640 - INFO  - Log4jESLogger - [Yith] initialized
2015-05-12-11:52:36:641 - INFO  - Log4jESLogger - [Yith] starting ...
2015-05-12-11:52:36:667 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-11:52:36:668 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-11:52:36:753 - DEBUG - Log4jESLogger - [Yith] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-11:52:36:756 - INFO  - Log4jESLogger - [Yith] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-11:52:36:782 - TRACE - Log4jESLogger - [Yith] waiting for 30s for the initial state to be set by the discovery
2015-05-12-11:52:36:796 - TRACE - Log4jESLogger - [Yith] [1] sending ping request
2015-05-12-14:00:17:965 - INFO  - Log4jESLogger - [Lee Forrester] version[0.90.5], pid[16938], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-14:00:18:017 - INFO  - Log4jESLogger - [Lee Forrester] initializing ...
2015-05-12-14:00:18:018 - DEBUG - Log4jESLogger - [Lee Forrester] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-14:00:18:027 - INFO  - Log4jESLogger - [Lee Forrester] loaded [], sites []
2015-05-12-14:00:18:091 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-14:00:18:109 - TRACE - Log4jESLogger - [Lee Forrester] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-14:00:18:140 - DEBUG - Log4jESLogger - [Lee Forrester] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-14:00:18:146 - TRACE - Log4jESLogger - [Lee Forrester] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.4gb]

2015-05-12-14:00:18:901 - TRACE - Log4jESLogger - [Lee Forrester] sigar loaded successfully
2015-05-12-14:00:19:884 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-14:00:19:902 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-14:00:19:907 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-14:00:19:908 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-14:00:19:910 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-14:00:19:912 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-14:00:19:923 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-14:00:19:925 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-14:00:19:927 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:19:928 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:19:928 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:19:929 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:19:929 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:19:929 - DEBUG - Log4jESLogger - [Lee Forrester] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-14:00:19:955 - DEBUG - Log4jESLogger - [Lee Forrester] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-14:00:19:981 - DEBUG - Log4jESLogger - [Lee Forrester] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-14:00:19:988 - DEBUG - Log4jESLogger - [Lee Forrester] using initial hosts [], with concurrent_connects [10]
2015-05-12-14:00:19:992 - DEBUG - Log4jESLogger - [Lee Forrester] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-14:00:19:994 - DEBUG - Log4jESLogger - [Lee Forrester] using minimum_master_nodes [-1]
2015-05-12-14:00:19:997 - DEBUG - Log4jESLogger - [Lee Forrester] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-14:00:20:003 - DEBUG - Log4jESLogger - [Lee Forrester] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-14:00:20:069 - DEBUG - Log4jESLogger - [Lee Forrester] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-14:00:20:598 - DEBUG - Log4jESLogger - [Lee Forrester] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-14:00:20:647 - DEBUG - Log4jESLogger - [Lee Forrester] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-14:00:20:678 - DEBUG - Log4jESLogger - [Lee Forrester] Using refresh_interval [1s]
2015-05-12-14:00:20:679 - DEBUG - Log4jESLogger - [Lee Forrester] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-14:00:20:715 - DEBUG - Log4jESLogger - [Lee Forrester] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-14:00:20:718 - TRACE - Log4jESLogger - [Lee Forrester] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:160602 errors:0 dropped:0 overruns:0 frame:0
	TX packets:160602 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:20205601 ( 19M)  TX bytes:20205601 ( 19M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:894757 errors:0 dropped:0 overruns:0 frame:0
	TX packets:430516 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:1031789575 (1.0G)  TX bytes:44862855 ( 43M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:751 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:750 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-14:00:20:749 - DEBUG - Log4jESLogger - [Lee Forrester] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-14:00:21:106 - DEBUG - Log4jESLogger - [Lee Forrester] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-14:00:21:125 - DEBUG - Log4jESLogger - [Lee Forrester] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-14:00:21:133 - DEBUG - Log4jESLogger - [Lee Forrester] using script cache with max_size [500], expire [null]
2015-05-12-14:00:21:140 - DEBUG - Log4jESLogger - [Lee Forrester] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:00:21:142 - DEBUG - Log4jESLogger - [Lee Forrester] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:00:21:143 - DEBUG - Log4jESLogger - [Lee Forrester] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:00:21:148 - DEBUG - Log4jESLogger - [Lee Forrester] using initial_shards [quorum], list_timeout [30s]
2015-05-12-14:00:21:268 - DEBUG - Log4jESLogger - [Lee Forrester] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-14:00:21:342 - DEBUG - Log4jESLogger - [Lee Forrester] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-14:00:21:350 - DEBUG - Log4jESLogger - [Lee Forrester] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-14:00:21:352 - DEBUG - Log4jESLogger - [Lee Forrester] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-14:00:21:355 - DEBUG - Log4jESLogger - [Lee Forrester] using size [-1] [-1b], expire [null]
2015-05-12-14:00:21:370 - DEBUG - Log4jESLogger - [Lee Forrester] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-14:00:21:383 - TRACE - Log4jESLogger - [Lee Forrester] [upgrade]: processing [global-29]
2015-05-12-14:00:21:556 - DEBUG - Log4jESLogger - [Lee Forrester] took 172ms to load state
2015-05-12-14:00:21:558 - TRACE - Log4jESLogger - [Lee Forrester] [find_latest_state]: processing [global-29]
2015-05-12-14:00:21:601 - DEBUG - Log4jESLogger - [Lee Forrester] took 42ms to load started shards state
2015-05-12-14:00:21:604 - DEBUG - Log4jESLogger - [Lee Forrester] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-14:00:21:608 - DEBUG - Log4jESLogger - [Lee Forrester] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:00:21:609 - DEBUG - Log4jESLogger - [Lee Forrester] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:00:21:610 - DEBUG - Log4jESLogger - [Lee Forrester] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:00:21:610 - DEBUG - Log4jESLogger - [Lee Forrester] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:00:21:611 - DEBUG - Log4jESLogger - [Lee Forrester] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:00:21:611 - DEBUG - Log4jESLogger - [Lee Forrester] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:00:21:616 - INFO  - Log4jESLogger - [Lee Forrester] initialized
2015-05-12-14:00:21:617 - INFO  - Log4jESLogger - [Lee Forrester] starting ...
2015-05-12-14:00:21:660 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-14:00:21:660 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-14:00:21:740 - DEBUG - Log4jESLogger - [Lee Forrester] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-14:00:21:746 - INFO  - Log4jESLogger - [Lee Forrester] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-14:00:21:768 - TRACE - Log4jESLogger - [Lee Forrester] waiting for 30s for the initial state to be set by the discovery
2015-05-12-14:00:21:777 - TRACE - Log4jESLogger - [Lee Forrester] [1] sending ping request
2015-05-12-14:00:23:279 - TRACE - Log4jESLogger - [Lee Forrester] [1] sending ping request
2015-05-12-14:00:24:781 - TRACE - Log4jESLogger - [Lee Forrester] full ping responses: {none}
2015-05-12-14:00:24:782 - DEBUG - Log4jESLogger - [Lee Forrester] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-14:00:24:786 - DEBUG - Log4jESLogger - [Lee Forrester] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-14:00:24:788 - TRACE - Log4jESLogger - [Lee Forrester] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[4yaWkkGNT3io2sWZX9ioQw][V]
---- unassigned

2015-05-12-14:00:24:789 - INFO  - Log4jESLogger - [Lee Forrester] new_master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-12-14:00:24:822 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0x57abe26a, /10.11.66.27:53065 => /10.11.66.27:9300]
2015-05-12-14:00:24:829 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0x7b8a0351, /10.11.66.27:53066 => /10.11.66.27:9300]
2015-05-12-14:00:24:830 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0x0bdf4982, /10.11.66.27:53067 => /10.11.66.27:9300]
2015-05-12-14:00:24:830 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0xe2b40b71, /10.11.66.27:53068 => /10.11.66.27:9300]
2015-05-12-14:00:24:833 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0x08ba54ad, /10.11.66.27:53069 => /10.11.66.27:9300]
2015-05-12-14:00:24:834 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0xc39b04a5, /10.11.66.27:53070 => /10.11.66.27:9300]
2015-05-12-14:00:24:835 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0xa70f6b8b, /10.11.66.27:53071 => /10.11.66.27:9300]
2015-05-12-14:00:24:835 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0x944e8882, /10.11.66.27:53072 => /10.11.66.27:9300]
2015-05-12-14:00:24:836 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0x6cc16d87, /10.11.66.27:53073 => /10.11.66.27:9300]
2015-05-12-14:00:24:837 - TRACE - Log4jESLogger - [Lee Forrester] channel opened: [id: 0x6db73801, /10.11.66.27:53074 => /10.11.66.27:9300]
2015-05-12-14:00:24:841 - DEBUG - Log4jESLogger - [Lee Forrester] connected to node [[Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]]]
2015-05-12-14:00:24:842 - DEBUG - Log4jESLogger - [Lee Forrester] Publishing cluster state version 1
2015-05-12-14:00:24:843 - DEBUG - Log4jESLogger - [Lee Forrester] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-14:00:24:846 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:00:24:847 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:00:24:847 - TRACE - Log4jESLogger - [Lee Forrester] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-14:00:24:849 - TRACE - Log4jESLogger - [Lee Forrester] initial state set from discovery
2015-05-12-14:00:24:849 - INFO  - Log4jESLogger - [Lee Forrester] peansData/4yaWkkGNT3io2sWZX9ioQw
2015-05-12-14:00:24:850 - TRACE - Log4jESLogger - [Lee Forrester] performing state recovery...
2015-05-12-14:00:24:851 - TRACE - Log4jESLogger - [Lee Forrester] performing state recovery from [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:855 - DEBUG - Log4jESLogger - [Lee Forrester] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-14:00:24:859 - TRACE - Log4jESLogger - [Lee Forrester] successful state recovery, importing cluster state...
2015-05-12-14:00:24:860 - DEBUG - Log4jESLogger - [Lee Forrester] processing [local-gateway-elected-state]: execute
2015-05-12-14:00:24:877 - INFO  - Log4jESLogger - [Lee Forrester] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-12-14:00:24:877 - INFO  - Log4jESLogger - [Lee Forrester] started
2015-05-12-14:00:24:886 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:00:24:888 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:00:24:890 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:00:24:890 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:00:24:891 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1]: throttling allocation [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[[Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-12-14:00:24:895 - TRACE - Log4jESLogger - [Lee Forrester] Start balancing cluster
2015-05-12-14:00:24:897 - TRACE - Log4jESLogger - [Lee Forrester] Start distributing Shards
2015-05-12-14:00:24:899 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:899 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:899 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:901 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:901 - TRACE - Log4jESLogger - [Lee Forrester] Start allocating unassigned shards
2015-05-12-14:00:24:903 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:24:903 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:24:903 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:24:904 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:24:904 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:24:905 - TRACE - Log4jESLogger - [Lee Forrester] Start balancing cluster
2015-05-12-14:00:24:906 - TRACE - Log4jESLogger - [Lee Forrester] Start distributing Shards
2015-05-12-14:00:24:906 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:906 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:906 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:907 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:24:907 - TRACE - Log4jESLogger - [Lee Forrester] Start allocating unassigned shards
2015-05-12-14:00:24:910 - TRACE - Log4jESLogger - [Lee Forrester] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[4yaWkkGNT3io2sWZX9ioQw][V]
--------[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:00:24:910 - DEBUG - Log4jESLogger - [Lee Forrester] Publishing cluster state version 2
2015-05-12-14:00:24:911 - DEBUG - Log4jESLogger - [Lee Forrester] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-14:00:24:912 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:00:24:913 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] creating index
2015-05-12-14:00:24:913 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:00:24:916 - DEBUG - Log4jESLogger - [Lee Forrester] creating Index [mimos], shards [5]/[1]
2015-05-12-14:00:25:512 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-14:00:25:513 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-14:00:25:532 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-14:00:25:590 - TRACE - Log4jESLogger - [Lee Forrester] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [4yaWkkGNT3io2sWZX9ioQw], scheduling a retry.
2015-05-12-14:00:25:647 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-14:00:25:738 - DEBUG - Log4jESLogger - [Lee Forrester] Sending mapping created for index mimos, type Programmer
2015-05-12-14:00:25:741 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] creating shard
2015-05-12-14:00:25:742 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] creating shard_id [0]
2015-05-12-14:00:25:932 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-14:00:25:935 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:00:25:935 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:00:25:940 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] state: [CREATED]
2015-05-12-14:00:25:941 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:00:25:947 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:00:25:949 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] creating shard
2015-05-12-14:00:25:949 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] starting recovery from local ...
2015-05-12-14:00:25:953 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] creating shard_id [2]
2015-05-12-14:00:25:979 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-14:00:25:980 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] starting engine
2015-05-12-14:00:25:995 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-14:00:25:996 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:00:25:996 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:00:25:997 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] state: [CREATED]
2015-05-12-14:00:25:998 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:00:25:999 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:00:26:000 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] creating shard
2015-05-12-14:00:26:003 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] creating shard_id [3]
2015-05-12-14:00:26:000 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] starting recovery from local ...
2015-05-12-14:00:26:024 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-14:00:26:026 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-14:00:26:027 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:00:26:028 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:00:26:028 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] starting engine
2015-05-12-14:00:26:030 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] state: [CREATED]
2015-05-12-14:00:26:034 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:00:26:035 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:00:26:038 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] creating shard
2015-05-12-14:00:26:038 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] starting recovery from local ...
2015-05-12-14:00:26:039 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] creating shard_id [4]
2015-05-12-14:00:26:044 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-14:00:26:047 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] starting engine
2015-05-12-14:00:26:056 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-14:00:26:060 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:00:26:061 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:00:26:062 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] state: [CREATED]
2015-05-12-14:00:26:067 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:00:26:068 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:00:26:069 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] starting recovery from local ...
2015-05-12-14:00:26:073 - TRACE - Log4jESLogger - [Lee Forrester] [_global] writing state, reason [changed]
2015-05-12-14:00:26:078 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-14:00:26:078 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] starting engine
2015-05-12-14:00:26:115 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:00:26:117 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:00:26:119 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:00:26:115 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:00:26:120 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][4] warming took [765.6micros]
2015-05-12-14:00:26:120 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][3] warming took [2ms]
2015-05-12-14:00:26:128 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][0] warming took [10.2ms]
2015-05-12-14:00:26:128 - INFO  - Log4jESLogger - [Lee Forrester] recovered [1] indices into cluster_state
2015-05-12-14:00:26:130 - DEBUG - Log4jESLogger - [Lee Forrester] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-14:00:26:137 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:00:26:131 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:00:26:139 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] scheduling refresher every 1s
2015-05-12-14:00:26:139 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] warming took [106.1micros]
2015-05-12-14:00:26:136 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:00:26:140 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] scheduling refresher every 1s
2015-05-12-14:00:26:141 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:00:26:141 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] scheduling refresher every 1s
2015-05-12-14:00:26:131 - TRACE - Log4jESLogger - [Lee Forrester] listener to cluster state added, trying to index again
2015-05-12-14:00:26:142 - TRACE - Log4jESLogger - [Lee Forrester] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [4yaWkkGNT3io2sWZX9ioQw], scheduling a retry.
2015-05-12-14:00:26:142 - TRACE - Log4jESLogger - [Lee Forrester] retry scheduling ignored as it as we already have a listener in place
2015-05-12-14:00:26:139 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] scheduling refresher every 1s
2015-05-12-14:00:26:144 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-14:00:26:145 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][3] refresh with force[true]
2015-05-12-14:00:26:145 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][3] recovery completed from [local], took [107ms]
2015-05-12-14:00:26:145 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:146 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:147 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-14:00:26:147 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][4] refresh with force[true]
2015-05-12-14:00:26:148 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-14:00:26:148 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] refresh with force[true]
2015-05-12-14:00:26:149 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][2] recovery completed from [local], took [148ms]
2015-05-12-14:00:26:148 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:00:26:150 - DEBUG - Log4jESLogger - [Lee Forrester] applying started shards [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-14:00:26:150 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:00:26:151 - TRACE - Log4jESLogger - [Lee Forrester] Start balancing cluster
2015-05-12-14:00:26:151 - TRACE - Log4jESLogger - [Lee Forrester] Start distributing Shards
2015-05-12-14:00:26:151 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:151 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:148 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-14:00:26:152 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][0] refresh with force[true]
2015-05-12-14:00:26:152 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][0] recovery completed from [local], took [203ms]
2015-05-12-14:00:26:153 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:153 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:148 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][4] recovery completed from [local], took [79ms]
2015-05-12-14:00:26:149 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:154 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:153 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:157 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:157 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:158 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:158 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:158 - TRACE - Log4jESLogger - [Lee Forrester] Start allocating unassigned shards
2015-05-12-14:00:26:158 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:159 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:159 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:159 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:159 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:160 - TRACE - Log4jESLogger - [Lee Forrester] Start balancing cluster
2015-05-12-14:00:26:160 - TRACE - Log4jESLogger - [Lee Forrester] Start distributing Shards
2015-05-12-14:00:26:160 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:160 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:163 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:163 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:163 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:164 - TRACE - Log4jESLogger - [Lee Forrester] Start allocating unassigned shards
2015-05-12-14:00:26:165 - TRACE - Log4jESLogger - [Lee Forrester] cluster state updated:
version [3], source [shard-started ([mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[4yaWkkGNT3io2sWZX9ioQw][V]
--------[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:00:26:165 - DEBUG - Log4jESLogger - [Lee Forrester] Publishing cluster state version 3
2015-05-12-14:00:26:165 - DEBUG - Log4jESLogger - [Lee Forrester] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-14:00:26:166 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:00:26:167 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:00:26:168 - TRACE - Log4jESLogger - [Lee Forrester] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-14:00:26:169 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-14:00:26:170 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-14:00:26:171 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] creating shard
2015-05-12-14:00:26:171 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos] creating shard_id [1]
2015-05-12-14:00:26:197 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-14:00:26:198 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:00:26:200 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:00:26:203 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] state: [CREATED]
2015-05-12-14:00:26:204 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:00:26:205 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:00:26:205 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] starting recovery from local ...
2015-05-12-14:00:26:206 - TRACE - Log4jESLogger - [Lee Forrester] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-14:00:26:206 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-14:00:26:206 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-14:00:26:207 - TRACE - Log4jESLogger - [Lee Forrester] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-14:00:26:208 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-14:00:26:208 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-14:00:26:208 - TRACE - Log4jESLogger - [Lee Forrester] cluster changed (version 3), trying to index again
2015-05-12-14:00:26:209 - TRACE - Log4jESLogger - [Lee Forrester] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [4yaWkkGNT3io2sWZX9ioQw], scheduling a retry.
2015-05-12-14:00:26:209 - TRACE - Log4jESLogger - [Lee Forrester] retry scheduling ignored as it as we already have a listener in place
2015-05-12-14:00:26:210 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][3] writing shard state, reason [version changed from [52] to [54]]
2015-05-12-14:00:26:239 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-14:00:26:273 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] starting engine
2015-05-12-14:00:26:302 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-14:00:26:302 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:00:26:302 - DEBUG - Log4jESLogger - [Lee Forrester] applying started shards [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], [mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], [mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], [mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], [mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], [mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-14:00:26:303 - TRACE - Log4jESLogger - [Lee Forrester] Start balancing cluster
2015-05-12-14:00:26:303 - TRACE - Log4jESLogger - [Lee Forrester] Start distributing Shards
2015-05-12-14:00:26:303 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:303 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:303 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:304 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:00:26:304 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:304 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:304 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][1] warming took [169.8micros]
2015-05-12-14:00:26:304 - TRACE - Log4jESLogger - [Lee Forrester] Start allocating unassigned shards
2015-05-12-14:00:26:305 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:305 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:305 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:00:26:305 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:305 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] scheduling refresher every 1s
2015-05-12-14:00:26:306 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:306 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-14:00:26:306 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:306 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][1] refresh with force[true]
2015-05-12-14:00:26:306 - TRACE - Log4jESLogger - [Lee Forrester] Start balancing cluster
2015-05-12-14:00:26:306 - DEBUG - Log4jESLogger - [Lee Forrester] [mimos][1] recovery completed from [local], took [101ms]
2015-05-12-14:00:26:306 - TRACE - Log4jESLogger - [Lee Forrester] Start distributing Shards
2015-05-12-14:00:26:307 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:307 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:307 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:00:26:307 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:307 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:307 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:307 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:308 - TRACE - Log4jESLogger - [Lee Forrester] Start allocating unassigned shards
2015-05-12-14:00:26:308 - TRACE - Log4jESLogger - [Lee Forrester] cluster state updated:
version [4], source [shard-started ([mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[4yaWkkGNT3io2sWZX9ioQw][V]
--------[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]
--------[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:00:26:309 - DEBUG - Log4jESLogger - [Lee Forrester] Publishing cluster state version 4
2015-05-12-14:00:26:309 - DEBUG - Log4jESLogger - [Lee Forrester] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-14:00:26:309 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:00:26:310 - TRACE - Log4jESLogger - [Lee Forrester] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-12-14:00:26:310 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:00:26:311 - DEBUG - Log4jESLogger - [Lee Forrester] sending shard started for [mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-14:00:26:311 - DEBUG - Log4jESLogger - [Lee Forrester] received shard started for [mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-12-14:00:26:312 - TRACE - Log4jESLogger - [Lee Forrester] cluster changed (version 4), trying to index again
2015-05-12-14:00:26:313 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][0] writing shard state, reason [version changed from [52] to [54]]
2015-05-12-14:00:26:328 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-14:00:26:361 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][4] writing shard state, reason [version changed from [54] to [56]]
2015-05-12-14:00:26:387 - DEBUG - Log4jESLogger - [Lee Forrester] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-14:00:26:432 - INFO  - Log4jESLogger - [Guthrie, Jebediah] version[0.90.5], pid[16938], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-14:00:26:432 - INFO  - Log4jESLogger - [Guthrie, Jebediah] initializing ...
2015-05-12-14:00:26:432 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-14:00:26:433 - INFO  - Log4jESLogger - [Guthrie, Jebediah] loaded [], sites []
2015-05-12-14:00:26:433 - TRACE - Log4jESLogger - [Guthrie, Jebediah] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-14:00:26:434 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-14:00:26:434 - TRACE - Log4jESLogger - [Guthrie, Jebediah] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.4gb]

2015-05-12-14:00:26:445 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] writing shard state, reason [version changed from [42] to [44]]
2015-05-12-14:00:26:472 - TRACE - Log4jESLogger - [Guthrie, Jebediah] sigar loaded successfully
2015-05-12-14:00:26:479 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-14:00:26:479 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:00:26:480 - DEBUG - Log4jESLogger - [Lee Forrester] applying started shards [[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING], [mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-14:00:26:480 - TRACE - Log4jESLogger - [Lee Forrester] Start balancing cluster
2015-05-12-14:00:26:481 - TRACE - Log4jESLogger - [Lee Forrester] Start distributing Shards
2015-05-12-14:00:26:481 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:481 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:481 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:481 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:481 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:481 - TRACE - Log4jESLogger - [Lee Forrester] Start allocating unassigned shards
2015-05-12-14:00:26:482 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:482 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:482 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:483 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:483 - TRACE - Log4jESLogger - [Lee Forrester] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:26:483 - TRACE - Log4jESLogger - [Lee Forrester] Start balancing cluster
2015-05-12-14:00:26:483 - TRACE - Log4jESLogger - [Lee Forrester] Start distributing Shards
2015-05-12-14:00:26:483 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:483 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:484 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:484 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:484 - TRACE - Log4jESLogger - [Lee Forrester] Assigned shard [[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]] to node [4yaWkkGNT3io2sWZX9ioQw]
2015-05-12-14:00:26:484 - TRACE - Log4jESLogger - [Lee Forrester] Start allocating unassigned shards
2015-05-12-14:00:26:487 - TRACE - Log4jESLogger - [Lee Forrester] cluster state updated:
version [5], source [shard-started ([mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[4yaWkkGNT3io2sWZX9ioQw][V]
--------[mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][3], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
--------[mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:00:26:488 - DEBUG - Log4jESLogger - [Lee Forrester] Publishing cluster state version 5
2015-05-12-14:00:26:488 - DEBUG - Log4jESLogger - [Lee Forrester] Set cluster state to version 5. Broadcasting to listeners.
2015-05-12-14:00:26:488 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:00:26:496 - DEBUG - Log4jESLogger - [Lee Forrester] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:00:26:502 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][1] writing shard state, reason [version changed from [38] to [40]]
2015-05-12-14:00:26:676 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 5)
2015-05-12-14:00:26:676 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:00:26:676 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-14:00:26:677 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-14:00:26:677 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][0], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-14:00:26:677 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-14:00:26:677 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][2], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-14:00:26:677 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-14:00:26:677 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][4], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-14:00:26:677 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:00:26:677 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-14:00:26:678 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: execute
2015-05-12-14:00:26:678 - DEBUG - Log4jESLogger - [Lee Forrester] processing [shard-started ([mimos][1], node[4yaWkkGNT3io2sWZX9ioQw], [P], s[INITIALIZING]), reason [master [Lee Forrester][4yaWkkGNT3io2sWZX9ioQw][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]]: no change in cluster_state
2015-05-12-14:00:26:678 - DEBUG - Log4jESLogger - [Lee Forrester] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-14:00:26:684 - DEBUG - Log4jESLogger - [Lee Forrester] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-14:00:26:708 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-14:00:26:709 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-14:00:26:709 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-14:00:26:710 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-14:00:26:710 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-14:00:26:711 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-14:00:26:711 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-14:00:26:711 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-14:00:26:712 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:26:712 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:26:712 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:26:713 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:26:713 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:00:26:713 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-14:00:26:714 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-14:00:26:715 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-14:00:26:715 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using initial hosts [], with concurrent_connects [10]
2015-05-12-14:00:26:716 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-14:00:26:716 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using minimum_master_nodes [-1]
2015-05-12-14:00:26:717 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-14:00:26:717 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-14:00:26:724 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-14:00:27:142 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] refresh with force[false]
2015-05-12-14:00:27:211 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] warming [StandardDirectoryReader(segments_1:3:nrt _0(4.4):c1)], new [MultiReader(_0(4.4):c1)]
2015-05-12-14:00:27:211 - TRACE - Log4jESLogger - [Lee Forrester] [mimos][2] warming took [109.5micros]
2015-05-12-14:00:27:228 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@5ba26eb0] with refresh_interval [1s]
2015-05-12-14:00:27:229 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@66f0548d] with refresh_interval [1s]
2015-05-12-14:00:27:232 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Using refresh_interval [1s]
2015-05-12-14:00:27:232 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@6daf7d37] with refresh_interval [5s]
2015-05-12-14:00:27:233 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-14:00:27:235 - TRACE - Log4jESLogger - [Guthrie, Jebediah] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:160632 errors:0 dropped:0 overruns:0 frame:0
	TX packets:160632 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:20207321 ( 19M)  TX bytes:20207321 ( 19M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:894850 errors:0 dropped:0 overruns:0 frame:0
	TX packets:430525 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:1031798098 (1.0G)  TX bytes:44864849 ( 43M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:751 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:750 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-14:00:27:236 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@9fc9f91] with refresh_interval [1s]
2015-05-12-14:00:27:239 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-14:00:27:239 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-14:00:27:241 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using script cache with max_size [500], expire [null]
2015-05-12-14:00:27:241 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:00:27:242 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:00:27:242 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:00:27:243 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using initial_shards [quorum], list_timeout [30s]
2015-05-12-14:00:27:248 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-14:00:27:259 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-14:00:27:260 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-14:00:27:260 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-14:00:27:261 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using size [-1] [-1b], expire [null]
2015-05-12-14:00:27:272 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-14:00:27:287 - TRACE - Log4jESLogger - [Guthrie, Jebediah] [upgrade]: processing [global-14]
2015-05-12-14:00:27:348 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] took 60ms to load state
2015-05-12-14:00:27:348 - TRACE - Log4jESLogger - [Guthrie, Jebediah] [find_latest_state]: processing [global-14]
2015-05-12-14:00:27:398 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] took 49ms to load started shards state
2015-05-12-14:00:27:399 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-14:00:27:402 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:00:27:402 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:00:27:402 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:00:27:403 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:00:27:403 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:00:27:403 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:00:27:408 - INFO  - Log4jESLogger - [Guthrie, Jebediah] initialized
2015-05-12-14:00:27:409 - INFO  - Log4jESLogger - [Guthrie, Jebediah] starting ...
2015-05-12-14:00:27:432 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-14:00:27:434 - INFO  - Log4jESLogger - [Guthrie, Jebediah] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-14:00:27:437 - TRACE - Log4jESLogger - [Guthrie, Jebediah] waiting for 30s for the initial state to be set by the discovery
2015-05-12-14:00:27:439 - TRACE - Log4jESLogger - [Lee Forrester] [1] received ping_request from [[Guthrie, Jebediah][tqvHTzR5R_SmN7JBewWc4Q][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-14:00:27:439 - TRACE - Log4jESLogger - [Guthrie, Jebediah] [1] sending ping request
2015-05-12-14:00:28:940 - TRACE - Log4jESLogger - [Guthrie, Jebediah] [1] sending ping request
2015-05-12-14:00:28:941 - TRACE - Log4jESLogger - [Lee Forrester] [1] received ping_request from [[Guthrie, Jebediah][tqvHTzR5R_SmN7JBewWc4Q][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-14:00:30:441 - TRACE - Log4jESLogger - [Guthrie, Jebediah] full ping responses: {none}
2015-05-12-14:00:30:441 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-14:00:30:441 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-14:00:30:442 - TRACE - Log4jESLogger - [Guthrie, Jebediah] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Guthrie, Jebediah][tqvHTzR5R_SmN7JBewWc4Q][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[tqvHTzR5R_SmN7JBewWc4Q][V]
---- unassigned

2015-05-12-14:00:30:442 - INFO  - Log4jESLogger - [Guthrie, Jebediah] new_master [Guthrie, Jebediah][tqvHTzR5R_SmN7JBewWc4Q][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-14:00:30:443 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0xa0030161, /10.11.66.27:54539 => /10.11.66.27:9301]
2015-05-12-14:00:30:444 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0x5f4a705b, /10.11.66.27:54540 => /10.11.66.27:9301]
2015-05-12-14:00:30:444 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0x5a6ec37a, /10.11.66.27:54541 => /10.11.66.27:9301]
2015-05-12-14:00:30:446 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0x669396dd, /10.11.66.27:54542 => /10.11.66.27:9301]
2015-05-12-14:00:30:447 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0xe7a52cfc, /10.11.66.27:54543 => /10.11.66.27:9301]
2015-05-12-14:00:30:449 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0x7270fa53, /10.11.66.27:54544 => /10.11.66.27:9301]
2015-05-12-14:00:30:449 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] connected to node [[Guthrie, Jebediah][tqvHTzR5R_SmN7JBewWc4Q][inet[/10.11.66.27:9301]]]
2015-05-12-14:00:30:449 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Publishing cluster state version 1
2015-05-12-14:00:30:449 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-14:00:30:449 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0x45ffcfcc, /10.11.66.27:54545 => /10.11.66.27:9301]
2015-05-12-14:00:30:457 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0xf2befd2c, /10.11.66.27:54546 => /10.11.66.27:9301]
2015-05-12-14:00:30:457 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0xd4ac1d64, /10.11.66.27:54547 => /10.11.66.27:9301]
2015-05-12-14:00:30:461 - TRACE - Log4jESLogger - [Guthrie, Jebediah] channel opened: [id: 0x6b8a9afd, /10.11.66.27:54548 => /10.11.66.27:9301]
2015-05-12-14:00:30:463 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-14:00:30:464 - TRACE - Log4jESLogger - [Guthrie, Jebediah] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-14:00:30:464 - TRACE - Log4jESLogger - [Guthrie, Jebediah] initial state set from discovery
2015-05-12-14:00:30:463 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:00:30:465 - INFO  - Log4jESLogger - [Guthrie, Jebediah] kodcu/tqvHTzR5R_SmN7JBewWc4Q
2015-05-12-14:00:30:465 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:00:30:466 - TRACE - Log4jESLogger - [Guthrie, Jebediah] performing state recovery...
2015-05-12-14:00:30:466 - TRACE - Log4jESLogger - [Guthrie, Jebediah] performing state recovery from [tqvHTzR5R_SmN7JBewWc4Q]
2015-05-12-14:00:30:467 - TRACE - Log4jESLogger - [Guthrie, Jebediah] successful state recovery, importing cluster state...
2015-05-12-14:00:30:468 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] processing [local-gateway-elected-state]: execute
2015-05-12-14:00:30:470 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-14:00:30:471 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Guthrie, Jebediah][tqvHTzR5R_SmN7JBewWc4Q][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-14:00:30:472 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Guthrie, Jebediah][tqvHTzR5R_SmN7JBewWc4Q][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-14:00:30:472 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-14:00:30:473 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-14:00:30:474 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Start balancing cluster
2015-05-12-14:00:30:481 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Start distributing Shards
2015-05-12-14:00:30:481 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Assigned shard [[mimos][2], node[tqvHTzR5R_SmN7JBewWc4Q], [P], s[INITIALIZING]] to node [tqvHTzR5R_SmN7JBewWc4Q]
2015-05-12-14:00:30:481 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Assigned shard [[mimos][0], node[tqvHTzR5R_SmN7JBewWc4Q], [P], s[INITIALIZING]] to node [tqvHTzR5R_SmN7JBewWc4Q]
2015-05-12-14:00:30:481 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Start allocating unassigned shards
2015-05-12-14:00:30:482 - TRACE - Log4jESLogger - [Guthrie, Jebediah] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:30:482 - TRACE - Log4jESLogger - [Guthrie, Jebediah] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:30:482 - TRACE - Log4jESLogger - [Guthrie, Jebediah] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:30:482 - TRACE - Log4jESLogger - [Guthrie, Jebediah] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:30:482 - TRACE - Log4jESLogger - [Guthrie, Jebediah] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:00:30:483 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Start balancing cluster
2015-05-12-14:00:30:483 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Start distributing Shards
2015-05-12-14:00:30:483 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Assigned shard [[mimos][2], node[tqvHTzR5R_SmN7JBewWc4Q], [P], s[INITIALIZING]] to node [tqvHTzR5R_SmN7JBewWc4Q]
2015-05-12-14:00:30:483 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Assigned shard [[mimos][0], node[tqvHTzR5R_SmN7JBewWc4Q], [P], s[INITIALIZING]] to node [tqvHTzR5R_SmN7JBewWc4Q]
2015-05-12-14:00:30:483 - TRACE - Log4jESLogger - [Guthrie, Jebediah] Start allocating unassigned shards
2015-05-12-14:00:30:484 - TRACE - Log4jESLogger - [Guthrie, Jebediah] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Guthrie, Jebediah][tqvHTzR5R_SmN7JBewWc4Q][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[tqvHTzR5R_SmN7JBewWc4Q], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[tqvHTzR5R_SmN7JBewWc4Q], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[tqvHTzR5R_SmN7JBewWc4Q][V]
--------[mimos][0], node[tqvHTzR5R_SmN7JBewWc4Q], [P], s[INITIALIZING]
--------[mimos][2], node[tqvHTzR5R_SmN7JBewWc4Q], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:00:30:484 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Publishing cluster state version 2
2015-05-12-14:00:30:484 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-14:00:30:485 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:00:30:489 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:00:30:489 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] [mimos] creating index
2015-05-12-14:00:30:489 - DEBUG - Log4jESLogger - [Guthrie, Jebediah] creating Index [mimos], shards [5]/[1]
2015-05-12-14:00:30:509 - INFO  - Log4jESLogger - [Guthrie, Jebediah] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-14:00:30:510 - INFO  - Log4jESLogger - [Guthrie, Jebediah] started
2015-05-12-14:30:57:476 - INFO  - Log4jESLogger - [Presence] version[0.90.5], pid[19489], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-14:30:57:480 - INFO  - Log4jESLogger - [Presence] initializing ...
2015-05-12-14:30:57:480 - DEBUG - Log4jESLogger - [Presence] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-14:30:57:490 - INFO  - Log4jESLogger - [Presence] loaded [], sites []
2015-05-12-14:30:57:518 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-14:30:57:521 - TRACE - Log4jESLogger - [Presence] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-14:30:57:530 - DEBUG - Log4jESLogger - [Presence] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-14:30:57:536 - TRACE - Log4jESLogger - [Presence] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.4gb]

2015-05-12-14:30:58:137 - TRACE - Log4jESLogger - [Presence] sigar loaded successfully
2015-05-12-14:30:58:766 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-14:30:58:772 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-14:30:58:776 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-14:30:58:776 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-14:30:58:779 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-14:30:58:781 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-14:30:58:791 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-14:30:58:793 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-14:30:58:795 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:30:58:795 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:30:58:796 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:30:58:796 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:30:58:796 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:30:58:797 - DEBUG - Log4jESLogger - [Presence] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-14:30:58:824 - DEBUG - Log4jESLogger - [Presence] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-14:30:58:835 - DEBUG - Log4jESLogger - [Presence] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-14:30:58:841 - DEBUG - Log4jESLogger - [Presence] using initial hosts [], with concurrent_connects [10]
2015-05-12-14:30:58:843 - DEBUG - Log4jESLogger - [Presence] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-14:30:58:845 - DEBUG - Log4jESLogger - [Presence] using minimum_master_nodes [-1]
2015-05-12-14:30:58:846 - DEBUG - Log4jESLogger - [Presence] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-14:30:58:853 - DEBUG - Log4jESLogger - [Presence] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-14:30:58:890 - DEBUG - Log4jESLogger - [Presence] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-14:30:59:406 - DEBUG - Log4jESLogger - [Presence] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-12-14:30:59:413 - DEBUG - Log4jESLogger - [Presence] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-12-14:30:59:425 - DEBUG - Log4jESLogger - [Presence] Using refresh_interval [1s]
2015-05-12-14:30:59:426 - DEBUG - Log4jESLogger - [Presence] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-12-14:30:59:432 - DEBUG - Log4jESLogger - [Presence] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-14:30:59:435 - TRACE - Log4jESLogger - [Presence] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:185706 errors:0 dropped:0 overruns:0 frame:0
	TX packets:185706 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:22870510 ( 22M)  TX bytes:22870510 ( 22M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:960405 errors:0 dropped:0 overruns:0 frame:0
	TX packets:464301 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:1102842003 (1.0G)  TX bytes:48243889 ( 46M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:820 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:819 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-14:30:59:508 - DEBUG - Log4jESLogger - [Presence] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-12-14:30:59:737 - DEBUG - Log4jESLogger - [Presence] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-14:30:59:745 - DEBUG - Log4jESLogger - [Presence] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-14:30:59:756 - DEBUG - Log4jESLogger - [Presence] using script cache with max_size [500], expire [null]
2015-05-12-14:30:59:762 - DEBUG - Log4jESLogger - [Presence] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:30:59:764 - DEBUG - Log4jESLogger - [Presence] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:30:59:765 - DEBUG - Log4jESLogger - [Presence] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:30:59:769 - DEBUG - Log4jESLogger - [Presence] using initial_shards [quorum], list_timeout [30s]
2015-05-12-14:30:59:861 - DEBUG - Log4jESLogger - [Presence] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-14:30:59:931 - DEBUG - Log4jESLogger - [Presence] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-14:30:59:941 - DEBUG - Log4jESLogger - [Presence] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-14:30:59:943 - DEBUG - Log4jESLogger - [Presence] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-14:30:59:945 - DEBUG - Log4jESLogger - [Presence] using size [-1] [-1b], expire [null]
2015-05-12-14:30:59:964 - DEBUG - Log4jESLogger - [Presence] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-14:30:59:979 - TRACE - Log4jESLogger - [Presence] [upgrade]: processing [global-30]
2015-05-12-14:31:00:114 - DEBUG - Log4jESLogger - [Presence] took 133ms to load state
2015-05-12-14:31:00:115 - TRACE - Log4jESLogger - [Presence] [find_latest_state]: processing [global-30]
2015-05-12-14:31:00:148 - DEBUG - Log4jESLogger - [Presence] took 33ms to load started shards state
2015-05-12-14:31:00:150 - DEBUG - Log4jESLogger - [Presence] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-14:31:00:155 - DEBUG - Log4jESLogger - [Presence] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:31:00:157 - DEBUG - Log4jESLogger - [Presence] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:31:00:158 - DEBUG - Log4jESLogger - [Presence] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:31:00:160 - DEBUG - Log4jESLogger - [Presence] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:31:00:161 - DEBUG - Log4jESLogger - [Presence] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:31:00:161 - DEBUG - Log4jESLogger - [Presence] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:31:00:167 - INFO  - Log4jESLogger - [Presence] initialized
2015-05-12-14:31:00:167 - INFO  - Log4jESLogger - [Presence] starting ...
2015-05-12-14:31:00:193 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-12-14:31:00:193 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-12-14:31:00:269 - DEBUG - Log4jESLogger - [Presence] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-12-14:31:00:273 - INFO  - Log4jESLogger - [Presence] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-12-14:31:00:294 - TRACE - Log4jESLogger - [Presence] waiting for 30s for the initial state to be set by the discovery
2015-05-12-14:31:00:302 - TRACE - Log4jESLogger - [Presence] [1] sending ping request
2015-05-12-14:31:01:804 - TRACE - Log4jESLogger - [Presence] [1] sending ping request
2015-05-12-14:31:03:307 - TRACE - Log4jESLogger - [Presence] full ping responses: {none}
2015-05-12-14:31:03:307 - DEBUG - Log4jESLogger - [Presence] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-14:31:03:311 - DEBUG - Log4jESLogger - [Presence] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-14:31:03:313 - TRACE - Log4jESLogger - [Presence] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[LpesBuwwTzepsC-0xYyQXg][V]
---- unassigned

2015-05-12-14:31:03:314 - INFO  - Log4jESLogger - [Presence] new_master [Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-12-14:31:03:330 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0x0a031d2f, /10.11.66.27:54663 => /10.11.66.27:9300]
2015-05-12-14:31:03:335 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0xbc14a3ba, /10.11.66.27:54664 => /10.11.66.27:9300]
2015-05-12-14:31:03:341 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0xd66da733, /10.11.66.27:54665 => /10.11.66.27:9300]
2015-05-12-14:31:03:342 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0x69470ddc, /10.11.66.27:54666 => /10.11.66.27:9300]
2015-05-12-14:31:03:342 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0xded39d9b, /10.11.66.27:54667 => /10.11.66.27:9300]
2015-05-12-14:31:03:343 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0xd1e58c10, /10.11.66.27:54668 => /10.11.66.27:9300]
2015-05-12-14:31:03:343 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0x4de4c5e6, /10.11.66.27:54669 => /10.11.66.27:9300]
2015-05-12-14:31:03:346 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0x83eea2ee, /10.11.66.27:54670 => /10.11.66.27:9300]
2015-05-12-14:31:03:348 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0x428707b6, /10.11.66.27:54671 => /10.11.66.27:9300]
2015-05-12-14:31:03:349 - TRACE - Log4jESLogger - [Presence] channel opened: [id: 0xd2f160eb, /10.11.66.27:54672 => /10.11.66.27:9300]
2015-05-12-14:31:03:354 - DEBUG - Log4jESLogger - [Presence] connected to node [[Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]]]
2015-05-12-14:31:03:356 - DEBUG - Log4jESLogger - [Presence] Publishing cluster state version 1
2015-05-12-14:31:03:356 - DEBUG - Log4jESLogger - [Presence] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-14:31:03:359 - DEBUG - Log4jESLogger - [Presence] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:31:03:360 - DEBUG - Log4jESLogger - [Presence] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:31:03:360 - TRACE - Log4jESLogger - [Presence] initial state set from discovery
2015-05-12-14:31:03:360 - INFO  - Log4jESLogger - [Presence] peansData/LpesBuwwTzepsC-0xYyQXg
2015-05-12-14:31:03:361 - TRACE - Log4jESLogger - [Presence] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-14:31:03:362 - DEBUG - Log4jESLogger - [Presence] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-14:31:03:362 - TRACE - Log4jESLogger - [Presence] performing state recovery...
2015-05-12-14:31:03:362 - TRACE - Log4jESLogger - [Presence] performing state recovery from [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:372 - TRACE - Log4jESLogger - [Presence] successful state recovery, importing cluster state...
2015-05-12-14:31:03:373 - DEBUG - Log4jESLogger - [Presence] processing [local-gateway-elected-state]: execute
2015-05-12-14:31:03:387 - INFO  - Log4jESLogger - [Presence] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-12-14:31:03:388 - INFO  - Log4jESLogger - [Presence] started
2015-05-12-14:31:03:398 - DEBUG - Log4jESLogger - [Presence] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:31:03:400 - DEBUG - Log4jESLogger - [Presence] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:31:03:401 - DEBUG - Log4jESLogger - [Presence] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:31:03:402 - DEBUG - Log4jESLogger - [Presence] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:31:03:403 - DEBUG - Log4jESLogger - [Presence] [mimos][1]: throttling allocation [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[[Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-12-14:31:03:407 - TRACE - Log4jESLogger - [Presence] Start balancing cluster
2015-05-12-14:31:03:408 - TRACE - Log4jESLogger - [Presence] Start distributing Shards
2015-05-12-14:31:03:409 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:410 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:410 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:411 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:432 - TRACE - Log4jESLogger - [Presence] Start allocating unassigned shards
2015-05-12-14:31:03:434 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:03:434 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:03:435 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:03:435 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:03:436 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:03:438 - TRACE - Log4jESLogger - [Presence] Start balancing cluster
2015-05-12-14:31:03:442 - TRACE - Log4jESLogger - [Presence] Start distributing Shards
2015-05-12-14:31:03:443 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:452 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:453 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:453 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:03:453 - TRACE - Log4jESLogger - [Presence] Start allocating unassigned shards
2015-05-12-14:31:03:458 - TRACE - Log4jESLogger - [Presence] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[LpesBuwwTzepsC-0xYyQXg][V]
--------[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:31:03:458 - DEBUG - Log4jESLogger - [Presence] Publishing cluster state version 2
2015-05-12-14:31:03:459 - DEBUG - Log4jESLogger - [Presence] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-14:31:03:460 - DEBUG - Log4jESLogger - [Presence] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:31:03:468 - DEBUG - Log4jESLogger - [Presence] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:31:03:474 - DEBUG - Log4jESLogger - [Presence] [mimos] creating index
2015-05-12-14:31:03:474 - DEBUG - Log4jESLogger - [Presence] creating Index [mimos], shards [5]/[1]
2015-05-12-14:31:03:750 - TRACE - Log4jESLogger - [Presence] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [LpesBuwwTzepsC-0xYyQXg], scheduling a retry.
2015-05-12-14:31:03:774 - DEBUG - Log4jESLogger - [Presence] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-12-14:31:03:775 - DEBUG - Log4jESLogger - [Presence] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-12-14:31:03:790 - DEBUG - Log4jESLogger - [Presence] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-12-14:31:03:862 - DEBUG - Log4jESLogger - [Presence] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"age":{"type":"string"},"author":{"type":"string"},"content":{"type":"string"},"id":{"type":"string"},"name":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-12-14:31:03:946 - DEBUG - Log4jESLogger - [Presence] Sending mapping created for index mimos, type Programmer
2015-05-12-14:31:03:956 - DEBUG - Log4jESLogger - [Presence] [mimos][0] creating shard
2015-05-12-14:31:03:957 - DEBUG - Log4jESLogger - [Presence] [mimos] creating shard_id [0]
2015-05-12-14:31:04:112 - DEBUG - Log4jESLogger - [Presence] [mimos][0] Using [keep_only_last] deletion policy
2015-05-12-14:31:04:115 - DEBUG - Log4jESLogger - [Presence] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:31:04:116 - DEBUG - Log4jESLogger - [Presence] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:31:04:122 - DEBUG - Log4jESLogger - [Presence] [mimos][0] state: [CREATED]
2015-05-12-14:31:04:123 - DEBUG - Log4jESLogger - [Presence] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:31:04:129 - DEBUG - Log4jESLogger - [Presence] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:31:04:131 - DEBUG - Log4jESLogger - [Presence] [mimos][2] creating shard
2015-05-12-14:31:04:131 - DEBUG - Log4jESLogger - [Presence] [mimos][0] starting recovery from local ...
2015-05-12-14:31:04:131 - DEBUG - Log4jESLogger - [Presence] [mimos] creating shard_id [2]
2015-05-12-14:31:04:175 - DEBUG - Log4jESLogger - [Presence] [mimos][2] Using [keep_only_last] deletion policy
2015-05-12-14:31:04:177 - DEBUG - Log4jESLogger - [Presence] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:31:04:179 - DEBUG - Log4jESLogger - [Presence] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:31:04:180 - DEBUG - Log4jESLogger - [Presence] [mimos][2] state: [CREATED]
2015-05-12-14:31:04:181 - DEBUG - Log4jESLogger - [Presence] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:31:04:182 - DEBUG - Log4jESLogger - [Presence] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:31:04:183 - DEBUG - Log4jESLogger - [Presence] [mimos][3] creating shard
2015-05-12-14:31:04:183 - DEBUG - Log4jESLogger - [Presence] [mimos][2] starting recovery from local ...
2015-05-12-14:31:04:185 - DEBUG - Log4jESLogger - [Presence] [mimos] creating shard_id [3]
2015-05-12-14:31:04:196 - TRACE - Log4jESLogger - [Presence] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-12-14:31:04:204 - DEBUG - Log4jESLogger - [Presence] [mimos][0] starting engine
2015-05-12-14:31:04:205 - DEBUG - Log4jESLogger - [Presence] [mimos][3] Using [keep_only_last] deletion policy
2015-05-12-14:31:04:208 - DEBUG - Log4jESLogger - [Presence] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:31:04:210 - DEBUG - Log4jESLogger - [Presence] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:31:04:211 - TRACE - Log4jESLogger - [Presence] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-12-14:31:04:214 - DEBUG - Log4jESLogger - [Presence] [mimos][2] starting engine
2015-05-12-14:31:04:221 - DEBUG - Log4jESLogger - [Presence] [mimos][3] state: [CREATED]
2015-05-12-14:31:04:221 - DEBUG - Log4jESLogger - [Presence] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:31:04:223 - DEBUG - Log4jESLogger - [Presence] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:31:04:233 - DEBUG - Log4jESLogger - [Presence] [mimos][4] creating shard
2015-05-12-14:31:04:234 - DEBUG - Log4jESLogger - [Presence] [mimos] creating shard_id [4]
2015-05-12-14:31:04:250 - DEBUG - Log4jESLogger - [Presence] [mimos][3] starting recovery from local ...
2015-05-12-14:31:04:251 - TRACE - Log4jESLogger - [Presence] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-12-14:31:04:251 - DEBUG - Log4jESLogger - [Presence] [mimos][3] starting engine
2015-05-12-14:31:04:260 - DEBUG - Log4jESLogger - [Presence] [mimos][4] Using [keep_only_last] deletion policy
2015-05-12-14:31:04:261 - DEBUG - Log4jESLogger - [Presence] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:31:04:262 - DEBUG - Log4jESLogger - [Presence] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:31:04:262 - DEBUG - Log4jESLogger - [Presence] [mimos][4] state: [CREATED]
2015-05-12-14:31:04:263 - DEBUG - Log4jESLogger - [Presence] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:31:04:264 - DEBUG - Log4jESLogger - [Presence] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:31:04:268 - DEBUG - Log4jESLogger - [Presence] [mimos][4] starting recovery from local ...
2015-05-12-14:31:04:269 - TRACE - Log4jESLogger - [Presence] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-12-14:31:04:270 - DEBUG - Log4jESLogger - [Presence] [mimos][4] starting engine
2015-05-12-14:31:04:274 - TRACE - Log4jESLogger - [Presence] [_global] writing state, reason [changed]
2015-05-12-14:31:04:342 - INFO  - Log4jESLogger - [Presence] recovered [1] indices into cluster_state
2015-05-12-14:31:04:343 - DEBUG - Log4jESLogger - [Presence] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-12-14:31:04:344 - TRACE - Log4jESLogger - [Presence] listener to cluster state added, trying to index again
2015-05-12-14:31:04:344 - TRACE - Log4jESLogger - [Presence] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [LpesBuwwTzepsC-0xYyQXg], scheduling a retry.
2015-05-12-14:31:04:344 - TRACE - Log4jESLogger - [Presence] retry scheduling ignored as it as we already have a listener in place
2015-05-12-14:31:04:356 - TRACE - Log4jESLogger - [Presence] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:31:04:357 - TRACE - Log4jESLogger - [Presence] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:31:04:356 - TRACE - Log4jESLogger - [Presence] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:31:04:356 - TRACE - Log4jESLogger - [Presence] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:31:04:367 - TRACE - Log4jESLogger - [Presence] [mimos][4] warming took [8ms]
2015-05-12-14:31:04:370 - DEBUG - Log4jESLogger - [Presence] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:31:04:378 - TRACE - Log4jESLogger - [Presence] [mimos][0] warming took [19.9ms]
2015-05-12-14:31:04:379 - DEBUG - Log4jESLogger - [Presence] [mimos][4] scheduling refresher every 1s
2015-05-12-14:31:04:379 - DEBUG - Log4jESLogger - [Presence] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:31:04:379 - DEBUG - Log4jESLogger - [Presence] [mimos][0] scheduling refresher every 1s
2015-05-12-14:31:04:376 - TRACE - Log4jESLogger - [Presence] [mimos][2] warming took [18.9ms]
2015-05-12-14:31:04:381 - TRACE - Log4jESLogger - [Presence] [mimos][3] warming took [19.9ms]
2015-05-12-14:31:04:380 - DEBUG - Log4jESLogger - [Presence] [mimos][0] scheduling optimizer / merger every 1s
2015-05-12-14:31:04:383 - DEBUG - Log4jESLogger - [Presence] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:31:04:380 - DEBUG - Log4jESLogger - [Presence] [mimos][4] scheduling optimizer / merger every 1s
2015-05-12-14:31:04:387 - TRACE - Log4jESLogger - [Presence] [mimos][4] refresh with force[true]
2015-05-12-14:31:04:387 - DEBUG - Log4jESLogger - [Presence] [mimos][4] recovery completed from [local], took [119ms]
2015-05-12-14:31:04:387 - DEBUG - Log4jESLogger - [Presence] sending shard started for [mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:388 - DEBUG - Log4jESLogger - [Presence] received shard started for [mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:384 - DEBUG - Log4jESLogger - [Presence] [mimos][3] scheduling refresher every 1s
2015-05-12-14:31:04:384 - TRACE - Log4jESLogger - [Presence] [mimos][0] refresh with force[true]
2015-05-12-14:31:04:389 - DEBUG - Log4jESLogger - [Presence] [mimos][0] recovery completed from [local], took [258ms]
2015-05-12-14:31:04:389 - DEBUG - Log4jESLogger - [Presence] sending shard started for [mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:389 - DEBUG - Log4jESLogger - [Presence] received shard started for [mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:381 - DEBUG - Log4jESLogger - [Presence] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:31:04:388 - DEBUG - Log4jESLogger - [Presence] [mimos][3] scheduling optimizer / merger every 1s
2015-05-12-14:31:04:390 - DEBUG - Log4jESLogger - [Presence] [mimos][2] scheduling refresher every 1s
2015-05-12-14:31:04:390 - DEBUG - Log4jESLogger - [Presence] [mimos][2] scheduling optimizer / merger every 1s
2015-05-12-14:31:04:390 - TRACE - Log4jESLogger - [Presence] [mimos][3] refresh with force[true]
2015-05-12-14:31:04:391 - TRACE - Log4jESLogger - [Presence] [mimos][2] refresh with force[true]
2015-05-12-14:31:04:391 - DEBUG - Log4jESLogger - [Presence] [mimos][3] recovery completed from [local], took [141ms]
2015-05-12-14:31:04:391 - DEBUG - Log4jESLogger - [Presence] [mimos][2] recovery completed from [local], took [208ms]
2015-05-12-14:31:04:391 - DEBUG - Log4jESLogger - [Presence] sending shard started for [mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:392 - DEBUG - Log4jESLogger - [Presence] received shard started for [mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:392 - DEBUG - Log4jESLogger - [Presence] sending shard started for [mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:392 - DEBUG - Log4jESLogger - [Presence] received shard started for [mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:393 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:31:04:394 - DEBUG - Log4jESLogger - [Presence] applying started shards [[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], [mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], [mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], [mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-14:31:04:394 - DEBUG - Log4jESLogger - [Presence] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-12-14:31:04:395 - TRACE - Log4jESLogger - [Presence] Start balancing cluster
2015-05-12-14:31:04:395 - TRACE - Log4jESLogger - [Presence] Start distributing Shards
2015-05-12-14:31:04:395 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:396 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:396 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:396 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:396 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:396 - TRACE - Log4jESLogger - [Presence] Start allocating unassigned shards
2015-05-12-14:31:04:397 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:397 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:397 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:398 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:398 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:399 - TRACE - Log4jESLogger - [Presence] Start balancing cluster
2015-05-12-14:31:04:399 - TRACE - Log4jESLogger - [Presence] Start distributing Shards
2015-05-12-14:31:04:400 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:400 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:400 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:400 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:400 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:401 - TRACE - Log4jESLogger - [Presence] Start allocating unassigned shards
2015-05-12-14:31:04:402 - TRACE - Log4jESLogger - [Presence] cluster state updated:
version [3], source [shard-started ([mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[LpesBuwwTzepsC-0xYyQXg][V]
--------[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]
--------[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:31:04:402 - DEBUG - Log4jESLogger - [Presence] Publishing cluster state version 3
2015-05-12-14:31:04:402 - DEBUG - Log4jESLogger - [Presence] Set cluster state to version 3. Broadcasting to listeners.
2015-05-12-14:31:04:405 - DEBUG - Log4jESLogger - [Presence] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:31:04:407 - DEBUG - Log4jESLogger - [Presence] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:31:04:414 - DEBUG - Log4jESLogger - [Presence] [mimos][1] creating shard
2015-05-12-14:31:04:414 - DEBUG - Log4jESLogger - [Presence] [mimos] creating shard_id [1]
2015-05-12-14:31:04:432 - DEBUG - Log4jESLogger - [Presence] [mimos][1] Using [keep_only_last] deletion policy
2015-05-12-14:31:04:438 - DEBUG - Log4jESLogger - [Presence] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-12-14:31:04:439 - DEBUG - Log4jESLogger - [Presence] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-12-14:31:04:440 - DEBUG - Log4jESLogger - [Presence] [mimos][1] state: [CREATED]
2015-05-12-14:31:04:441 - DEBUG - Log4jESLogger - [Presence] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-12-14:31:04:442 - DEBUG - Log4jESLogger - [Presence] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-12-14:31:04:443 - DEBUG - Log4jESLogger - [Presence] [mimos][1] starting recovery from local ...
2015-05-12-14:31:04:444 - TRACE - Log4jESLogger - [Presence] cluster changed (version 3), trying to index again
2015-05-12-14:31:04:444 - TRACE - Log4jESLogger - [Presence] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-12-14:31:04:445 - DEBUG - Log4jESLogger - [Presence] [mimos][1] starting engine
2015-05-12-14:31:04:446 - TRACE - Log4jESLogger - [Presence] [mimos][0] writing shard state, reason [version changed from [54] to [56]]
2015-05-12-14:31:04:447 - TRACE - Log4jESLogger - [Presence] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-12-14:31:04:449 - TRACE - Log4jESLogger - [Presence] [mimos][1] warming took [195.8micros]
2015-05-12-14:31:04:451 - DEBUG - Log4jESLogger - [Presence] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-12-14:31:04:451 - DEBUG - Log4jESLogger - [Presence] [mimos][1] scheduling refresher every 1s
2015-05-12-14:31:04:452 - DEBUG - Log4jESLogger - [Presence] [mimos][1] scheduling optimizer / merger every 1s
2015-05-12-14:31:04:452 - TRACE - Log4jESLogger - [Presence] [mimos][1] refresh with force[true]
2015-05-12-14:31:04:455 - DEBUG - Log4jESLogger - [Presence] [mimos][1] recovery completed from [local], took [12ms]
2015-05-12-14:31:04:455 - DEBUG - Log4jESLogger - [Presence] sending shard started for [mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:456 - DEBUG - Log4jESLogger - [Presence] received shard started for [mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-12-14:31:04:484 - TRACE - Log4jESLogger - [Presence] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-12-14:31:04:510 - DEBUG - Log4jESLogger - [Presence] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-12-14:31:04:511 - TRACE - Log4jESLogger - [Presence] [mimos][4] writing shard state, reason [version changed from [56] to [58]]
2015-05-12-14:31:04:551 - INFO  - Log4jESLogger - [Saint Anna] version[0.90.5], pid[19489], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-14:31:04:552 - INFO  - Log4jESLogger - [Saint Anna] initializing ...
2015-05-12-14:31:04:552 - DEBUG - Log4jESLogger - [Saint Anna] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-14:31:04:552 - INFO  - Log4jESLogger - [Saint Anna] loaded [], sites []
2015-05-12-14:31:04:553 - TRACE - Log4jESLogger - [Saint Anna] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0 ...
2015-05-12-14:31:04:553 - DEBUG - Log4jESLogger - [Saint Anna] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0]], local_node_id [0]
2015-05-12-14:31:04:553 - TRACE - Log4jESLogger - [Saint Anna] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/kodcu/nodes/0, free_space [18.7gb], usable_space [13.4gb]

2015-05-12-14:31:04:554 - TRACE - Log4jESLogger - [Presence] [mimos][3] writing shard state, reason [version changed from [54] to [56]]
2015-05-12-14:31:04:588 - TRACE - Log4jESLogger - [Presence] [mimos][2] writing shard state, reason [version changed from [44] to [46]]
2015-05-12-14:31:04:603 - TRACE - Log4jESLogger - [Saint Anna] sigar loaded successfully
2015-05-12-14:31:04:622 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-12-14:31:04:622 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:31:04:622 - DEBUG - Log4jESLogger - [Presence] applying started shards [[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-12-14:31:04:623 - TRACE - Log4jESLogger - [Presence] Start balancing cluster
2015-05-12-14:31:04:623 - TRACE - Log4jESLogger - [Presence] Start distributing Shards
2015-05-12-14:31:04:623 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:624 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:624 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:624 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:630 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:630 - TRACE - Log4jESLogger - [Presence] Start allocating unassigned shards
2015-05-12-14:31:04:631 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:631 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:631 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:631 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:632 - TRACE - Log4jESLogger - [Presence] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:04:632 - TRACE - Log4jESLogger - [Presence] Start balancing cluster
2015-05-12-14:31:04:632 - TRACE - Log4jESLogger - [Presence] Start distributing Shards
2015-05-12-14:31:04:632 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:633 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:633 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:633 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:633 - TRACE - Log4jESLogger - [Presence] Assigned shard [[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]] to node [LpesBuwwTzepsC-0xYyQXg]
2015-05-12-14:31:04:633 - TRACE - Log4jESLogger - [Presence] Start allocating unassigned shards
2015-05-12-14:31:04:634 - TRACE - Log4jESLogger - [Presence] cluster state updated:
version [4], source [shard-started ([mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Presence][LpesBuwwTzepsC-0xYyQXg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[LpesBuwwTzepsC-0xYyQXg][V]
--------[mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
--------[mimos][4], node[LpesBuwwTzepsC-0xYyQXg], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:31:04:635 - DEBUG - Log4jESLogger - [Presence] Publishing cluster state version 4
2015-05-12-14:31:04:635 - DEBUG - Log4jESLogger - [Presence] Set cluster state to version 4. Broadcasting to listeners.
2015-05-12-14:31:04:635 - DEBUG - Log4jESLogger - [Presence] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:31:04:636 - DEBUG - Log4jESLogger - [Presence] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:31:04:639 - TRACE - Log4jESLogger - [Presence] [mimos][1] writing shard state, reason [version changed from [40] to [42]]
2015-05-12-14:31:04:669 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-12-14:31:04:670 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-12-14:31:04:670 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-12-14:31:04:671 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-12-14:31:04:671 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-12-14:31:04:671 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-12-14:31:04:671 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-12-14:31:04:672 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-12-14:31:04:672 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:31:04:672 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][2], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-12-14:31:04:673 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:31:04:673 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][3], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-14:31:04:673 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:31:04:673 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][0], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-14:31:04:673 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-12-14:31:04:673 - DEBUG - Log4jESLogger - [Presence] processing [shard-started ([mimos][1], node[LpesBuwwTzepsC-0xYyQXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-12-14:31:04:674 - DEBUG - Log4jESLogger - [Presence] processing [update-mapping [mimos][Programmer]]: execute
2015-05-12-14:31:04:676 - DEBUG - Log4jESLogger - [Presence] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-12-14:31:04:672 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:31:04:680 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:31:04:681 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:31:04:681 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-12-14:31:04:681 - DEBUG - Log4jESLogger - [Saint Anna] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-12-14:31:04:682 - DEBUG - Log4jESLogger - [Saint Anna] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-12-14:31:04:682 - DEBUG - Log4jESLogger - [Saint Anna] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-12-14:31:04:683 - DEBUG - Log4jESLogger - [Saint Anna] using initial hosts [], with concurrent_connects [10]
2015-05-12-14:31:04:683 - DEBUG - Log4jESLogger - [Saint Anna] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-12-14:31:04:684 - DEBUG - Log4jESLogger - [Saint Anna] using minimum_master_nodes [-1]
2015-05-12-14:31:04:684 - DEBUG - Log4jESLogger - [Saint Anna] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-14:31:04:684 - DEBUG - Log4jESLogger - [Saint Anna] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-12-14:31:04:690 - DEBUG - Log4jESLogger - [Saint Anna] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-12-14:31:05:192 - DEBUG - Log4jESLogger - [Saint Anna] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@5ba26eb0] with refresh_interval [1s]
2015-05-12-14:31:05:193 - DEBUG - Log4jESLogger - [Saint Anna] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@66f0548d] with refresh_interval [1s]
2015-05-12-14:31:05:195 - DEBUG - Log4jESLogger - [Saint Anna] Using refresh_interval [1s]
2015-05-12-14:31:05:195 - DEBUG - Log4jESLogger - [Saint Anna] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@6daf7d37] with refresh_interval [5s]
2015-05-12-14:31:05:197 - DEBUG - Log4jESLogger - [Saint Anna] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:70:21c5:4d8b:a993%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-12-14:31:05:197 - TRACE - Log4jESLogger - [Saint Anna] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:185736 errors:0 dropped:0 overruns:0 frame:0
	TX packets:185736 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:22872230 ( 22M)  TX bytes:22872230 ( 22M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:960451 errors:0 dropped:0 overruns:0 frame:0
	TX packets:464310 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:1102846154 (1.0G)  TX bytes:48246867 ( 46M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:820 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:819 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-12-14:31:05:198 - DEBUG - Log4jESLogger - [Saint Anna] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@9fc9f91] with refresh_interval [1s]
2015-05-12-14:31:05:200 - DEBUG - Log4jESLogger - [Saint Anna] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-12-14:31:05:201 - DEBUG - Log4jESLogger - [Saint Anna] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-12-14:31:05:202 - DEBUG - Log4jESLogger - [Saint Anna] using script cache with max_size [500], expire [null]
2015-05-12-14:31:05:203 - DEBUG - Log4jESLogger - [Saint Anna] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:31:05:203 - DEBUG - Log4jESLogger - [Saint Anna] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:31:05:203 - DEBUG - Log4jESLogger - [Saint Anna] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:31:05:204 - DEBUG - Log4jESLogger - [Saint Anna] using initial_shards [quorum], list_timeout [30s]
2015-05-12-14:31:05:209 - DEBUG - Log4jESLogger - [Saint Anna] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-12-14:31:05:216 - DEBUG - Log4jESLogger - [Saint Anna] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-12-14:31:05:217 - DEBUG - Log4jESLogger - [Saint Anna] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-12-14:31:05:218 - DEBUG - Log4jESLogger - [Saint Anna] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-12-14:31:05:218 - DEBUG - Log4jESLogger - [Saint Anna] using size [-1] [-1b], expire [null]
2015-05-12-14:31:05:220 - DEBUG - Log4jESLogger - [Saint Anna] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-12-14:31:05:221 - TRACE - Log4jESLogger - [Saint Anna] [upgrade]: processing [global-14]
2015-05-12-14:31:05:235 - DEBUG - Log4jESLogger - [Saint Anna] took 14ms to load state
2015-05-12-14:31:05:236 - TRACE - Log4jESLogger - [Saint Anna] [find_latest_state]: processing [global-14]
2015-05-12-14:31:05:238 - DEBUG - Log4jESLogger - [Saint Anna] took 2ms to load started shards state
2015-05-12-14:31:05:239 - DEBUG - Log4jESLogger - [Saint Anna] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-12-14:31:05:241 - DEBUG - Log4jESLogger - [Saint Anna] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:31:05:241 - DEBUG - Log4jESLogger - [Saint Anna] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:31:05:241 - DEBUG - Log4jESLogger - [Saint Anna] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:31:05:242 - DEBUG - Log4jESLogger - [Saint Anna] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-12-14:31:05:244 - DEBUG - Log4jESLogger - [Saint Anna] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-12-14:31:05:244 - DEBUG - Log4jESLogger - [Saint Anna] using [cluster_concurrent_rebalance] with [2]
2015-05-12-14:31:05:247 - INFO  - Log4jESLogger - [Saint Anna] initialized
2015-05-12-14:31:05:248 - INFO  - Log4jESLogger - [Saint Anna] starting ...
2015-05-12-14:31:05:408 - TRACE - Log4jESLogger - [Presence] [mimos][2] refresh with force[false]
2015-05-12-14:31:05:425 - DEBUG - Log4jESLogger - [Saint Anna] Bound to address [/0:0:0:0:0:0:0:0:9301]
2015-05-12-14:31:05:426 - INFO  - Log4jESLogger - [Saint Anna] bound_address {inet[/0:0:0:0:0:0:0:0:9301]}, publish_address {inet[/10.11.66.27:9301]}
2015-05-12-14:31:05:428 - TRACE - Log4jESLogger - [Saint Anna] waiting for 30s for the initial state to be set by the discovery
2015-05-12-14:31:05:433 - TRACE - Log4jESLogger - [Presence] [1] received ping_request from [[Saint Anna][F6SW51zlRdm-T2BVcnX1mw][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-14:31:05:434 - TRACE - Log4jESLogger - [Saint Anna] [1] sending ping request
2015-05-12-14:31:05:497 - TRACE - Log4jESLogger - [Presence] [mimos][2] warming [StandardDirectoryReader(segments_1:3:nrt _0(4.4):c1)], new [MultiReader(_0(4.4):c1)]
2015-05-12-14:31:05:497 - TRACE - Log4jESLogger - [Presence] [mimos][2] warming took [110.1micros]
2015-05-12-14:31:06:935 - TRACE - Log4jESLogger - [Presence] [1] received ping_request from [[Saint Anna][F6SW51zlRdm-T2BVcnX1mw][inet[/10.11.66.27:9301]]], but wrong cluster_name [Cluster [kodcu]], expected [Cluster [peansData]], ignoring
2015-05-12-14:31:06:935 - TRACE - Log4jESLogger - [Saint Anna] [1] sending ping request
2015-05-12-14:31:08:435 - TRACE - Log4jESLogger - [Saint Anna] full ping responses: {none}
2015-05-12-14:31:08:435 - DEBUG - Log4jESLogger - [Saint Anna] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-12-14:31:08:435 - DEBUG - Log4jESLogger - [Saint Anna] processing [zen-disco-join (elected_as_master)]: execute
2015-05-12-14:31:08:436 - TRACE - Log4jESLogger - [Saint Anna] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Saint Anna][F6SW51zlRdm-T2BVcnX1mw][inet[/10.11.66.27:9301]], local, master
routing_table:
routing_nodes:
-----node_id[F6SW51zlRdm-T2BVcnX1mw][V]
---- unassigned

2015-05-12-14:31:08:436 - INFO  - Log4jESLogger - [Saint Anna] new_master [Saint Anna][F6SW51zlRdm-T2BVcnX1mw][inet[/10.11.66.27:9301]], reason: zen-disco-join (elected_as_master)
2015-05-12-14:31:08:438 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0xfb5b4f5e, /10.11.66.27:56137 => /10.11.66.27:9301]
2015-05-12-14:31:08:439 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0x36ca1588, /10.11.66.27:56138 => /10.11.66.27:9301]
2015-05-12-14:31:08:439 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0xbd8635c9, /10.11.66.27:56139 => /10.11.66.27:9301]
2015-05-12-14:31:08:440 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0xc8a9cee5, /10.11.66.27:56140 => /10.11.66.27:9301]
2015-05-12-14:31:08:440 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0xf02b48e4, /10.11.66.27:56141 => /10.11.66.27:9301]
2015-05-12-14:31:08:440 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0x451f7900, /10.11.66.27:56142 => /10.11.66.27:9301]
2015-05-12-14:31:08:441 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0x39036cc1, /10.11.66.27:56143 => /10.11.66.27:9301]
2015-05-12-14:31:08:441 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0x4e168471, /10.11.66.27:56144 => /10.11.66.27:9301]
2015-05-12-14:31:08:443 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0xb6a20323, /10.11.66.27:56145 => /10.11.66.27:9301]
2015-05-12-14:31:08:443 - DEBUG - Log4jESLogger - [Saint Anna] connected to node [[Saint Anna][F6SW51zlRdm-T2BVcnX1mw][inet[/10.11.66.27:9301]]]
2015-05-12-14:31:08:443 - DEBUG - Log4jESLogger - [Saint Anna] Publishing cluster state version 1
2015-05-12-14:31:08:443 - DEBUG - Log4jESLogger - [Saint Anna] Set cluster state to version 1. Broadcasting to listeners.
2015-05-12-14:31:08:444 - DEBUG - Log4jESLogger - [Saint Anna] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:31:08:444 - DEBUG - Log4jESLogger - [Saint Anna] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:31:08:444 - TRACE - Log4jESLogger - [Saint Anna] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-12-14:31:08:444 - DEBUG - Log4jESLogger - [Saint Anna] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-12-14:31:08:444 - TRACE - Log4jESLogger - [Saint Anna] channel opened: [id: 0x2c47fc15, /10.11.66.27:56146 => /10.11.66.27:9301]
2015-05-12-14:31:08:448 - TRACE - Log4jESLogger - [Saint Anna] initial state set from discovery
2015-05-12-14:31:08:448 - INFO  - Log4jESLogger - [Saint Anna] kodcu/F6SW51zlRdm-T2BVcnX1mw
2015-05-12-14:31:08:448 - TRACE - Log4jESLogger - [Saint Anna] performing state recovery...
2015-05-12-14:31:08:448 - TRACE - Log4jESLogger - [Saint Anna] performing state recovery from [F6SW51zlRdm-T2BVcnX1mw]
2015-05-12-14:31:08:450 - TRACE - Log4jESLogger - [Saint Anna] successful state recovery, importing cluster state...
2015-05-12-14:31:08:451 - DEBUG - Log4jESLogger - [Saint Anna] processing [local-gateway-elected-state]: execute
2015-05-12-14:31:08:453 - DEBUG - Log4jESLogger - [Saint Anna] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Saint Anna][F6SW51zlRdm-T2BVcnX1mw][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-14:31:08:454 - DEBUG - Log4jESLogger - [Saint Anna] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Saint Anna][F6SW51zlRdm-T2BVcnX1mw][inet[/10.11.66.27:9301]]] on primary allocation
2015-05-12-14:31:08:457 - DEBUG - Log4jESLogger - [Saint Anna] [mimos][1]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-14:31:08:457 - DEBUG - Log4jESLogger - [Saint Anna] [mimos][3]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-14:31:08:458 - DEBUG - Log4jESLogger - [Saint Anna] [mimos][4]: not allocating, number_of_allocated_shards_found [0], required_number [1]
2015-05-12-14:31:08:458 - TRACE - Log4jESLogger - [Saint Anna] Start balancing cluster
2015-05-12-14:31:08:458 - TRACE - Log4jESLogger - [Saint Anna] Start distributing Shards
2015-05-12-14:31:08:458 - TRACE - Log4jESLogger - [Saint Anna] Assigned shard [[mimos][0], node[F6SW51zlRdm-T2BVcnX1mw], [P], s[INITIALIZING]] to node [F6SW51zlRdm-T2BVcnX1mw]
2015-05-12-14:31:08:459 - TRACE - Log4jESLogger - [Saint Anna] Assigned shard [[mimos][2], node[F6SW51zlRdm-T2BVcnX1mw], [P], s[INITIALIZING]] to node [F6SW51zlRdm-T2BVcnX1mw]
2015-05-12-14:31:08:459 - TRACE - Log4jESLogger - [Saint Anna] Start allocating unassigned shards
2015-05-12-14:31:08:459 - TRACE - Log4jESLogger - [Saint Anna] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:08:459 - TRACE - Log4jESLogger - [Saint Anna] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:08:459 - TRACE - Log4jESLogger - [Saint Anna] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:08:459 - TRACE - Log4jESLogger - [Saint Anna] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:08:460 - TRACE - Log4jESLogger - [Saint Anna] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-12-14:31:08:461 - TRACE - Log4jESLogger - [Saint Anna] Start balancing cluster
2015-05-12-14:31:08:461 - TRACE - Log4jESLogger - [Saint Anna] Start distributing Shards
2015-05-12-14:31:08:461 - TRACE - Log4jESLogger - [Saint Anna] Assigned shard [[mimos][0], node[F6SW51zlRdm-T2BVcnX1mw], [P], s[INITIALIZING]] to node [F6SW51zlRdm-T2BVcnX1mw]
2015-05-12-14:31:08:461 - TRACE - Log4jESLogger - [Saint Anna] Assigned shard [[mimos][2], node[F6SW51zlRdm-T2BVcnX1mw], [P], s[INITIALIZING]] to node [F6SW51zlRdm-T2BVcnX1mw]
2015-05-12-14:31:08:461 - TRACE - Log4jESLogger - [Saint Anna] Start allocating unassigned shards
2015-05-12-14:31:08:462 - TRACE - Log4jESLogger - [Saint Anna] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Saint Anna][F6SW51zlRdm-T2BVcnX1mw][inet[/10.11.66.27:9301]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[F6SW51zlRdm-T2BVcnX1mw], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[F6SW51zlRdm-T2BVcnX1mw], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[F6SW51zlRdm-T2BVcnX1mw][V]
--------[mimos][0], node[F6SW51zlRdm-T2BVcnX1mw], [P], s[INITIALIZING]
--------[mimos][2], node[F6SW51zlRdm-T2BVcnX1mw], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [P], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-12-14:31:08:462 - DEBUG - Log4jESLogger - [Saint Anna] Publishing cluster state version 2
2015-05-12-14:31:08:462 - DEBUG - Log4jESLogger - [Saint Anna] Set cluster state to version 2. Broadcasting to listeners.
2015-05-12-14:31:08:468 - DEBUG - Log4jESLogger - [Saint Anna] processing [reroute_rivers_node_changed]: execute
2015-05-12-14:31:08:468 - DEBUG - Log4jESLogger - [Saint Anna] [mimos] creating index
2015-05-12-14:31:08:469 - DEBUG - Log4jESLogger - [Saint Anna] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-12-14:31:08:471 - DEBUG - Log4jESLogger - [Saint Anna] creating Index [mimos], shards [5]/[1]
2015-05-12-14:31:08:473 - INFO  - Log4jESLogger - [Saint Anna] bound_address {inet[/0:0:0:0:0:0:0:0:9201]}, publish_address {inet[/10.11.66.27:9201]}
2015-05-12-14:31:08:473 - INFO  - Log4jESLogger - [Saint Anna] started
2015-05-12-14:33:51:485 - INFO  - Log4jESLogger - [Proctor] version[0.90.5], pid[19713], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-12-14:33:51:489 - INFO  - Log4jESLogger - [Proctor] initializing ...
2015-05-12-14:33:51:489 - DEBUG - Log4jESLogger - [Proctor] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-12-14:33:51:502 - INFO  - Log4jESLogger - [Proctor] loaded [], sites []
2015-05-12-14:33:51:528 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-12-14:33:51:532 - TRACE - Log4jESLogger - [Proctor] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-12-14:33:51:539 - DEBUG - Log4jESLogger - [Proctor] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-12-14:33:51:544 - TRACE - Log4jESLogger - [Proctor] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [18.7gb], usable_space [13.4gb]

2015-05-12-14:33:52:134 - TRACE - Log4jESLogger - [Proctor] sigar loaded successfully
