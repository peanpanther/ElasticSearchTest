2015-05-05-10:33:30:538 - INFO  - Log4jESLogger - [Lunatik] version[0.90.5], pid[7204], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-05-10:33:30:562 - INFO  - Log4jESLogger - [Lunatik] initializing ...
2015-05-05-10:33:30:563 - DEBUG - Log4jESLogger - [Lunatik] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-05-10:33:30:572 - INFO  - Log4jESLogger - [Lunatik] loaded [], sites []
2015-05-05-10:33:30:601 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-05-10:33:30:626 - TRACE - Log4jESLogger - [Lunatik] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-05-10:33:30:634 - DEBUG - Log4jESLogger - [Lunatik] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-05-10:33:30:640 - TRACE - Log4jESLogger - [Lunatik] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [34.9gb], usable_space [29.7gb]

2015-05-05-10:33:31:218 - TRACE - Log4jESLogger - [Lunatik] sigar loaded successfully
2015-05-05-10:33:31:888 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-05-10:33:31:894 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-05-10:33:31:899 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-05-10:33:31:900 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-05-10:33:31:902 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-05-10:33:31:903 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-05-10:33:31:904 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-05-10:33:31:914 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-05-10:33:31:916 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:33:31:917 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:33:31:917 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:33:31:918 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:33:31:918 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:33:31:919 - DEBUG - Log4jESLogger - [Lunatik] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-05-10:33:31:937 - DEBUG - Log4jESLogger - [Lunatik] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-05-10:33:31:948 - DEBUG - Log4jESLogger - [Lunatik] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-05-10:33:31:954 - DEBUG - Log4jESLogger - [Lunatik] using initial hosts [], with concurrent_connects [10]
2015-05-05-10:33:31:955 - DEBUG - Log4jESLogger - [Lunatik] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-05-10:33:31:957 - DEBUG - Log4jESLogger - [Lunatik] using minimum_master_nodes [-1]
2015-05-05-10:33:31:959 - DEBUG - Log4jESLogger - [Lunatik] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-10:33:31:966 - DEBUG - Log4jESLogger - [Lunatik] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-10:33:32:005 - DEBUG - Log4jESLogger - [Lunatik] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-05-10:33:32:514 - DEBUG - Log4jESLogger - [Lunatik] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@47747fb9] with refresh_interval [1s]
2015-05-05-10:33:32:518 - DEBUG - Log4jESLogger - [Lunatik] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@1edb61b1] with refresh_interval [1s]
2015-05-05-10:33:32:531 - DEBUG - Log4jESLogger - [Lunatik] Using refresh_interval [1s]
2015-05-05-10:33:32:532 - DEBUG - Log4jESLogger - [Lunatik] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@52c8295b] with refresh_interval [5s]
2015-05-05-10:33:32:537 - DEBUG - Log4jESLogger - [Lunatik] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:a:8707:d723:bfb2%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-05-10:33:32:540 - TRACE - Log4jESLogger - [Lunatik] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:10844 errors:0 dropped:0 overruns:0 frame:0
	TX packets:10844 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:2853710 (2.7M)  TX bytes:2853710 (2.7M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:481347 errors:0 dropped:0 overruns:0 frame:0
	TX packets:234507 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:574493086 (548M)  TX bytes:25272093 ( 24M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:359 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:359 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-05-10:33:32:546 - DEBUG - Log4jESLogger - [Lunatik] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@581d969c] with refresh_interval [1s]
2015-05-05-10:33:32:867 - DEBUG - Log4jESLogger - [Lunatik] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-05-10:33:32:877 - DEBUG - Log4jESLogger - [Lunatik] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-05-10:33:32:886 - DEBUG - Log4jESLogger - [Lunatik] using script cache with max_size [500], expire [null]
2015-05-05-10:33:32:891 - DEBUG - Log4jESLogger - [Lunatik] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:33:32:892 - DEBUG - Log4jESLogger - [Lunatik] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:33:32:893 - DEBUG - Log4jESLogger - [Lunatik] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:33:32:902 - DEBUG - Log4jESLogger - [Lunatik] using initial_shards [quorum], list_timeout [30s]
2015-05-05-10:33:32:995 - DEBUG - Log4jESLogger - [Lunatik] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-05-10:33:33:106 - DEBUG - Log4jESLogger - [Lunatik] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-05-10:33:33:115 - DEBUG - Log4jESLogger - [Lunatik] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-05-10:33:33:117 - DEBUG - Log4jESLogger - [Lunatik] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-05-10:33:33:119 - DEBUG - Log4jESLogger - [Lunatik] using size [-1] [-1b], expire [null]
2015-05-05-10:33:33:137 - DEBUG - Log4jESLogger - [Lunatik] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-05-10:33:33:138 - TRACE - Log4jESLogger - [Lunatik] [upgrade]: processing [global-6]
2015-05-05-10:33:33:347 - DEBUG - Log4jESLogger - [Lunatik] took 208ms to load state
2015-05-05-10:33:33:348 - TRACE - Log4jESLogger - [Lunatik] [find_latest_state]: processing [global-6]
2015-05-05-10:33:33:409 - DEBUG - Log4jESLogger - [Lunatik] took 60ms to load started shards state
2015-05-05-10:33:33:412 - DEBUG - Log4jESLogger - [Lunatik] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-05-10:33:33:418 - DEBUG - Log4jESLogger - [Lunatik] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:33:33:419 - DEBUG - Log4jESLogger - [Lunatik] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:33:33:419 - DEBUG - Log4jESLogger - [Lunatik] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:33:33:420 - DEBUG - Log4jESLogger - [Lunatik] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:33:33:421 - DEBUG - Log4jESLogger - [Lunatik] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:33:33:421 - DEBUG - Log4jESLogger - [Lunatik] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:33:33:431 - INFO  - Log4jESLogger - [Lunatik] initialized
2015-05-05-10:33:33:432 - INFO  - Log4jESLogger - [Lunatik] starting ...
2015-05-05-10:33:33:462 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-05-10:33:33:462 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-05-10:33:33:548 - DEBUG - Log4jESLogger - [Lunatik] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-05-10:33:33:552 - INFO  - Log4jESLogger - [Lunatik] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-05-10:33:33:576 - TRACE - Log4jESLogger - [Lunatik] waiting for 30s for the initial state to be set by the discovery
2015-05-05-10:33:33:586 - TRACE - Log4jESLogger - [Lunatik] [1] sending ping request
2015-05-05-10:33:35:088 - TRACE - Log4jESLogger - [Lunatik] [1] sending ping request
2015-05-05-10:33:36:599 - TRACE - Log4jESLogger - [Lunatik] full ping responses: {none}
2015-05-05-10:33:36:600 - DEBUG - Log4jESLogger - [Lunatik] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-05-10:33:36:604 - DEBUG - Log4jESLogger - [Lunatik] processing [zen-disco-join (elected_as_master)]: execute
2015-05-05-10:33:36:606 - TRACE - Log4jESLogger - [Lunatik] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[evLdXoJnSD-4ilX71tarsw][V]
---- unassigned

2015-05-05-10:33:36:608 - INFO  - Log4jESLogger - [Lunatik] new_master [Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-05-10:33:36:626 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0x566ad701, /10.11.66.27:54635 => /10.11.66.27:9300]
2015-05-05-10:33:36:631 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0x9e95044e, /10.11.66.27:54636 => /10.11.66.27:9300]
2015-05-05-10:33:36:632 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0xeba77bea, /10.11.66.27:54637 => /10.11.66.27:9300]
2015-05-05-10:33:36:634 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0x9048cce1, /10.11.66.27:54638 => /10.11.66.27:9300]
2015-05-05-10:33:36:635 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0x904d3bda, /10.11.66.27:54639 => /10.11.66.27:9300]
2015-05-05-10:33:36:658 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0x009c272f, /10.11.66.27:54640 => /10.11.66.27:9300]
2015-05-05-10:33:36:668 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0xde0b5f2a, /10.11.66.27:54641 => /10.11.66.27:9300]
2015-05-05-10:33:36:679 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0xeb36c40e, /10.11.66.27:54642 => /10.11.66.27:9300]
2015-05-05-10:33:36:680 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0xf1f6c165, /10.11.66.27:54643 => /10.11.66.27:9300]
2015-05-05-10:33:36:680 - TRACE - Log4jESLogger - [Lunatik] channel opened: [id: 0xa00daa4f, /10.11.66.27:54644 => /10.11.66.27:9300]
2015-05-05-10:33:36:685 - DEBUG - Log4jESLogger - [Lunatik] connected to node [[Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]]]
2015-05-05-10:33:36:689 - DEBUG - Log4jESLogger - [Lunatik] Publishing cluster state version 1
2015-05-05-10:33:36:690 - DEBUG - Log4jESLogger - [Lunatik] Set cluster state to version 1. Broadcasting to listeners.
2015-05-05-10:33:36:701 - DEBUG - Log4jESLogger - [Lunatik] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:33:36:702 - DEBUG - Log4jESLogger - [Lunatik] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:33:36:703 - DEBUG - Log4jESLogger - [Lunatik] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-05-10:33:36:703 - TRACE - Log4jESLogger - [Lunatik] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-05-10:33:36:703 - TRACE - Log4jESLogger - [Lunatik] initial state set from discovery
2015-05-05-10:33:36:705 - INFO  - Log4jESLogger - [Lunatik] peansData/evLdXoJnSD-4ilX71tarsw
2015-05-05-10:33:36:706 - TRACE - Log4jESLogger - [Lunatik] performing state recovery...
2015-05-05-10:33:36:720 - TRACE - Log4jESLogger - [Lunatik] performing state recovery from [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:732 - TRACE - Log4jESLogger - [Lunatik] successful state recovery, importing cluster state...
2015-05-05-10:33:36:735 - DEBUG - Log4jESLogger - [Lunatik] processing [local-gateway-elected-state]: execute
2015-05-05-10:33:36:756 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:33:36:778 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:33:36:780 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:33:36:781 - INFO  - Log4jESLogger - [Lunatik] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-05-10:33:36:782 - INFO  - Log4jESLogger - [Lunatik] started
2015-05-05-10:33:36:785 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:33:36:786 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1]: throttling allocation [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[[Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-05-10:33:36:792 - TRACE - Log4jESLogger - [Lunatik] Start balancing cluster
2015-05-05-10:33:36:800 - TRACE - Log4jESLogger - [Lunatik] Start distributing Shards
2015-05-05-10:33:36:801 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:802 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:802 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:802 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:802 - TRACE - Log4jESLogger - [Lunatik] Start allocating unassigned shards
2015-05-05-10:33:36:808 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:36:815 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:36:815 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:36:815 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:36:816 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:36:817 - TRACE - Log4jESLogger - [Lunatik] Start balancing cluster
2015-05-05-10:33:36:817 - TRACE - Log4jESLogger - [Lunatik] Start distributing Shards
2015-05-05-10:33:36:818 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:818 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:818 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:818 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:36:818 - TRACE - Log4jESLogger - [Lunatik] Start allocating unassigned shards
2015-05-05-10:33:36:822 - TRACE - Log4jESLogger - [Lunatik] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[evLdXoJnSD-4ilX71tarsw][V]
--------[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-10:33:36:823 - DEBUG - Log4jESLogger - [Lunatik] Publishing cluster state version 2
2015-05-05-10:33:36:823 - DEBUG - Log4jESLogger - [Lunatik] Set cluster state to version 2. Broadcasting to listeners.
2015-05-05-10:33:36:825 - DEBUG - Log4jESLogger - [Lunatik] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:33:36:826 - DEBUG - Log4jESLogger - [Lunatik] [mimos] creating index
2015-05-05-10:33:36:826 - DEBUG - Log4jESLogger - [Lunatik] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:33:36:826 - DEBUG - Log4jESLogger - [Lunatik] creating Index [mimos], shards [5]/[1]
2015-05-05-10:33:37:432 - DEBUG - Log4jESLogger - [Lunatik] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-05-10:33:37:438 - DEBUG - Log4jESLogger - [Lunatik] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-05-10:33:37:465 - DEBUG - Log4jESLogger - [Lunatik] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-05-10:33:37:607 - DEBUG - Log4jESLogger - [Lunatik] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"author":{"type":"string"},"content":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-05-10:33:37:719 - DEBUG - Log4jESLogger - [Lunatik] Sending mapping created for index mimos, type Programmer
2015-05-05-10:33:37:722 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] creating shard
2015-05-05-10:33:37:723 - DEBUG - Log4jESLogger - [Lunatik] [mimos] creating shard_id [0]
2015-05-05-10:33:37:920 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] Using [keep_only_last] deletion policy
2015-05-05-10:33:37:924 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:33:37:929 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:33:37:938 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] state: [CREATED]
2015-05-05-10:33:37:939 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:33:37:948 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:33:37:951 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] creating shard
2015-05-05-10:33:37:951 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] starting recovery from local ...
2015-05-05-10:33:37:951 - DEBUG - Log4jESLogger - [Lunatik] [mimos] creating shard_id [2]
2015-05-05-10:33:37:983 - TRACE - Log4jESLogger - [Lunatik] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-05-10:33:37:984 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] starting engine
2015-05-05-10:33:38:000 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] Using [keep_only_last] deletion policy
2015-05-05-10:33:38:001 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:33:38:002 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:33:38:002 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] state: [CREATED]
2015-05-05-10:33:38:003 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:33:38:008 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:33:38:008 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] starting recovery from local ...
2015-05-05-10:33:38:014 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] creating shard
2015-05-05-10:33:38:015 - DEBUG - Log4jESLogger - [Lunatik] [mimos] creating shard_id [3]
2015-05-05-10:33:38:040 - TRACE - Log4jESLogger - [Lunatik] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-05-10:33:38:045 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] Using [keep_only_last] deletion policy
2015-05-05-10:33:38:048 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:33:38:054 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] starting engine
2015-05-05-10:33:38:064 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:33:38:071 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] state: [CREATED]
2015-05-05-10:33:38:072 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:33:38:073 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:33:38:074 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] creating shard
2015-05-05-10:33:38:075 - DEBUG - Log4jESLogger - [Lunatik] [mimos] creating shard_id [4]
2015-05-05-10:33:38:085 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] starting recovery from local ...
2015-05-05-10:33:38:092 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] Using [keep_only_last] deletion policy
2015-05-05-10:33:38:094 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:33:38:095 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:33:38:095 - TRACE - Log4jESLogger - [Lunatik] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-05-10:33:38:100 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] state: [CREATED]
2015-05-05-10:33:38:101 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:33:38:102 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:33:38:102 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] starting engine
2015-05-05-10:33:38:119 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] starting recovery from local ...
2015-05-05-10:33:38:124 - TRACE - Log4jESLogger - [Lunatik] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-05-10:33:38:125 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] starting engine
2015-05-05-10:33:38:130 - TRACE - Log4jESLogger - [Lunatik] [_global] writing state, reason [changed]
2015-05-05-10:33:38:189 - TRACE - Log4jESLogger - [Lunatik] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:33:38:189 - TRACE - Log4jESLogger - [Lunatik] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:33:38:189 - INFO  - Log4jESLogger - [Lunatik] recovered [1] indices into cluster_state
2015-05-05-10:33:38:190 - DEBUG - Log4jESLogger - [Lunatik] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-05-10:33:38:194 - TRACE - Log4jESLogger - [Lunatik] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:33:38:195 - TRACE - Log4jESLogger - [Lunatik] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:33:38:198 - DEBUG - Log4jESLogger - [Lunatik] processing [create-index [mimos], cause [auto(index api)]]: execute
2015-05-05-10:33:38:200 - TRACE - Log4jESLogger - [Lunatik] failed to execute cluster state update, state:
version [2], source [create-index [mimos], cause [auto(index api)]]
nodes: 
   [Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[evLdXoJnSD-4ilX71tarsw][V]
--------[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [P], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

org.elasticsearch.indices.IndexAlreadyExistsException: [mimos] Already exists
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validate(MetaDataCreateIndexService.java:508)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.access$200(MetaDataCreateIndexService.java:86)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:171)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:298)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:135)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-05-05-10:33:38:212 - TRACE - Log4jESLogger - [Lunatik] [mimos][2] warming took [17.7ms]
2015-05-05-10:33:38:212 - TRACE - Log4jESLogger - [Lunatik] [mimos][3] warming took [16.6ms]
2015-05-05-10:33:38:204 - TRACE - Log4jESLogger - [Lunatik] [mimos][4] warming took [14ms]
2015-05-05-10:33:38:223 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:33:38:224 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:33:38:212 - TRACE - Log4jESLogger - [Lunatik] [mimos][0] warming took [22.3ms]
2015-05-05-10:33:38:225 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] scheduling refresher every 1s
2015-05-05-10:33:38:225 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:33:38:226 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] scheduling refresher every 1s
2015-05-05-10:33:38:226 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] scheduling optimizer / merger every 1s
2015-05-05-10:33:38:226 - TRACE - Log4jESLogger - [Lunatik] [mimos][4] refresh with force[true]
2015-05-05-10:33:38:227 - DEBUG - Log4jESLogger - [Lunatik] [mimos][4] recovery completed from [local], took [108ms]
2015-05-05-10:33:38:227 - DEBUG - Log4jESLogger - [Lunatik] sending shard started for [mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:227 - DEBUG - Log4jESLogger - [Lunatik] received shard started for [mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:224 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] scheduling refresher every 1s
2015-05-05-10:33:38:230 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] scheduling optimizer / merger every 1s
2015-05-05-10:33:38:222 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:33:38:231 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] scheduling refresher every 1s
2015-05-05-10:33:38:234 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] scheduling optimizer / merger every 1s
2015-05-05-10:33:38:234 - TRACE - Log4jESLogger - [Lunatik] [mimos][2] refresh with force[true]
2015-05-05-10:33:38:226 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] scheduling optimizer / merger every 1s
2015-05-05-10:33:38:233 - TRACE - Log4jESLogger - [Lunatik] [mimos] failed to create
org.elasticsearch.indices.IndexAlreadyExistsException: [mimos] Already exists
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validate(MetaDataCreateIndexService.java:508)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.access$200(MetaDataCreateIndexService.java:86)
	at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:171)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:298)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:135)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-05-05-10:33:38:230 - TRACE - Log4jESLogger - [Lunatik] [mimos][3] refresh with force[true]
2015-05-05-10:33:38:236 - DEBUG - Log4jESLogger - [Lunatik] [mimos][3] recovery completed from [local], took [152ms]
2015-05-05-10:33:38:236 - DEBUG - Log4jESLogger - [Lunatik] sending shard started for [mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:237 - DEBUG - Log4jESLogger - [Lunatik] received shard started for [mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:235 - DEBUG - Log4jESLogger - [Lunatik] [mimos][2] recovery completed from [local], took [227ms]
2015-05-05-10:33:38:235 - TRACE - Log4jESLogger - [Lunatik] [mimos][0] refresh with force[true]
2015-05-05-10:33:38:238 - DEBUG - Log4jESLogger - [Lunatik] [mimos][0] recovery completed from [local], took [286ms]
2015-05-05-10:33:38:238 - DEBUG - Log4jESLogger - [Lunatik] sending shard started for [mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:238 - DEBUG - Log4jESLogger - [Lunatik] received shard started for [mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:238 - DEBUG - Log4jESLogger - [Lunatik] sending shard started for [mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:239 - DEBUG - Log4jESLogger - [Lunatik] received shard started for [mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:236 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-10:33:38:240 - DEBUG - Log4jESLogger - [Lunatik] applying started shards [[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], [mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], [mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], [mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-05-10:33:38:241 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:33:38:241 - TRACE - Log4jESLogger - [Lunatik] Start balancing cluster
2015-05-05-10:33:38:242 - TRACE - Log4jESLogger - [Lunatik] Start distributing Shards
2015-05-05-10:33:38:242 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:242 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:242 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:242 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:243 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:243 - TRACE - Log4jESLogger - [Lunatik] Start allocating unassigned shards
2015-05-05-10:33:38:243 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:243 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:244 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:244 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:244 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:245 - TRACE - Log4jESLogger - [Lunatik] Start balancing cluster
2015-05-05-10:33:38:245 - TRACE - Log4jESLogger - [Lunatik] Start distributing Shards
2015-05-05-10:33:38:245 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:245 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:246 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:246 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:246 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:246 - TRACE - Log4jESLogger - [Lunatik] Start allocating unassigned shards
2015-05-05-10:33:38:247 - TRACE - Log4jESLogger - [Lunatik] cluster state updated:
version [3], source [shard-started ([mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[evLdXoJnSD-4ilX71tarsw][V]
--------[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]
--------[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-10:33:38:248 - DEBUG - Log4jESLogger - [Lunatik] Publishing cluster state version 3
2015-05-05-10:33:38:248 - TRACE - Log4jESLogger - [Lunatik] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [evLdXoJnSD-4ilX71tarsw], scheduling a retry.
2015-05-05-10:33:38:248 - DEBUG - Log4jESLogger - [Lunatik] Set cluster state to version 3. Broadcasting to listeners.
2015-05-05-10:33:38:257 - DEBUG - Log4jESLogger - [Lunatik] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:33:38:258 - DEBUG - Log4jESLogger - [Lunatik] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:33:38:260 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] creating shard
2015-05-05-10:33:38:267 - DEBUG - Log4jESLogger - [Lunatik] [mimos] creating shard_id [1]
2015-05-05-10:33:38:293 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] Using [keep_only_last] deletion policy
2015-05-05-10:33:38:295 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:33:38:295 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:33:38:297 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] state: [CREATED]
2015-05-05-10:33:38:300 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:33:38:301 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:33:38:302 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] starting recovery from local ...
2015-05-05-10:33:38:308 - TRACE - Log4jESLogger - [Lunatik] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-05-10:33:38:309 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] starting engine
2015-05-05-10:33:38:312 - TRACE - Log4jESLogger - [Lunatik] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:33:38:316 - TRACE - Log4jESLogger - [Lunatik] [mimos][1] warming took [3ms]
2015-05-05-10:33:38:317 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:33:38:318 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] scheduling refresher every 1s
2015-05-05-10:33:38:318 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] scheduling optimizer / merger every 1s
2015-05-05-10:33:38:318 - TRACE - Log4jESLogger - [Lunatik] [mimos][1] refresh with force[true]
2015-05-05-10:33:38:319 - DEBUG - Log4jESLogger - [Lunatik] [mimos][1] recovery completed from [local], took [16ms]
2015-05-05-10:33:38:319 - DEBUG - Log4jESLogger - [Lunatik] sending shard started for [mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:319 - DEBUG - Log4jESLogger - [Lunatik] received shard started for [mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:33:38:321 - TRACE - Log4jESLogger - [Lunatik] [mimos][0] writing shard state, reason [version changed from [12] to [14]]
2015-05-05-10:33:38:388 - TRACE - Log4jESLogger - [Lunatik] [mimos][4] writing shard state, reason [version changed from [12] to [14]]
2015-05-05-10:33:38:439 - TRACE - Log4jESLogger - [Lunatik] [mimos][3] writing shard state, reason [version changed from [12] to [14]]
2015-05-05-10:33:38:489 - TRACE - Log4jESLogger - [Lunatik] [mimos][2] writing shard state, reason [version changed from [12] to [14]]
2015-05-05-10:33:38:540 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-05-10:33:38:540 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-10:33:38:540 - DEBUG - Log4jESLogger - [Lunatik] applying started shards [[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-05-10:33:38:541 - TRACE - Log4jESLogger - [Lunatik] Start balancing cluster
2015-05-05-10:33:38:541 - TRACE - Log4jESLogger - [Lunatik] Start distributing Shards
2015-05-05-10:33:38:541 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:542 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:542 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:542 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:542 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:542 - TRACE - Log4jESLogger - [Lunatik] Start allocating unassigned shards
2015-05-05-10:33:38:543 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:543 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:543 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:543 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:544 - TRACE - Log4jESLogger - [Lunatik] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:33:38:544 - TRACE - Log4jESLogger - [Lunatik] Start balancing cluster
2015-05-05-10:33:38:544 - TRACE - Log4jESLogger - [Lunatik] Start distributing Shards
2015-05-05-10:33:38:544 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:545 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:545 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:545 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:545 - TRACE - Log4jESLogger - [Lunatik] Assigned shard [[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]] to node [evLdXoJnSD-4ilX71tarsw]
2015-05-05-10:33:38:545 - TRACE - Log4jESLogger - [Lunatik] Start allocating unassigned shards
2015-05-05-10:33:38:546 - TRACE - Log4jESLogger - [Lunatik] cluster state updated:
version [4], source [shard-started ([mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Lunatik][evLdXoJnSD-4ilX71tarsw][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[evLdXoJnSD-4ilX71tarsw][V]
--------[mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
--------[mimos][4], node[evLdXoJnSD-4ilX71tarsw], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-10:33:38:547 - DEBUG - Log4jESLogger - [Lunatik] Publishing cluster state version 4
2015-05-05-10:33:38:547 - DEBUG - Log4jESLogger - [Lunatik] Set cluster state to version 4. Broadcasting to listeners.
2015-05-05-10:33:38:547 - DEBUG - Log4jESLogger - [Lunatik] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:33:38:552 - DEBUG - Log4jESLogger - [Lunatik] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:33:38:554 - TRACE - Log4jESLogger - [Lunatik] [mimos][1] writing shard state, reason [version changed from [12] to [14]]
2015-05-05-10:33:38:607 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][3], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 4)
2015-05-05-10:33:38:607 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-10:33:38:607 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][0], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-05-10:33:38:608 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-10:33:38:608 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][2], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-05-10:33:38:608 - TRACE - Log4jESLogger - [Lunatik] listener to cluster state added, trying to index again
2015-05-05-10:33:38:616 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-10:33:38:616 - DEBUG - Log4jESLogger - [Lunatik] processing [shard-started ([mimos][1], node[evLdXoJnSD-4ilX71tarsw], [P], s[INITIALIZING]), reason [after recovery from gateway]]: no change in cluster_state
2015-05-05-10:33:38:657 - TRACE - Log4jESLogger - [Lunatik] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 61 75 74 68 6f 72 22 3a 22 31 22 2c 22 70 6f 73 74 44 61 74 65 22 3a 22 32 30 31 35 2d 30 35 2d 30 35 54 30 32 3a 33 33 3a 33 36 2e 37 38 36 5a 22 2c 22 74 69 74 6c 65 22 3a 22 4d 69 2d 72 65 73 74 6e 6f 73 71 6c 22 2c 22 63 6f 6e 74 65 6e 74 22 3a 22 63 6f 64 65 20 6f 70 74 69 6d 69 7a 61 74 69 6f 6e 22 2c 22 74 61 67 73 22 3a 5b 22 65 6c 61 73 74 69 63 73 65 61 72 63 68 22 5d 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<author:1> indexed,omitNorms,indexOptions=DOCS_ONLY<postDate:1430793216786> indexed,tokenized<title:Mi-restnosql> indexed,tokenized<content:code optimization> indexed,tokenized<tags:elasticsearch> indexed,tokenized<_all:>>]
2015-05-05-10:33:38:706 - DEBUG - Log4jESLogger - [Lunatik] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-05-10:33:38:709 - DEBUG - Log4jESLogger - [Lunatik] processing [update-mapping [mimos][Programmer]]: execute
2015-05-05-10:33:38:715 - DEBUG - Log4jESLogger - [Lunatik] processing [update-mapping [mimos][Programmer]]: no change in cluster_state
2015-05-05-10:34:49:871 - INFO  - Log4jESLogger - [Marko, Flint] version[0.90.5], pid[7303], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-05-10:34:49:875 - INFO  - Log4jESLogger - [Marko, Flint] initializing ...
2015-05-05-10:34:49:876 - DEBUG - Log4jESLogger - [Marko, Flint] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-05-10:34:49:886 - INFO  - Log4jESLogger - [Marko, Flint] loaded [], sites []
2015-05-05-10:34:49:911 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-05-10:34:49:914 - TRACE - Log4jESLogger - [Marko, Flint] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-05-10:34:49:922 - DEBUG - Log4jESLogger - [Marko, Flint] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-05-10:34:49:929 - TRACE - Log4jESLogger - [Marko, Flint] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [34.9gb], usable_space [29.7gb]

2015-05-05-10:34:50:506 - TRACE - Log4jESLogger - [Marko, Flint] sigar loaded successfully
2015-05-05-10:34:51:175 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-05-10:34:51:181 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-05-10:34:51:186 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-05-10:34:51:187 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-05-10:34:51:189 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-05-10:34:51:191 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-05-10:34:51:191 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-05-10:34:51:193 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-05-10:34:51:204 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:34:51:204 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:34:51:204 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:34:51:205 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:34:51:205 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:34:51:205 - DEBUG - Log4jESLogger - [Marko, Flint] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-05-10:34:51:221 - DEBUG - Log4jESLogger - [Marko, Flint] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-05-10:34:51:231 - DEBUG - Log4jESLogger - [Marko, Flint] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-05-10:34:51:235 - DEBUG - Log4jESLogger - [Marko, Flint] using initial hosts [], with concurrent_connects [10]
2015-05-05-10:34:51:237 - DEBUG - Log4jESLogger - [Marko, Flint] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-05-10:34:51:238 - DEBUG - Log4jESLogger - [Marko, Flint] using minimum_master_nodes [-1]
2015-05-05-10:34:51:240 - DEBUG - Log4jESLogger - [Marko, Flint] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-10:34:51:244 - DEBUG - Log4jESLogger - [Marko, Flint] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-10:34:51:282 - DEBUG - Log4jESLogger - [Marko, Flint] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-05-10:34:51:792 - DEBUG - Log4jESLogger - [Marko, Flint] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@47747fb9] with refresh_interval [1s]
2015-05-05-10:34:51:797 - DEBUG - Log4jESLogger - [Marko, Flint] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@1edb61b1] with refresh_interval [1s]
2015-05-05-10:34:51:804 - DEBUG - Log4jESLogger - [Marko, Flint] Using refresh_interval [1s]
2015-05-05-10:34:51:805 - DEBUG - Log4jESLogger - [Marko, Flint] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@52c8295b] with refresh_interval [5s]
2015-05-05-10:34:51:810 - DEBUG - Log4jESLogger - [Marko, Flint] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:a:8707:d723:bfb2%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-05-10:34:51:813 - TRACE - Log4jESLogger - [Marko, Flint] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:10972 errors:0 dropped:0 overruns:0 frame:0
	TX packets:10972 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:2865655 (2.7M)  TX bytes:2865655 (2.7M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:488165 errors:0 dropped:0 overruns:0 frame:0
	TX packets:237846 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:582679682 (556M)  TX bytes:25671477 ( 24M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:361 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:361 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-05-10:34:51:818 - DEBUG - Log4jESLogger - [Marko, Flint] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@581d969c] with refresh_interval [1s]
2015-05-05-10:34:52:072 - DEBUG - Log4jESLogger - [Marko, Flint] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-05-10:34:52:078 - DEBUG - Log4jESLogger - [Marko, Flint] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-05-10:34:52:086 - DEBUG - Log4jESLogger - [Marko, Flint] using script cache with max_size [500], expire [null]
2015-05-05-10:34:52:091 - DEBUG - Log4jESLogger - [Marko, Flint] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:34:52:093 - DEBUG - Log4jESLogger - [Marko, Flint] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:34:52:094 - DEBUG - Log4jESLogger - [Marko, Flint] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:34:52:099 - DEBUG - Log4jESLogger - [Marko, Flint] using initial_shards [quorum], list_timeout [30s]
2015-05-05-10:34:52:168 - DEBUG - Log4jESLogger - [Marko, Flint] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-05-10:34:52:283 - DEBUG - Log4jESLogger - [Marko, Flint] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-05-10:34:52:291 - DEBUG - Log4jESLogger - [Marko, Flint] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-05-10:34:52:296 - DEBUG - Log4jESLogger - [Marko, Flint] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-05-10:34:52:299 - DEBUG - Log4jESLogger - [Marko, Flint] using size [-1] [-1b], expire [null]
2015-05-05-10:34:52:325 - DEBUG - Log4jESLogger - [Marko, Flint] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-05-10:34:52:326 - TRACE - Log4jESLogger - [Marko, Flint] [upgrade]: processing [global-7]
2015-05-05-10:34:52:449 - DEBUG - Log4jESLogger - [Marko, Flint] took 123ms to load state
2015-05-05-10:34:52:451 - TRACE - Log4jESLogger - [Marko, Flint] [find_latest_state]: processing [global-7]
2015-05-05-10:34:52:458 - DEBUG - Log4jESLogger - [Marko, Flint] took 4ms to load started shards state
2015-05-05-10:34:52:460 - DEBUG - Log4jESLogger - [Marko, Flint] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-05-10:34:52:464 - DEBUG - Log4jESLogger - [Marko, Flint] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:34:52:465 - DEBUG - Log4jESLogger - [Marko, Flint] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:34:52:465 - DEBUG - Log4jESLogger - [Marko, Flint] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:34:52:466 - DEBUG - Log4jESLogger - [Marko, Flint] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:34:52:467 - DEBUG - Log4jESLogger - [Marko, Flint] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:34:52:467 - DEBUG - Log4jESLogger - [Marko, Flint] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:34:52:472 - INFO  - Log4jESLogger - [Marko, Flint] initialized
2015-05-05-10:34:52:472 - INFO  - Log4jESLogger - [Marko, Flint] starting ...
2015-05-05-10:34:52:497 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-05-10:34:52:497 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-05-10:34:52:580 - DEBUG - Log4jESLogger - [Marko, Flint] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-05-10:34:52:586 - INFO  - Log4jESLogger - [Marko, Flint] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-05-10:34:52:616 - TRACE - Log4jESLogger - [Marko, Flint] waiting for 30s for the initial state to be set by the discovery
2015-05-05-10:34:52:627 - TRACE - Log4jESLogger - [Marko, Flint] [1] sending ping request
2015-05-05-10:34:54:129 - TRACE - Log4jESLogger - [Marko, Flint] [1] sending ping request
2015-05-05-10:34:55:631 - TRACE - Log4jESLogger - [Marko, Flint] full ping responses: {none}
2015-05-05-10:34:55:631 - DEBUG - Log4jESLogger - [Marko, Flint] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-05-10:34:55:635 - DEBUG - Log4jESLogger - [Marko, Flint] processing [zen-disco-join (elected_as_master)]: execute
2015-05-05-10:34:55:636 - TRACE - Log4jESLogger - [Marko, Flint] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Marko, Flint][xLkRmy02Rw2jfcWN4hFdxQ][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[xLkRmy02Rw2jfcWN4hFdxQ][V]
---- unassigned

2015-05-05-10:34:55:638 - INFO  - Log4jESLogger - [Marko, Flint] new_master [Marko, Flint][xLkRmy02Rw2jfcWN4hFdxQ][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-05-10:34:55:654 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0x0a938485, /10.11.66.27:54662 => /10.11.66.27:9300]
2015-05-05-10:34:55:656 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0x62603946, /10.11.66.27:54663 => /10.11.66.27:9300]
2015-05-05-10:34:55:657 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0xa4af4f0c, /10.11.66.27:54664 => /10.11.66.27:9300]
2015-05-05-10:34:55:658 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0x7dab0f08, /10.11.66.27:54665 => /10.11.66.27:9300]
2015-05-05-10:34:55:659 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0xb49c1565, /10.11.66.27:54666 => /10.11.66.27:9300]
2015-05-05-10:34:55:660 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0xb4a4daa7, /10.11.66.27:54667 => /10.11.66.27:9300]
2015-05-05-10:34:55:661 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0x874c3665, /10.11.66.27:54668 => /10.11.66.27:9300]
2015-05-05-10:34:55:663 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0x1679a5dd, /10.11.66.27:54669 => /10.11.66.27:9300]
2015-05-05-10:34:55:668 - DEBUG - Log4jESLogger - [Marko, Flint] connected to node [[Marko, Flint][xLkRmy02Rw2jfcWN4hFdxQ][inet[/10.11.66.27:9300]]]
2015-05-05-10:34:55:669 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0x6c49a7d8, /10.11.66.27:54670 => /10.11.66.27:9300]
2015-05-05-10:34:55:669 - DEBUG - Log4jESLogger - [Marko, Flint] Publishing cluster state version 1
2015-05-05-10:34:55:670 - TRACE - Log4jESLogger - [Marko, Flint] channel opened: [id: 0x7e81d207, /10.11.66.27:54671 => /10.11.66.27:9300]
2015-05-05-10:34:55:670 - DEBUG - Log4jESLogger - [Marko, Flint] Set cluster state to version 1. Broadcasting to listeners.
2015-05-05-10:34:55:673 - DEBUG - Log4jESLogger - [Marko, Flint] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:34:55:673 - DEBUG - Log4jESLogger - [Marko, Flint] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:34:55:674 - TRACE - Log4jESLogger - [Marko, Flint] initial state set from discovery
2015-05-05-10:34:55:674 - TRACE - Log4jESLogger - [Marko, Flint] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-05-10:34:55:674 - DEBUG - Log4jESLogger - [Marko, Flint] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-05-10:34:55:674 - INFO  - Log4jESLogger - [Marko, Flint] peansData/xLkRmy02Rw2jfcWN4hFdxQ
2015-05-05-10:34:55:675 - TRACE - Log4jESLogger - [Marko, Flint] performing state recovery...
2015-05-05-10:34:55:676 - TRACE - Log4jESLogger - [Marko, Flint] performing state recovery from [xLkRmy02Rw2jfcWN4hFdxQ]
2015-05-05-10:34:55:683 - TRACE - Log4jESLogger - [Marko, Flint] successful state recovery, importing cluster state...
2015-05-05-10:34:55:684 - DEBUG - Log4jESLogger - [Marko, Flint] processing [local-gateway-elected-state]: execute
2015-05-05-10:34:55:705 - INFO  - Log4jESLogger - [Marko, Flint] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-05-10:34:55:706 - INFO  - Log4jESLogger - [Marko, Flint] started
2015-05-05-10:34:55:706 - DEBUG - Log4jESLogger - [Marko, Flint] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Marko, Flint][xLkRmy02Rw2jfcWN4hFdxQ][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:34:55:707 - DEBUG - Log4jESLogger - [Marko, Flint] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Marko, Flint][xLkRmy02Rw2jfcWN4hFdxQ][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:34:55:708 - DEBUG - Log4jESLogger - [Marko, Flint] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Marko, Flint][xLkRmy02Rw2jfcWN4hFdxQ][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:34:55:708 - DEBUG - Log4jESLogger - [Marko, Flint] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Marko, Flint][xLkRmy02Rw2jfcWN4hFdxQ][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:34:55:709 - DEBUG - Log4jESLogger - [Marko, Flint] [mimos][1]: throttling allocation [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[[Marko, Flint][xLkRmy02Rw2jfcWN4hFdxQ][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-05-10:34:55:716 - TRACE - Log4jESLogger - [Marko, Flint] Start balancing cluster
2015-05-05-10:34:55:717 - TRACE - Log4jESLogger - [Marko, Flint] Start distributing Shards
2015-05-05-10:39:00:952 - INFO  - Log4jESLogger - [Zarek] version[0.90.5], pid[7557], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-05-10:39:00:955 - INFO  - Log4jESLogger - [Zarek] initializing ...
2015-05-05-10:39:00:956 - DEBUG - Log4jESLogger - [Zarek] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-05-10:39:00:965 - INFO  - Log4jESLogger - [Zarek] loaded [], sites []
2015-05-05-10:39:00:990 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-05-10:39:00:994 - TRACE - Log4jESLogger - [Zarek] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-05-10:39:01:001 - DEBUG - Log4jESLogger - [Zarek] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-05-10:39:01:006 - TRACE - Log4jESLogger - [Zarek] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [34.9gb], usable_space [29.7gb]

2015-05-05-10:39:01:559 - TRACE - Log4jESLogger - [Zarek] sigar loaded successfully
2015-05-05-10:39:02:179 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-05-10:39:02:185 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-05-10:39:02:189 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-05-10:39:02:190 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-05-10:39:02:191 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-05-10:39:02:193 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-05-10:39:02:203 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-05-10:39:02:205 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-05-10:39:02:206 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:39:02:207 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:39:02:207 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:39:02:208 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:39:02:208 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:39:02:208 - DEBUG - Log4jESLogger - [Zarek] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-05-10:39:02:224 - DEBUG - Log4jESLogger - [Zarek] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-05-10:39:02:234 - DEBUG - Log4jESLogger - [Zarek] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-05-10:39:02:240 - DEBUG - Log4jESLogger - [Zarek] using initial hosts [], with concurrent_connects [10]
2015-05-05-10:39:02:243 - DEBUG - Log4jESLogger - [Zarek] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-05-10:39:02:244 - DEBUG - Log4jESLogger - [Zarek] using minimum_master_nodes [-1]
2015-05-05-10:39:02:247 - DEBUG - Log4jESLogger - [Zarek] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-10:39:02:253 - DEBUG - Log4jESLogger - [Zarek] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-10:39:02:293 - DEBUG - Log4jESLogger - [Zarek] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-05-10:39:02:803 - DEBUG - Log4jESLogger - [Zarek] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-05-10:39:02:808 - DEBUG - Log4jESLogger - [Zarek] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-05-10:39:02:816 - DEBUG - Log4jESLogger - [Zarek] Using refresh_interval [1s]
2015-05-05-10:39:02:816 - DEBUG - Log4jESLogger - [Zarek] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-05-10:39:02:821 - DEBUG - Log4jESLogger - [Zarek] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:a:8707:d723:bfb2%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-05-10:39:02:824 - TRACE - Log4jESLogger - [Zarek] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:11308 errors:0 dropped:0 overruns:0 frame:0
	TX packets:11308 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:2898834 (2.8M)  TX bytes:2898834 (2.8M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:502585 errors:0 dropped:0 overruns:0 frame:0
	TX packets:245682 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:597707341 (570M)  TX bytes:26740154 ( 26M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:372 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:372 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-05-10:39:02:830 - DEBUG - Log4jESLogger - [Zarek] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-05-10:39:03:112 - DEBUG - Log4jESLogger - [Zarek] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-05-10:39:03:119 - DEBUG - Log4jESLogger - [Zarek] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-05-10:39:03:131 - DEBUG - Log4jESLogger - [Zarek] using script cache with max_size [500], expire [null]
2015-05-05-10:39:03:136 - DEBUG - Log4jESLogger - [Zarek] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:39:03:139 - DEBUG - Log4jESLogger - [Zarek] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:39:03:139 - DEBUG - Log4jESLogger - [Zarek] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:39:03:145 - DEBUG - Log4jESLogger - [Zarek] using initial_shards [quorum], list_timeout [30s]
2015-05-05-10:39:03:254 - DEBUG - Log4jESLogger - [Zarek] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-05-10:39:03:330 - DEBUG - Log4jESLogger - [Zarek] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-05-10:39:03:339 - DEBUG - Log4jESLogger - [Zarek] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-05-10:39:03:341 - DEBUG - Log4jESLogger - [Zarek] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-05-10:39:03:343 - DEBUG - Log4jESLogger - [Zarek] using size [-1] [-1b], expire [null]
2015-05-05-10:39:03:362 - DEBUG - Log4jESLogger - [Zarek] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-05-10:39:03:363 - TRACE - Log4jESLogger - [Zarek] [upgrade]: processing [global-7]
2015-05-05-10:39:03:494 - DEBUG - Log4jESLogger - [Zarek] took 130ms to load state
2015-05-05-10:39:03:495 - TRACE - Log4jESLogger - [Zarek] [find_latest_state]: processing [global-7]
2015-05-05-10:39:03:499 - DEBUG - Log4jESLogger - [Zarek] took 3ms to load started shards state
2015-05-05-10:39:03:504 - DEBUG - Log4jESLogger - [Zarek] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-05-10:39:03:513 - DEBUG - Log4jESLogger - [Zarek] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:39:03:514 - DEBUG - Log4jESLogger - [Zarek] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:39:03:514 - DEBUG - Log4jESLogger - [Zarek] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:39:03:515 - DEBUG - Log4jESLogger - [Zarek] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:39:03:515 - DEBUG - Log4jESLogger - [Zarek] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:39:03:516 - DEBUG - Log4jESLogger - [Zarek] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:39:03:520 - INFO  - Log4jESLogger - [Zarek] initialized
2015-05-05-10:39:03:521 - INFO  - Log4jESLogger - [Zarek] starting ...
2015-05-05-10:39:03:551 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-05-10:39:03:552 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-05-10:39:03:632 - DEBUG - Log4jESLogger - [Zarek] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-05-10:39:03:636 - INFO  - Log4jESLogger - [Zarek] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-05-10:39:03:664 - TRACE - Log4jESLogger - [Zarek] waiting for 30s for the initial state to be set by the discovery
2015-05-05-10:39:03:675 - TRACE - Log4jESLogger - [Zarek] [1] sending ping request
2015-05-05-10:39:05:177 - TRACE - Log4jESLogger - [Zarek] [1] sending ping request
2015-05-05-10:39:06:680 - TRACE - Log4jESLogger - [Zarek] full ping responses: {none}
2015-05-05-10:39:06:681 - DEBUG - Log4jESLogger - [Zarek] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-05-10:39:06:684 - DEBUG - Log4jESLogger - [Zarek] processing [zen-disco-join (elected_as_master)]: execute
2015-05-05-10:39:06:686 - TRACE - Log4jESLogger - [Zarek] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[GnONWZGxTuKjZJ0EmMeKcA][V]
---- unassigned

2015-05-05-10:39:06:688 - INFO  - Log4jESLogger - [Zarek] new_master [Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-05-10:39:06:703 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0x9103b166, /10.11.66.27:54829 => /10.11.66.27:9300]
2015-05-05-10:39:06:706 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0xff8c573c, /10.11.66.27:54830 => /10.11.66.27:9300]
2015-05-05-10:39:06:707 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0x5065bfd8, /10.11.66.27:54831 => /10.11.66.27:9300]
2015-05-05-10:39:06:708 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0x51120cd2, /10.11.66.27:54832 => /10.11.66.27:9300]
2015-05-05-10:39:06:709 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0x91f6f6f6, /10.11.66.27:54833 => /10.11.66.27:9300]
2015-05-05-10:39:06:709 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0xce3c4f01, /10.11.66.27:54834 => /10.11.66.27:9300]
2015-05-05-10:39:06:710 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0xf52f31c2, /10.11.66.27:54835 => /10.11.66.27:9300]
2015-05-05-10:39:06:714 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0xc142d75a, /10.11.66.27:54836 => /10.11.66.27:9300]
2015-05-05-10:39:06:721 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0xca2a6d23, /10.11.66.27:54837 => /10.11.66.27:9300]
2015-05-05-10:39:06:722 - TRACE - Log4jESLogger - [Zarek] channel opened: [id: 0x6e6aa477, /10.11.66.27:54838 => /10.11.66.27:9300]
2015-05-05-10:39:06:724 - DEBUG - Log4jESLogger - [Zarek] connected to node [[Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]]]
2015-05-05-10:39:06:725 - DEBUG - Log4jESLogger - [Zarek] Publishing cluster state version 1
2015-05-05-10:39:06:726 - DEBUG - Log4jESLogger - [Zarek] Set cluster state to version 1. Broadcasting to listeners.
2015-05-05-10:39:06:731 - TRACE - Log4jESLogger - [Zarek] initial state set from discovery
2015-05-05-10:39:06:732 - INFO  - Log4jESLogger - [Zarek] peansData/GnONWZGxTuKjZJ0EmMeKcA
2015-05-05-10:39:06:733 - TRACE - Log4jESLogger - [Zarek] performing state recovery...
2015-05-05-10:39:06:734 - TRACE - Log4jESLogger - [Zarek] performing state recovery from [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:731 - TRACE - Log4jESLogger - [Zarek] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-05-10:39:06:731 - DEBUG - Log4jESLogger - [Zarek] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:39:06:731 - DEBUG - Log4jESLogger - [Zarek] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-05-10:39:06:744 - DEBUG - Log4jESLogger - [Zarek] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:39:06:745 - TRACE - Log4jESLogger - [Zarek] successful state recovery, importing cluster state...
2015-05-05-10:39:06:746 - DEBUG - Log4jESLogger - [Zarek] processing [local-gateway-elected-state]: execute
2015-05-05-10:39:06:767 - DEBUG - Log4jESLogger - [Zarek] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:39:06:768 - INFO  - Log4jESLogger - [Zarek] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-05-10:39:06:768 - INFO  - Log4jESLogger - [Zarek] started
2015-05-05-10:39:06:780 - DEBUG - Log4jESLogger - [Zarek] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:39:06:781 - DEBUG - Log4jESLogger - [Zarek] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:39:06:782 - DEBUG - Log4jESLogger - [Zarek] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:39:06:783 - DEBUG - Log4jESLogger - [Zarek] [mimos][0]: throttling allocation [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[[Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-05-10:39:06:808 - TRACE - Log4jESLogger - [Zarek] Start balancing cluster
2015-05-05-10:39:06:810 - TRACE - Log4jESLogger - [Zarek] Start distributing Shards
2015-05-05-10:39:06:812 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:812 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:813 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:814 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:820 - TRACE - Log4jESLogger - [Zarek] Start allocating unassigned shards
2015-05-05-10:39:06:822 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:06:832 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:06:833 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:06:833 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:06:833 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:06:834 - TRACE - Log4jESLogger - [Zarek] Start balancing cluster
2015-05-05-10:39:06:835 - TRACE - Log4jESLogger - [Zarek] Start distributing Shards
2015-05-05-10:39:06:835 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:835 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:837 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:838 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:06:838 - TRACE - Log4jESLogger - [Zarek] Start allocating unassigned shards
2015-05-05-10:39:06:841 - TRACE - Log4jESLogger - [Zarek] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[null], [P], s[UNASSIGNED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[GnONWZGxTuKjZJ0EmMeKcA][V]
--------[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [P], s[UNASSIGNED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-10:39:06:842 - DEBUG - Log4jESLogger - [Zarek] Publishing cluster state version 2
2015-05-05-10:39:06:844 - DEBUG - Log4jESLogger - [Zarek] Set cluster state to version 2. Broadcasting to listeners.
2015-05-05-10:39:06:846 - DEBUG - Log4jESLogger - [Zarek] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:39:06:847 - DEBUG - Log4jESLogger - [Zarek] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:39:06:847 - DEBUG - Log4jESLogger - [Zarek] [mimos] creating index
2015-05-05-10:39:06:849 - DEBUG - Log4jESLogger - [Zarek] creating Index [mimos], shards [5]/[1]
2015-05-05-10:39:07:260 - TRACE - Log4jESLogger - [Zarek] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [GnONWZGxTuKjZJ0EmMeKcA], scheduling a retry.
2015-05-05-10:39:07:267 - DEBUG - Log4jESLogger - [Zarek] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-05-10:39:07:268 - DEBUG - Log4jESLogger - [Zarek] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-05-10:39:07:283 - DEBUG - Log4jESLogger - [Zarek] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-05-10:39:07:365 - DEBUG - Log4jESLogger - [Zarek] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"author":{"type":"string"},"content":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-05-10:39:07:457 - DEBUG - Log4jESLogger - [Zarek] Sending mapping created for index mimos, type Programmer
2015-05-05-10:39:07:460 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] creating shard
2015-05-05-10:39:07:460 - DEBUG - Log4jESLogger - [Zarek] [mimos] creating shard_id [1]
2015-05-05-10:39:07:587 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] Using [keep_only_last] deletion policy
2015-05-05-10:39:07:591 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:39:07:592 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:39:07:599 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] state: [CREATED]
2015-05-05-10:39:07:600 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:39:07:609 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:39:07:611 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] creating shard
2015-05-05-10:39:07:611 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] starting recovery from local ...
2015-05-05-10:39:07:612 - DEBUG - Log4jESLogger - [Zarek] [mimos] creating shard_id [2]
2015-05-05-10:39:07:620 - TRACE - Log4jESLogger - [Zarek] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-05-10:39:07:621 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] starting engine
2015-05-05-10:39:07:627 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] Using [keep_only_last] deletion policy
2015-05-05-10:39:07:627 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:39:07:628 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:39:07:629 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] state: [CREATED]
2015-05-05-10:39:07:629 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:39:07:630 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:39:07:630 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] creating shard
2015-05-05-10:39:07:630 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] starting recovery from local ...
2015-05-05-10:39:07:634 - DEBUG - Log4jESLogger - [Zarek] [mimos] creating shard_id [3]
2015-05-05-10:39:07:635 - TRACE - Log4jESLogger - [Zarek] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-05-10:39:07:636 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] starting engine
2015-05-05-10:39:07:655 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] Using [keep_only_last] deletion policy
2015-05-05-10:39:07:657 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:39:07:658 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:39:07:671 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] state: [CREATED]
2015-05-05-10:39:07:673 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:39:07:673 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:39:07:674 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] creating shard
2015-05-05-10:39:07:674 - DEBUG - Log4jESLogger - [Zarek] [mimos] creating shard_id [4]
2015-05-05-10:39:07:680 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] starting recovery from local ...
2015-05-05-10:39:07:685 - TRACE - Log4jESLogger - [Zarek] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-05-10:39:07:685 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] starting engine
2015-05-05-10:39:07:687 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] Using [keep_only_last] deletion policy
2015-05-05-10:39:07:705 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:39:07:705 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:39:07:706 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] state: [CREATED]
2015-05-05-10:39:07:707 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:39:07:707 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:39:07:722 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] starting recovery from local ...
2015-05-05-10:39:07:725 - TRACE - Log4jESLogger - [Zarek] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-05-10:39:07:728 - TRACE - Log4jESLogger - [Zarek] [_global] writing state, reason [changed]
2015-05-05-10:39:07:729 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] starting engine
2015-05-05-10:39:07:752 - TRACE - Log4jESLogger - [Zarek] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:39:07:754 - TRACE - Log4jESLogger - [Zarek] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:39:07:754 - TRACE - Log4jESLogger - [Zarek] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:39:07:755 - TRACE - Log4jESLogger - [Zarek] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:39:07:758 - TRACE - Log4jESLogger - [Zarek] [mimos][1] warming took [3.8ms]
2015-05-05-10:39:07:758 - TRACE - Log4jESLogger - [Zarek] [mimos][3] warming took [5.1ms]
2015-05-05-10:39:07:763 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:39:07:762 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:39:07:766 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] scheduling refresher every 1s
2015-05-05-10:39:07:768 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] scheduling optimizer / merger every 1s
2015-05-05-10:39:07:768 - TRACE - Log4jESLogger - [Zarek] [mimos][3] refresh with force[true]
2015-05-05-10:39:07:769 - DEBUG - Log4jESLogger - [Zarek] [mimos][3] recovery completed from [local], took [89ms]
2015-05-05-10:39:07:767 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] scheduling refresher every 1s
2015-05-05-10:39:07:769 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] scheduling optimizer / merger every 1s
2015-05-05-10:39:07:770 - TRACE - Log4jESLogger - [Zarek] [mimos][1] refresh with force[true]
2015-05-05-10:39:07:770 - DEBUG - Log4jESLogger - [Zarek] [mimos][1] recovery completed from [local], took [159ms]
2015-05-05-10:39:07:770 - DEBUG - Log4jESLogger - [Zarek] sending shard started for [mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:770 - DEBUG - Log4jESLogger - [Zarek] received shard started for [mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:771 - DEBUG - Log4jESLogger - [Zarek] sending shard started for [mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:772 - DEBUG - Log4jESLogger - [Zarek] received shard started for [mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:772 - TRACE - Log4jESLogger - [Zarek] [mimos][2] warming took [17.4ms]
2015-05-05-10:39:07:774 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:39:07:774 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] scheduling refresher every 1s
2015-05-05-10:39:07:774 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] scheduling optimizer / merger every 1s
2015-05-05-10:39:07:774 - TRACE - Log4jESLogger - [Zarek] [mimos][2] refresh with force[true]
2015-05-05-10:39:07:775 - DEBUG - Log4jESLogger - [Zarek] [mimos][2] recovery completed from [local], took [145ms]
2015-05-05-10:39:07:775 - DEBUG - Log4jESLogger - [Zarek] sending shard started for [mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:775 - DEBUG - Log4jESLogger - [Zarek] received shard started for [mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:775 - TRACE - Log4jESLogger - [Zarek] [mimos][4] warming took [19.8ms]
2015-05-05-10:39:07:776 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:39:07:777 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] scheduling refresher every 1s
2015-05-05-10:39:07:777 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] scheduling optimizer / merger every 1s
2015-05-05-10:39:07:777 - TRACE - Log4jESLogger - [Zarek] [mimos][4] refresh with force[true]
2015-05-05-10:39:07:778 - DEBUG - Log4jESLogger - [Zarek] [mimos][4] recovery completed from [local], took [56ms]
2015-05-05-10:39:07:778 - DEBUG - Log4jESLogger - [Zarek] sending shard started for [mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:778 - DEBUG - Log4jESLogger - [Zarek] received shard started for [mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:800 - INFO  - Log4jESLogger - [Zarek] recovered [1] indices into cluster_state
2015-05-05-10:39:07:801 - DEBUG - Log4jESLogger - [Zarek] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-05-10:39:07:802 - TRACE - Log4jESLogger - [Zarek] listener to cluster state added, trying to index again
2015-05-05-10:39:07:802 - TRACE - Log4jESLogger - [Zarek] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [GnONWZGxTuKjZJ0EmMeKcA], scheduling a retry.
2015-05-05-10:39:07:802 - TRACE - Log4jESLogger - [Zarek] retry scheduling ignored as it as we already have a listener in place
2015-05-05-10:39:07:802 - DEBUG - Log4jESLogger - [Zarek] processing [shard-started ([mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-10:39:07:803 - DEBUG - Log4jESLogger - [Zarek] applying started shards [[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], [mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], [mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], [mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-05-10:39:07:804 - DEBUG - Log4jESLogger - [Zarek] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:39:07:804 - TRACE - Log4jESLogger - [Zarek] Start balancing cluster
2015-05-05-10:39:07:808 - TRACE - Log4jESLogger - [Zarek] Start distributing Shards
2015-05-05-10:39:07:809 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:809 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:809 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:809 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:809 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][0], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:810 - TRACE - Log4jESLogger - [Zarek] Start allocating unassigned shards
2015-05-05-10:39:07:810 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:07:810 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:07:810 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:07:811 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:07:812 - TRACE - Log4jESLogger - [Zarek] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:39:07:812 - TRACE - Log4jESLogger - [Zarek] Start balancing cluster
2015-05-05-10:39:07:813 - TRACE - Log4jESLogger - [Zarek] Start distributing Shards
2015-05-05-10:39:07:813 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:813 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:813 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:813 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:814 - TRACE - Log4jESLogger - [Zarek] Assigned shard [[mimos][0], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]] to node [GnONWZGxTuKjZJ0EmMeKcA]
2015-05-05-10:39:07:814 - TRACE - Log4jESLogger - [Zarek] Start allocating unassigned shards
2015-05-05-10:39:07:825 - TRACE - Log4jESLogger - [Zarek] cluster state updated:
version [3], source [shard-started ([mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Zarek][GnONWZGxTuKjZJ0EmMeKcA][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[GnONWZGxTuKjZJ0EmMeKcA][V]
--------[mimos][0], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING]
--------[mimos][1], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]
--------[mimos][2], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]
--------[mimos][3], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]
--------[mimos][4], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-10:39:07:826 - DEBUG - Log4jESLogger - [Zarek] Publishing cluster state version 3
2015-05-05-10:39:07:826 - DEBUG - Log4jESLogger - [Zarek] Set cluster state to version 3. Broadcasting to listeners.
2015-05-05-10:39:07:826 - DEBUG - Log4jESLogger - [Zarek] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:39:07:827 - DEBUG - Log4jESLogger - [Zarek] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:39:07:827 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] creating shard
2015-05-05-10:39:07:828 - DEBUG - Log4jESLogger - [Zarek] [mimos] creating shard_id [0]
2015-05-05-10:39:07:835 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] Using [keep_only_last] deletion policy
2015-05-05-10:39:07:837 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:39:07:837 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:39:07:838 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] state: [CREATED]
2015-05-05-10:39:07:839 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:39:07:840 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:39:07:841 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] starting recovery from local ...
2015-05-05-10:39:07:842 - TRACE - Log4jESLogger - [Zarek] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-05-10:39:07:842 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] starting engine
2015-05-05-10:39:07:844 - TRACE - Log4jESLogger - [Zarek] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:39:07:845 - TRACE - Log4jESLogger - [Zarek] [mimos][0] warming took [187.1micros]
2015-05-05-10:39:07:846 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:39:07:847 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] scheduling refresher every 1s
2015-05-05-10:39:07:847 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] scheduling optimizer / merger every 1s
2015-05-05-10:39:07:847 - TRACE - Log4jESLogger - [Zarek] [mimos][0] refresh with force[true]
2015-05-05-10:39:07:847 - DEBUG - Log4jESLogger - [Zarek] [mimos][0] recovery completed from [local], took [6ms]
2015-05-05-10:39:07:848 - DEBUG - Log4jESLogger - [Zarek] sending shard started for [mimos][0], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:848 - DEBUG - Log4jESLogger - [Zarek] received shard started for [mimos][0], node[GnONWZGxTuKjZJ0EmMeKcA], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:39:07:855 - TRACE - Log4jESLogger - [Zarek] cluster changed (version 3), trying to index again
2015-05-05-10:39:07:864 - TRACE - Log4jESLogger - [Zarek] [mimos][4] writing shard state, reason [version changed from [14] to [16]]
2015-05-05-10:39:07:906 - TRACE - Log4jESLogger - [Zarek] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-05-10:39:07:949 - TRACE - Log4jESLogger - [Zarek] [mimos][3] writing shard state, reason [version changed from [14] to [16]]
2015-05-05-10:39:07:949 - DEBUG - Log4jESLogger - [Zarek] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-05-10:40:06:186 - INFO  - Log4jESLogger - [Scratch, Nicholas] version[0.90.5], pid[7670], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-05-10:40:06:189 - INFO  - Log4jESLogger - [Scratch, Nicholas] initializing ...
2015-05-05-10:40:06:190 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-05-10:40:06:202 - INFO  - Log4jESLogger - [Scratch, Nicholas] loaded [], sites []
2015-05-05-10:40:06:224 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-05-10:40:06:228 - TRACE - Log4jESLogger - [Scratch, Nicholas] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-05-10:40:06:235 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-05-10:40:06:241 - TRACE - Log4jESLogger - [Scratch, Nicholas] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [34.9gb], usable_space [29.7gb]

2015-05-05-10:40:06:799 - TRACE - Log4jESLogger - [Scratch, Nicholas] sigar loaded successfully
2015-05-05-10:40:07:407 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-05-10:40:07:413 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-05-10:40:07:416 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-05-10:40:07:417 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-05-10:40:07:419 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-05-10:40:07:420 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-05-10:40:07:431 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-05-10:40:07:433 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-05-10:40:07:434 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:40:07:435 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:40:07:436 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:40:07:436 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:40:07:436 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-10:40:07:437 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-05-10:40:07:452 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-05-10:40:07:463 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-05-10:40:07:470 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using initial hosts [], with concurrent_connects [10]
2015-05-05-10:40:07:472 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-05-10:40:07:473 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using minimum_master_nodes [-1]
2015-05-05-10:40:07:475 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-10:40:07:480 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-10:40:07:517 - DEBUG - Log4jESLogger - [Scratch, Nicholas] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-05-10:40:08:026 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-05-10:40:08:031 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-05-10:40:08:038 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Using refresh_interval [1s]
2015-05-05-10:40:08:039 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-05-10:40:08:044 - DEBUG - Log4jESLogger - [Scratch, Nicholas] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:a:8707:d723:bfb2%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-05-10:40:08:047 - TRACE - Log4jESLogger - [Scratch, Nicholas] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:11414 errors:0 dropped:0 overruns:0 frame:0
	TX packets:11414 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:2907996 (2.8M)  TX bytes:2907996 (2.8M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:508622 errors:0 dropped:0 overruns:0 frame:0
	TX packets:249059 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:604907042 (577M)  TX bytes:27096222 ( 26M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:374 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:374 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-05-10:40:08:053 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-05-10:40:08:306 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-05-10:40:08:312 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-05-10:40:08:320 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using script cache with max_size [500], expire [null]
2015-05-05-10:40:08:325 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:40:08:326 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:40:08:326 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:40:08:330 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using initial_shards [quorum], list_timeout [30s]
2015-05-05-10:40:08:399 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-05-10:40:08:480 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-05-10:40:08:492 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-05-10:40:08:496 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-05-10:40:08:499 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using size [-1] [-1b], expire [null]
2015-05-05-10:40:08:527 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-05-10:40:08:528 - TRACE - Log4jESLogger - [Scratch, Nicholas] [upgrade]: processing [global-8]
2015-05-05-10:40:08:658 - DEBUG - Log4jESLogger - [Scratch, Nicholas] took 128ms to load state
2015-05-05-10:40:08:659 - TRACE - Log4jESLogger - [Scratch, Nicholas] [find_latest_state]: processing [global-8]
2015-05-05-10:40:08:662 - DEBUG - Log4jESLogger - [Scratch, Nicholas] took 3ms to load started shards state
2015-05-05-10:40:08:664 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-05-10:40:08:668 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:40:08:668 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:40:08:669 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:40:08:669 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-10:40:08:670 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-10:40:08:670 - DEBUG - Log4jESLogger - [Scratch, Nicholas] using [cluster_concurrent_rebalance] with [2]
2015-05-05-10:40:08:675 - INFO  - Log4jESLogger - [Scratch, Nicholas] initialized
2015-05-05-10:40:08:675 - INFO  - Log4jESLogger - [Scratch, Nicholas] starting ...
2015-05-05-10:40:08:696 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-05-10:40:08:696 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-05-10:40:08:759 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-05-10:40:08:764 - INFO  - Log4jESLogger - [Scratch, Nicholas] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-05-10:40:08:787 - TRACE - Log4jESLogger - [Scratch, Nicholas] waiting for 30s for the initial state to be set by the discovery
2015-05-05-10:40:08:800 - TRACE - Log4jESLogger - [Scratch, Nicholas] [1] sending ping request
2015-05-05-10:40:10:303 - TRACE - Log4jESLogger - [Scratch, Nicholas] [1] sending ping request
2015-05-05-10:40:11:805 - TRACE - Log4jESLogger - [Scratch, Nicholas] full ping responses: {none}
2015-05-05-10:40:11:805 - DEBUG - Log4jESLogger - [Scratch, Nicholas] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-05-10:40:11:809 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [zen-disco-join (elected_as_master)]: execute
2015-05-05-10:40:11:811 - TRACE - Log4jESLogger - [Scratch, Nicholas] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[CP_maFCdQTOVobnJFxUeXg][V]
---- unassigned

2015-05-05-10:40:11:812 - INFO  - Log4jESLogger - [Scratch, Nicholas] new_master [Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-05-10:40:11:830 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x85cdf22a, /10.11.66.27:54852 => /10.11.66.27:9300]
2015-05-05-10:40:11:835 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x7704eac1, /10.11.66.27:54853 => /10.11.66.27:9300]
2015-05-05-10:40:11:837 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x938cbf6c, /10.11.66.27:54854 => /10.11.66.27:9300]
2015-05-05-10:40:11:846 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0xa4afbea8, /10.11.66.27:54855 => /10.11.66.27:9300]
2015-05-05-10:40:11:847 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x907df2a8, /10.11.66.27:54856 => /10.11.66.27:9300]
2015-05-05-10:40:11:848 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x9e769642, /10.11.66.27:54857 => /10.11.66.27:9300]
2015-05-05-10:40:11:848 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x2b9274e9, /10.11.66.27:54858 => /10.11.66.27:9300]
2015-05-05-10:40:11:849 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x2a2591b4, /10.11.66.27:54859 => /10.11.66.27:9300]
2015-05-05-10:40:11:850 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x0f53eb25, /10.11.66.27:54860 => /10.11.66.27:9300]
2015-05-05-10:40:11:852 - TRACE - Log4jESLogger - [Scratch, Nicholas] channel opened: [id: 0x9700bda1, /10.11.66.27:54861 => /10.11.66.27:9300]
2015-05-05-10:40:11:856 - DEBUG - Log4jESLogger - [Scratch, Nicholas] connected to node [[Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]]]
2015-05-05-10:40:11:861 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Publishing cluster state version 1
2015-05-05-10:40:11:861 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Set cluster state to version 1. Broadcasting to listeners.
2015-05-05-10:40:11:864 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:40:11:864 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:40:11:868 - TRACE - Log4jESLogger - [Scratch, Nicholas] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-05-10:40:11:868 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-05-10:40:11:868 - TRACE - Log4jESLogger - [Scratch, Nicholas] initial state set from discovery
2015-05-05-10:40:11:869 - INFO  - Log4jESLogger - [Scratch, Nicholas] peansData/CP_maFCdQTOVobnJFxUeXg
2015-05-05-10:40:11:870 - TRACE - Log4jESLogger - [Scratch, Nicholas] performing state recovery...
2015-05-05-10:40:11:871 - TRACE - Log4jESLogger - [Scratch, Nicholas] performing state recovery from [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:881 - TRACE - Log4jESLogger - [Scratch, Nicholas] successful state recovery, importing cluster state...
2015-05-05-10:40:11:882 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [local-gateway-elected-state]: execute
2015-05-05-10:40:11:894 - INFO  - Log4jESLogger - [Scratch, Nicholas] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-05-10:40:11:894 - INFO  - Log4jESLogger - [Scratch, Nicholas] started
2015-05-05-10:40:11:913 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:40:11:914 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:40:11:916 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:40:11:917 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:40:11:918 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0]: throttling allocation [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[[Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-05-10:40:11:922 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start balancing cluster
2015-05-05-10:40:11:924 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start distributing Shards
2015-05-05-10:40:11:926 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:926 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:927 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:927 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:927 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start allocating unassigned shards
2015-05-05-10:40:11:930 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:11:930 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:11:931 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:11:932 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:11:932 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:11:936 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start balancing cluster
2015-05-05-10:40:11:937 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start distributing Shards
2015-05-05-10:40:11:937 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:938 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:938 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:938 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:11:939 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start allocating unassigned shards
2015-05-05-10:40:11:941 - TRACE - Log4jESLogger - [Scratch, Nicholas] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[null], [P], s[UNASSIGNED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[CP_maFCdQTOVobnJFxUeXg][V]
--------[mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [P], s[UNASSIGNED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-10:40:11:942 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Publishing cluster state version 2
2015-05-05-10:40:11:943 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Set cluster state to version 2. Broadcasting to listeners.
2015-05-05-10:40:11:944 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:40:11:946 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:40:11:946 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] creating index
2015-05-05-10:40:11:947 - DEBUG - Log4jESLogger - [Scratch, Nicholas] creating Index [mimos], shards [5]/[1]
2015-05-05-10:40:12:304 - TRACE - Log4jESLogger - [Scratch, Nicholas] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [CP_maFCdQTOVobnJFxUeXg], scheduling a retry.
2015-05-05-10:40:12:322 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-05-10:40:12:323 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-05-10:40:12:335 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-05-10:40:12:398 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"author":{"type":"string"},"content":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-05-10:40:12:488 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Sending mapping created for index mimos, type Programmer
2015-05-05-10:40:12:492 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] creating shard
2015-05-05-10:40:12:493 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] creating shard_id [1]
2015-05-05-10:40:12:649 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] Using [keep_only_last] deletion policy
2015-05-05-10:40:12:653 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:40:12:654 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:40:12:660 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] state: [CREATED]
2015-05-05-10:40:12:661 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:40:12:673 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:40:12:674 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] starting recovery from local ...
2015-05-05-10:40:12:676 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] creating shard
2015-05-05-10:40:12:677 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] creating shard_id [2]
2015-05-05-10:40:12:683 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-05-10:40:12:684 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] starting engine
2015-05-05-10:40:12:700 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] Using [keep_only_last] deletion policy
2015-05-05-10:40:12:701 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:40:12:702 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:40:12:703 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] state: [CREATED]
2015-05-05-10:40:12:704 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:40:12:707 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:40:12:707 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] starting recovery from local ...
2015-05-05-10:40:12:708 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-05-10:40:12:709 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] starting engine
2015-05-05-10:40:12:713 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] creating shard
2015-05-05-10:40:12:715 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] creating shard_id [3]
2015-05-05-10:40:12:728 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] Using [keep_only_last] deletion policy
2015-05-05-10:40:12:731 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:40:12:734 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:40:12:741 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] state: [CREATED]
2015-05-05-10:40:12:742 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:40:12:743 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:40:12:744 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] creating shard
2015-05-05-10:40:12:744 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] creating shard_id [4]
2015-05-05-10:40:12:751 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] starting recovery from local ...
2015-05-05-10:40:12:759 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-05-10:40:12:759 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] starting engine
2015-05-05-10:40:12:762 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] Using [keep_only_last] deletion policy
2015-05-05-10:40:12:763 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:40:12:764 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:40:12:765 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] state: [CREATED]
2015-05-05-10:40:12:765 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:40:12:774 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:40:12:780 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] starting recovery from local ...
2015-05-05-10:40:12:781 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-05-10:40:12:782 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] starting engine
2015-05-05-10:40:12:788 - TRACE - Log4jESLogger - [Scratch, Nicholas] [_global] writing state, reason [changed]
2015-05-05-10:40:12:825 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:40:12:825 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:40:12:825 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:40:12:825 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:40:12:829 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][4] warming took [3ms]
2015-05-05-10:40:12:829 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][2] warming took [2.2ms]
2015-05-05-10:40:12:829 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][1] warming took [1.8ms]
2015-05-05-10:40:12:838 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:40:12:841 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:40:12:851 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] scheduling refresher every 1s
2015-05-05-10:40:12:840 - INFO  - Log4jESLogger - [Scratch, Nicholas] recovered [1] indices into cluster_state
2015-05-05-10:40:12:837 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][3] warming took [10.7ms]
2015-05-05-10:40:12:834 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:40:12:853 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] scheduling refresher every 1s
2015-05-05-10:40:12:854 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:40:12:859 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] scheduling refresher every 1s
2015-05-05-10:40:12:842 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] scheduling refresher every 1s
2015-05-05-10:40:12:860 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-05-10:40:12:861 - TRACE - Log4jESLogger - [Scratch, Nicholas] listener to cluster state added, trying to index again
2015-05-05-10:40:12:862 - TRACE - Log4jESLogger - [Scratch, Nicholas] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [CP_maFCdQTOVobnJFxUeXg], scheduling a retry.
2015-05-05-10:40:12:862 - TRACE - Log4jESLogger - [Scratch, Nicholas] retry scheduling ignored as it as we already have a listener in place
2015-05-05-10:40:12:873 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] scheduling optimizer / merger every 1s
2015-05-05-10:40:12:874 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][2] refresh with force[true]
2015-05-05-10:40:12:874 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][2] recovery completed from [local], took [167ms]
2015-05-05-10:40:12:875 - DEBUG - Log4jESLogger - [Scratch, Nicholas] sending shard started for [mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:875 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] scheduling optimizer / merger every 1s
2015-05-05-10:40:12:875 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] scheduling optimizer / merger every 1s
2015-05-05-10:40:12:875 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] scheduling optimizer / merger every 1s
2015-05-05-10:40:12:876 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][4] refresh with force[true]
2015-05-05-10:40:12:876 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][4] recovery completed from [local], took [96ms]
2015-05-05-10:40:12:876 - DEBUG - Log4jESLogger - [Scratch, Nicholas] sending shard started for [mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:877 - DEBUG - Log4jESLogger - [Scratch, Nicholas] received shard started for [mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:875 - DEBUG - Log4jESLogger - [Scratch, Nicholas] received shard started for [mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:878 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [shard-started ([mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-10:40:12:879 - DEBUG - Log4jESLogger - [Scratch, Nicholas] applying started shards [[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], [mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-05-10:40:12:875 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][3] refresh with force[true]
2015-05-05-10:40:12:878 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][1] refresh with force[true]
2015-05-05-10:40:12:881 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-10:40:12:881 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start balancing cluster
2015-05-05-10:40:12:881 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start distributing Shards
2015-05-05-10:40:12:882 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:882 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[STARTED]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:882 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:882 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[STARTED]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:882 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][0], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:882 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start allocating unassigned shards
2015-05-05-10:40:12:883 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:12:883 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:12:883 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:12:880 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][3] recovery completed from [local], took [129ms]
2015-05-05-10:40:12:884 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][1] recovery completed from [local], took [210ms]
2015-05-05-10:40:12:885 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:12:884 - DEBUG - Log4jESLogger - [Scratch, Nicholas] sending shard started for [mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:886 - DEBUG - Log4jESLogger - [Scratch, Nicholas] received shard started for [mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:886 - TRACE - Log4jESLogger - [Scratch, Nicholas] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-10:40:12:885 - DEBUG - Log4jESLogger - [Scratch, Nicholas] sending shard started for [mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:888 - DEBUG - Log4jESLogger - [Scratch, Nicholas] received shard started for [mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:887 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start balancing cluster
2015-05-05-10:40:12:889 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start distributing Shards
2015-05-05-10:40:12:889 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:889 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[STARTED]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:889 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:890 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[STARTED]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:890 - TRACE - Log4jESLogger - [Scratch, Nicholas] Assigned shard [[mimos][0], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]] to node [CP_maFCdQTOVobnJFxUeXg]
2015-05-05-10:40:12:890 - TRACE - Log4jESLogger - [Scratch, Nicholas] Start allocating unassigned shards
2015-05-05-10:40:12:891 - TRACE - Log4jESLogger - [Scratch, Nicholas] cluster state updated:
version [3], source [shard-started ([mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[CP_maFCdQTOVobnJFxUeXg][V]
--------[mimos][0], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][2], node[CP_maFCdQTOVobnJFxUeXg], [P], s[STARTED]
--------[mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING]
--------[mimos][4], node[CP_maFCdQTOVobnJFxUeXg], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-10:40:12:891 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Publishing cluster state version 3
2015-05-05-10:40:12:892 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Set cluster state to version 3. Broadcasting to listeners.
2015-05-05-10:40:12:892 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [reroute_rivers_node_changed]: execute
2015-05-05-10:40:12:893 - DEBUG - Log4jESLogger - [Scratch, Nicholas] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-10:40:12:892 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] creating shard
2015-05-05-10:40:12:899 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos] creating shard_id [0]
2015-05-05-10:40:12:906 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] Using [keep_only_last] deletion policy
2015-05-05-10:40:12:908 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-10:40:12:908 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-10:40:12:909 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] state: [CREATED]
2015-05-05-10:40:12:909 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-10:40:12:910 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-10:40:12:911 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] starting recovery from local ...
2015-05-05-10:40:12:911 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-05-10:40:12:912 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] starting engine
2015-05-05-10:40:12:914 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-10:40:12:915 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][0] warming took [210.3micros]
2015-05-05-10:40:12:916 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-10:40:12:916 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] scheduling refresher every 1s
2015-05-05-10:40:12:916 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] scheduling optimizer / merger every 1s
2015-05-05-10:40:12:917 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][0] refresh with force[true]
2015-05-05-10:40:12:917 - DEBUG - Log4jESLogger - [Scratch, Nicholas] [mimos][0] recovery completed from [local], took [6ms]
2015-05-05-10:40:12:917 - DEBUG - Log4jESLogger - [Scratch, Nicholas] sending shard started for [mimos][0], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:917 - DEBUG - Log4jESLogger - [Scratch, Nicholas] received shard started for [mimos][0], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-10:40:12:915 - TRACE - Log4jESLogger - [Scratch, Nicholas] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-05-10:40:12:918 - DEBUG - Log4jESLogger - [Scratch, Nicholas] sending shard started for [mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [master [Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-10:40:12:918 - DEBUG - Log4jESLogger - [Scratch, Nicholas] received shard started for [mimos][1], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [master [Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-10:40:12:919 - TRACE - Log4jESLogger - [Scratch, Nicholas] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-05-10:40:12:919 - DEBUG - Log4jESLogger - [Scratch, Nicholas] sending shard started for [mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [master [Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-10:40:12:919 - DEBUG - Log4jESLogger - [Scratch, Nicholas] received shard started for [mimos][3], node[CP_maFCdQTOVobnJFxUeXg], [P], s[INITIALIZING], reason [master [Scratch, Nicholas][CP_maFCdQTOVobnJFxUeXg][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-10:40:12:920 - TRACE - Log4jESLogger - [Scratch, Nicholas] cluster changed (version 3), trying to index again
2015-05-05-10:40:12:923 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][4] writing shard state, reason [version changed from [16] to [18]]
2015-05-05-10:40:12:946 - TRACE - Log4jESLogger - [Scratch, Nicholas] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-05-10:40:12:976 - DEBUG - Log4jESLogger - [Scratch, Nicholas] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-05-17:05:09:517 - INFO  - Log4jESLogger - [Killraven] version[0.90.5], pid[22189], build[c8714e8/2013-09-17T12:50:20Z]
2015-05-05-17:05:09:520 - INFO  - Log4jESLogger - [Killraven] initializing ...
2015-05-05-17:05:09:521 - DEBUG - Log4jESLogger - [Killraven] using home [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated], config [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/config], data [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data]], logs [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/logs], work [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/work], plugins [/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/plugins]
2015-05-05-17:05:09:534 - INFO  - Log4jESLogger - [Killraven] loaded [], sites []
2015-05-05-17:05:09:562 - DEBUG - Log4jESLogger - using [UnsafeChunkDecoder] decoder
2015-05-05-17:05:09:583 - TRACE - Log4jESLogger - [Killraven] obtaining node lock on /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0 ...
2015-05-05-17:05:09:617 - DEBUG - Log4jESLogger - [Killraven] using node location [[/home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0]], local_node_id [0]
2015-05-05-17:05:09:623 - TRACE - Log4jESLogger - [Killraven] node data locations details:
 -> /home/filhan/WKSPC/wkspc-orm/ElasticSearchUpdated/data/peansData/nodes/0, free_space [31.9gb], usable_space [26.6gb]

2015-05-05-17:05:10:230 - TRACE - Log4jESLogger - [Killraven] sigar loaded successfully
2015-05-05-17:05:10:829 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [generic], type [cached], keep_alive [30s]
2015-05-05-17:05:10:835 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [index], type [fixed], size [4], queue_size [null]
2015-05-05-17:05:10:839 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [bulk], type [fixed], size [4], queue_size [null]
2015-05-05-17:05:10:840 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [get], type [fixed], size [4], queue_size [null]
2015-05-05-17:05:10:842 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [search], type [fixed], size [12], queue_size [1k]
2015-05-05-17:05:10:844 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2015-05-05-17:05:10:854 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2015-05-05-17:05:10:857 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2015-05-05-17:05:10:859 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-17:05:10:859 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [merge], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-17:05:10:860 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-17:05:10:860 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-17:05:10:861 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2015-05-05-17:05:10:861 - DEBUG - Log4jESLogger - [Killraven] creating thread_pool [optimize], type [fixed], size [1], queue_size [null]
2015-05-05-17:05:10:877 - DEBUG - Log4jESLogger - [Killraven] using worker_count[8], port[9300-9400], bind_host[null], publish_host[null], compress[false], connect_timeout[30s], connections_per_node[2/6/1/1], receive_predictor[512kb->512kb]
2015-05-05-17:05:10:887 - DEBUG - Log4jESLogger - [Killraven] using group [224.2.2.4], with port [54328], ttl [3], and address [null]
2015-05-05-17:05:10:892 - DEBUG - Log4jESLogger - [Killraven] using initial hosts [], with concurrent_connects [10]
2015-05-05-17:05:10:896 - DEBUG - Log4jESLogger - [Killraven] using ping.timeout [3s], master_election.filter_client [true], master_election.filter_data [false]
2015-05-05-17:05:10:898 - DEBUG - Log4jESLogger - [Killraven] using minimum_master_nodes [-1]
2015-05-05-17:05:10:900 - DEBUG - Log4jESLogger - [Killraven] [master] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-17:05:10:906 - DEBUG - Log4jESLogger - [Killraven] [node  ] uses ping_interval [1s], ping_timeout [30s], ping_retries [3]
2015-05-05-17:05:10:953 - DEBUG - Log4jESLogger - [Killraven] enabled [true], last_gc_enabled [false], interval [1s], gc_threshold [{ParNew=GcThreshold{name='ParNew', warnThreshold=1000, infoThreshold=700, debugThreshold=400}, default=GcThreshold{name='default', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}, ConcurrentMarkSweep=GcThreshold{name='ConcurrentMarkSweep', warnThreshold=10000, infoThreshold=5000, debugThreshold=2000}}]
2015-05-05-17:05:11:465 - DEBUG - Log4jESLogger - [Killraven] Using probe [org.elasticsearch.monitor.os.SigarOsProbe@f5c79a6] with refresh_interval [1s]
2015-05-05-17:05:11:470 - DEBUG - Log4jESLogger - [Killraven] Using probe [org.elasticsearch.monitor.process.SigarProcessProbe@41c07648] with refresh_interval [1s]
2015-05-05-17:05:11:477 - DEBUG - Log4jESLogger - [Killraven] Using refresh_interval [1s]
2015-05-05-17:05:11:478 - DEBUG - Log4jESLogger - [Killraven] Using probe [org.elasticsearch.monitor.network.SigarNetworkProbe@4593ff34] with refresh_interval [5s]
2015-05-05-17:05:11:484 - DEBUG - Log4jESLogger - [Killraven] net_info
host [khairul-OptiPlex-760]
vmnet8	display_name [vmnet8]
		address [/fe80:0:0:0:250:56ff:fec0:8%vmnet8] [/192.168.25.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
vmnet1	display_name [vmnet1]
		address [/fe80:0:0:0:250:56ff:fec0:1%vmnet1] [/192.168.75.1] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
eth0	display_name [eth0]
		address [/fe80:0:0:0:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:223:aeff:fe8a:d666%eth0] [/2407:4000:4:366:a:8707:d723:bfb2%eth0] [/10.11.66.27] 
		mtu [1500] multicast [true] ptp [false] loopback [false] up [true] virtual [false]
lo	display_name [lo]
		address [/0:0:0:0:0:0:0:1%lo] [/127.0.0.1] 
		mtu [65536] multicast [false] ptp [false] loopback [true] up [true] virtual [false]

2015-05-05-17:05:11:487 - TRACE - Log4jESLogger - [Killraven] ifconfig

lo	Link encap:Local Loopback
	inet addr:127.0.0.1  Mask:255.0.0.0
	UP LOOPBACK RUNNING  MTU:65536  Metric:1
	RX packets:93193 errors:0 dropped:0 overruns:0 frame:0
	TX packets:93193 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:10738541 ( 10M)  TX bytes:10738541 ( 10M)
eth0	Link encap:Ethernet HWaddr 00:23:AE:8A:D6:66
	inet addr:10.11.66.27  Bcast:10.11.66.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:4055526 errors:0 dropped:0 overruns:0 frame:0
	TX packets:1998853 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:5326447521 (5.0G)  TX bytes:172912205 (165M)
vmnet1	Link encap:Ethernet HWaddr 00:50:56:C0:00:01
	inet addr:192.168.75.1  Bcast:192.168.75.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:1220 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )
vmnet8	Link encap:Ethernet HWaddr 00:50:56:C0:00:08
	inet addr:192.168.25.1  Bcast:192.168.25.255  Mask:255.255.255.0
	UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
	RX packets:0 errors:0 dropped:0 overruns:0 frame:0
	TX packets:1220 errors:0 dropped:0 overruns:0 carrier:0
	collisions:0
	RX bytes:0 (  0 )  TX bytes:0 (  0 )

2015-05-05-17:05:11:517 - DEBUG - Log4jESLogger - [Killraven] Using probe [org.elasticsearch.monitor.fs.SigarFsProbe@c8b96ec] with refresh_interval [1s]
2015-05-05-17:05:11:767 - DEBUG - Log4jESLogger - [Killraven] using indices.store.throttle.type [MERGE], with index.store.throttle.max_bytes_per_sec [20mb]
2015-05-05-17:05:11:776 - DEBUG - Log4jESLogger - [Killraven] using bytebuffer cache with small_buffer_size [1kb], large_buffer_size [1mb], small_cache_size [10mb], large_cache_size [500mb], direct [true]
2015-05-05-17:05:11:785 - DEBUG - Log4jESLogger - [Killraven] using script cache with max_size [500], expire [null]
2015-05-05-17:05:11:791 - DEBUG - Log4jESLogger - [Killraven] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-17:05:11:793 - DEBUG - Log4jESLogger - [Killraven] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-17:05:11:794 - DEBUG - Log4jESLogger - [Killraven] using [cluster_concurrent_rebalance] with [2]
2015-05-05-17:05:11:800 - DEBUG - Log4jESLogger - [Killraven] using initial_shards [quorum], list_timeout [30s]
2015-05-05-17:05:11:892 - DEBUG - Log4jESLogger - [Killraven] using max_bytes_per_sec[20mb], concurrent_streams [3], file_chunk_size [512kb], translog_size [512kb], translog_ops [1000], and compress [true]
2015-05-05-17:05:11:985 - DEBUG - Log4jESLogger - [Killraven] using max_chunk_size[8kb], max_header_size[8kb], max_initial_line_length[4kb], max_content_length[100mb], receive_predictor[512kb->512kb]
2015-05-05-17:05:11:999 - DEBUG - Log4jESLogger - [Killraven] using index_buffer_size [85.1mb], with min_shard_index_buffer_size [4mb], max_shard_index_buffer_size [512mb], shard_inactive_time [30m]
2015-05-05-17:05:12:002 - DEBUG - Log4jESLogger - [Killraven] using [node] weighted filter cache with size [20%], actual_size [170.3mb], expire [null], clean_interval [1m]
2015-05-05-17:05:12:005 - DEBUG - Log4jESLogger - [Killraven] using size [-1] [-1b], expire [null]
2015-05-05-17:05:12:020 - DEBUG - Log4jESLogger - [Killraven] using gateway.local.auto_import_dangled [YES], with gateway.local.dangling_timeout [2h]
2015-05-05-17:05:12:037 - TRACE - Log4jESLogger - [Killraven] [upgrade]: processing [global-9]
2015-05-05-17:05:12:179 - DEBUG - Log4jESLogger - [Killraven] took 141ms to load state
2015-05-05-17:05:12:180 - TRACE - Log4jESLogger - [Killraven] [find_latest_state]: processing [global-9]
2015-05-05-17:05:12:199 - DEBUG - Log4jESLogger - [Killraven] took 18ms to load started shards state
2015-05-05-17:05:12:203 - DEBUG - Log4jESLogger - [Killraven] using enabled [false], host [null], port [9700-9800], bulk_actions [1000], bulk_size [5mb], flush_interval [5s], concurrent_requests [4]
2015-05-05-17:05:12:209 - DEBUG - Log4jESLogger - [Killraven] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-17:05:12:211 - DEBUG - Log4jESLogger - [Killraven] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-17:05:12:212 - DEBUG - Log4jESLogger - [Killraven] using [cluster_concurrent_rebalance] with [2]
2015-05-05-17:05:12:213 - DEBUG - Log4jESLogger - [Killraven] using node_concurrent_recoveries [2], node_initial_primaries_recoveries [4]
2015-05-05-17:05:12:213 - DEBUG - Log4jESLogger - [Killraven] using [cluster.routing.allocation.allow_rebalance] with [indices_all_active]
2015-05-05-17:05:12:214 - DEBUG - Log4jESLogger - [Killraven] using [cluster_concurrent_rebalance] with [2]
2015-05-05-17:05:12:219 - INFO  - Log4jESLogger - [Killraven] initialized
2015-05-05-17:05:12:219 - INFO  - Log4jESLogger - [Killraven] starting ...
2015-05-05-17:05:12:245 - DEBUG - Log4jESLogger - Using select timeout of 500
2015-05-05-17:05:12:246 - DEBUG - Log4jESLogger - Epoll-bug workaround enabled = false
2015-05-05-17:05:12:311 - DEBUG - Log4jESLogger - [Killraven] Bound to address [/0:0:0:0:0:0:0:0:9300]
2015-05-05-17:05:12:315 - INFO  - Log4jESLogger - [Killraven] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.11.66.27:9300]}
2015-05-05-17:05:12:344 - TRACE - Log4jESLogger - [Killraven] waiting for 30s for the initial state to be set by the discovery
2015-05-05-17:05:12:353 - TRACE - Log4jESLogger - [Killraven] [1] sending ping request
2015-05-05-17:05:13:854 - TRACE - Log4jESLogger - [Killraven] [1] sending ping request
2015-05-05-17:05:15:357 - TRACE - Log4jESLogger - [Killraven] full ping responses: {none}
2015-05-05-17:05:15:357 - DEBUG - Log4jESLogger - [Killraven] filtered ping responses: (filter_client[true], filter_data[false]) {none}
2015-05-05-17:05:15:361 - DEBUG - Log4jESLogger - [Killraven] processing [zen-disco-join (elected_as_master)]: execute
2015-05-05-17:05:15:363 - TRACE - Log4jESLogger - [Killraven] cluster state updated:
version [1], source [zen-disco-join (elected_as_master)]
nodes: 
   [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]], local, master
routing_table:
routing_nodes:
-----node_id[FdRZqslHRsuI92g6qNab0A][V]
---- unassigned

2015-05-05-17:05:15:365 - INFO  - Log4jESLogger - [Killraven] new_master [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]], reason: zen-disco-join (elected_as_master)
2015-05-05-17:05:15:382 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0xc25d1399, /10.11.66.27:60904 => /10.11.66.27:9300]
2015-05-05-17:05:15:385 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0xcff52988, /10.11.66.27:60905 => /10.11.66.27:9300]
2015-05-05-17:05:15:387 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0x4496fb92, /10.11.66.27:60906 => /10.11.66.27:9300]
2015-05-05-17:05:15:389 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0x44f6b698, /10.11.66.27:60907 => /10.11.66.27:9300]
2015-05-05-17:05:15:395 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0xe18ca5b6, /10.11.66.27:60908 => /10.11.66.27:9300]
2015-05-05-17:05:15:398 - DEBUG - Log4jESLogger - [Killraven] connected to node [[Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]]]
2015-05-05-17:05:15:399 - DEBUG - Log4jESLogger - [Killraven] Publishing cluster state version 1
2015-05-05-17:05:15:400 - DEBUG - Log4jESLogger - [Killraven] Set cluster state to version 1. Broadcasting to listeners.
2015-05-05-17:05:15:401 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0xc1f19f8a, /10.11.66.27:60909 => /10.11.66.27:9300]
2015-05-05-17:05:15:406 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0x1fbbc4b0, /10.11.66.27:60910 => /10.11.66.27:9300]
2015-05-05-17:05:15:406 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0x0ea8e238, /10.11.66.27:60911 => /10.11.66.27:9300]
2015-05-05-17:05:15:408 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0xdb64b737, /10.11.66.27:60912 => /10.11.66.27:9300]
2015-05-05-17:05:15:408 - DEBUG - Log4jESLogger - [Killraven] processing [reroute_rivers_node_changed]: execute
2015-05-05-17:05:15:409 - DEBUG - Log4jESLogger - [Killraven] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-17:05:15:409 - TRACE - Log4jESLogger - [Killraven] initial state set from discovery
2015-05-05-17:05:15:409 - TRACE - Log4jESLogger - [Killraven] channel opened: [id: 0xe73761fd, /10.11.66.27:60913 => /10.11.66.27:9300]
2015-05-05-17:05:15:409 - DEBUG - Log4jESLogger - [Killraven] processing [zen-disco-join (elected_as_master)]: done applying updated cluster_state (version: 1)
2015-05-05-17:05:15:410 - INFO  - Log4jESLogger - [Killraven] peansData/FdRZqslHRsuI92g6qNab0A
2015-05-05-17:05:15:412 - TRACE - Log4jESLogger - [Killraven] performing state recovery...
2015-05-05-17:05:15:412 - TRACE - Log4jESLogger - [Killraven] performing state recovery from [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:414 - TRACE - Log4jESLogger - [Killraven] I have been elected master, scheduling a ClusterInfoUpdateJob
2015-05-05-17:05:15:422 - TRACE - Log4jESLogger - [Killraven] successful state recovery, importing cluster state...
2015-05-05-17:05:15:424 - DEBUG - Log4jESLogger - [Killraven] processing [local-gateway-elected-state]: execute
2015-05-05-17:05:15:441 - INFO  - Log4jESLogger - [Killraven] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/10.11.66.27:9200]}
2015-05-05-17:05:15:441 - INFO  - Log4jESLogger - [Killraven] started
2015-05-05-17:05:15:447 - DEBUG - Log4jESLogger - [Killraven] [mimos][4]: allocating [[mimos][4], node[null], [P], s[UNASSIGNED]] to [[Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-17:05:15:449 - DEBUG - Log4jESLogger - [Killraven] [mimos][0]: allocating [[mimos][0], node[null], [P], s[UNASSIGNED]] to [[Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-17:05:15:450 - DEBUG - Log4jESLogger - [Killraven] [mimos][1]: allocating [[mimos][1], node[null], [P], s[UNASSIGNED]] to [[Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-17:05:15:452 - DEBUG - Log4jESLogger - [Killraven] [mimos][2]: allocating [[mimos][2], node[null], [P], s[UNASSIGNED]] to [[Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-17:05:15:454 - DEBUG - Log4jESLogger - [Killraven] [mimos][3]: throttling allocation [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[[Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]]]] on primary allocation
2015-05-05-17:05:15:458 - TRACE - Log4jESLogger - [Killraven] Start balancing cluster
2015-05-05-17:05:15:459 - TRACE - Log4jESLogger - [Killraven] Start distributing Shards
2015-05-05-17:05:15:462 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:462 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:464 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:464 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:465 - TRACE - Log4jESLogger - [Killraven] Start allocating unassigned shards
2015-05-05-17:05:15:466 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:15:467 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:15:467 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:15:468 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:15:468 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:15:469 - TRACE - Log4jESLogger - [Killraven] Start balancing cluster
2015-05-05-17:05:15:470 - TRACE - Log4jESLogger - [Killraven] Start distributing Shards
2015-05-05-17:05:15:470 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:470 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:470 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:471 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:15:475 - TRACE - Log4jESLogger - [Killraven] Start allocating unassigned shards
2015-05-05-17:05:15:481 - TRACE - Log4jESLogger - [Killraven] cluster state updated:
version [2], source [local-gateway-elected-state]
nodes: 
   [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[FdRZqslHRsuI92g6qNab0A][V]
--------[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [P], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-17:05:15:482 - DEBUG - Log4jESLogger - [Killraven] Publishing cluster state version 2
2015-05-05-17:05:15:483 - DEBUG - Log4jESLogger - [Killraven] Set cluster state to version 2. Broadcasting to listeners.
2015-05-05-17:05:15:486 - DEBUG - Log4jESLogger - [Killraven] processing [reroute_rivers_node_changed]: execute
2015-05-05-17:05:15:487 - DEBUG - Log4jESLogger - [Killraven] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-17:05:15:487 - DEBUG - Log4jESLogger - [Killraven] [mimos] creating index
2015-05-05-17:05:15:489 - DEBUG - Log4jESLogger - [Killraven] creating Index [mimos], shards [5]/[1]
2015-05-05-17:05:15:863 - TRACE - Log4jESLogger - [Killraven] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [FdRZqslHRsuI92g6qNab0A], scheduling a retry.
2015-05-05-17:05:15:892 - DEBUG - Log4jESLogger - [Killraven] [mimos] using dynamic[true], default mapping: default_mapping_location[null], loaded_from[jar:file:/home/filhan/.m2/repository/org/elasticsearch/elasticsearch/0.90.5/elasticsearch-0.90.5.jar!/org/elasticsearch/index/mapper/default-mapping.json]
2015-05-05-17:05:15:893 - DEBUG - Log4jESLogger - [Killraven] [mimos] using [resident] query cache with max_size [100], expire [null]
2015-05-05-17:05:15:911 - DEBUG - Log4jESLogger - [Killraven] [mimos] using index.store.throttle.type [node], with index.store.throttle.max_bytes_per_sec [0b]
2015-05-05-17:05:15:974 - DEBUG - Log4jESLogger - [Killraven] [mimos] adding mapping [Programmer], source [{"Programmer":{"properties":{"author":{"type":"string"},"content":{"type":"string"},"postDate":{"type":"date","format":"dateOptionalTime"},"tags":{"type":"string"},"title":{"type":"string"}}}}]
2015-05-05-17:05:16:050 - DEBUG - Log4jESLogger - [Killraven] Sending mapping created for index mimos, type Programmer
2015-05-05-17:05:16:053 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] creating shard
2015-05-05-17:05:16:054 - DEBUG - Log4jESLogger - [Killraven] [mimos] creating shard_id [0]
2015-05-05-17:05:16:186 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] Using [keep_only_last] deletion policy
2015-05-05-17:05:16:192 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-17:05:16:194 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-17:05:16:201 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] state: [CREATED]
2015-05-05-17:05:16:205 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-17:05:16:212 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-17:05:16:215 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] starting recovery from local ...
2015-05-05-17:05:16:216 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] creating shard
2015-05-05-17:05:16:218 - DEBUG - Log4jESLogger - [Killraven] [mimos] creating shard_id [1]
2015-05-05-17:05:16:231 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] Using [keep_only_last] deletion policy
2015-05-05-17:05:16:235 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-17:05:16:236 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-17:05:16:237 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] state: [CREATED]
2015-05-05-17:05:16:238 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-17:05:16:240 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-17:05:16:241 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] starting recovery from local ...
2015-05-05-17:05:16:242 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] creating shard
2015-05-05-17:05:16:242 - DEBUG - Log4jESLogger - [Killraven] [mimos] creating shard_id [2]
2015-05-05-17:05:16:257 - TRACE - Log4jESLogger - [Killraven] [mimos][1] using existing shard data, translog id [1430291139236]
2015-05-05-17:05:16:259 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] starting engine
2015-05-05-17:05:16:257 - TRACE - Log4jESLogger - [Killraven] [mimos][0] using existing shard data, translog id [1430291139236]
2015-05-05-17:05:16:268 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] starting engine
2015-05-05-17:05:16:282 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] Using [keep_only_last] deletion policy
2015-05-05-17:05:16:283 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-17:05:16:287 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-17:05:16:294 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] state: [CREATED]
2015-05-05-17:05:16:296 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-17:05:16:299 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-17:05:16:299 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] creating shard
2015-05-05-17:05:16:300 - DEBUG - Log4jESLogger - [Killraven] [mimos] creating shard_id [4]
2015-05-05-17:05:16:308 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] starting recovery from local ...
2015-05-05-17:05:16:316 - TRACE - Log4jESLogger - [Killraven] [mimos][2] using existing shard data, translog id [1430291139236]
2015-05-05-17:05:16:319 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] starting engine
2015-05-05-17:05:16:329 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] Using [keep_only_last] deletion policy
2015-05-05-17:05:16:330 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-17:05:16:331 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-17:05:16:332 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] state: [CREATED]
2015-05-05-17:05:16:333 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-17:05:16:334 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-17:05:16:338 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] starting recovery from local ...
2015-05-05-17:05:16:339 - TRACE - Log4jESLogger - [Killraven] [_global] writing state, reason [changed]
2015-05-05-17:05:16:349 - TRACE - Log4jESLogger - [Killraven] [mimos][4] using existing shard data, translog id [1430291139427]
2015-05-05-17:05:16:374 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] starting engine
2015-05-05-17:05:16:379 - TRACE - Log4jESLogger - [Killraven] [mimos][4] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-17:05:16:381 - TRACE - Log4jESLogger - [Killraven] [mimos][2] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-17:05:16:382 - TRACE - Log4jESLogger - [Killraven] [mimos][1] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-17:05:16:382 - TRACE - Log4jESLogger - [Killraven] [mimos][4] warming took [1.6ms]
2015-05-05-17:05:16:389 - INFO  - Log4jESLogger - [Killraven] recovered [1] indices into cluster_state
2015-05-05-17:05:16:390 - DEBUG - Log4jESLogger - [Killraven] processing [local-gateway-elected-state]: done applying updated cluster_state (version: 2)
2015-05-05-17:05:16:381 - TRACE - Log4jESLogger - [Killraven] [mimos][0] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-17:05:16:391 - TRACE - Log4jESLogger - [Killraven] listener to cluster state added, trying to index again
2015-05-05-17:05:16:390 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-17:05:16:383 - TRACE - Log4jESLogger - [Killraven] [mimos][2] warming took [589.4micros]
2015-05-05-17:05:16:396 - TRACE - Log4jESLogger - [Killraven] [mimos][0] warming took [1ms]
2015-05-05-17:05:16:395 - TRACE - Log4jESLogger - [Killraven] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [FdRZqslHRsuI92g6qNab0A], scheduling a retry.
2015-05-05-17:05:16:397 - TRACE - Log4jESLogger - [Killraven] retry scheduling ignored as it as we already have a listener in place
2015-05-05-17:05:16:395 - TRACE - Log4jESLogger - [Killraven] [mimos][1] warming took [7.8ms]
2015-05-05-17:05:16:398 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-17:05:16:397 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-17:05:16:397 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] scheduling refresher every 1s
2015-05-05-17:05:16:399 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-17:05:16:399 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] scheduling refresher every 1s
2015-05-05-17:05:16:400 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] scheduling optimizer / merger every 1s
2015-05-05-17:05:16:401 - TRACE - Log4jESLogger - [Killraven] [mimos][1] refresh with force[true]
2015-05-05-17:05:16:401 - DEBUG - Log4jESLogger - [Killraven] [mimos][1] recovery completed from [local], took [160ms]
2015-05-05-17:05:16:401 - DEBUG - Log4jESLogger - [Killraven] sending shard started for [mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:401 - DEBUG - Log4jESLogger - [Killraven] received shard started for [mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:399 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] scheduling refresher every 1s
2015-05-05-17:05:16:399 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] scheduling refresher every 1s
2015-05-05-17:05:16:403 - DEBUG - Log4jESLogger - [Killraven] processing [shard-started ([mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-17:05:16:404 - DEBUG - Log4jESLogger - [Killraven] applying started shards [[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-05-17:05:16:405 - DEBUG - Log4jESLogger - [Killraven] [mimos][3]: allocating [[mimos][3], node[null], [P], s[UNASSIGNED]] to [[Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]]] on primary allocation
2015-05-05-17:05:16:405 - TRACE - Log4jESLogger - [Killraven] Start balancing cluster
2015-05-05-17:05:16:405 - TRACE - Log4jESLogger - [Killraven] Start distributing Shards
2015-05-05-17:05:16:406 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:406 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:406 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:406 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:406 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:406 - TRACE - Log4jESLogger - [Killraven] Start allocating unassigned shards
2015-05-05-17:05:16:407 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:407 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:407 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:408 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:408 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:403 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] scheduling optimizer / merger every 1s
2015-05-05-17:05:16:409 - TRACE - Log4jESLogger - [Killraven] [mimos][0] refresh with force[true]
2015-05-05-17:05:16:409 - DEBUG - Log4jESLogger - [Killraven] [mimos][0] recovery completed from [local], took [194ms]
2015-05-05-17:05:16:409 - DEBUG - Log4jESLogger - [Killraven] sending shard started for [mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:409 - DEBUG - Log4jESLogger - [Killraven] received shard started for [mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:400 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] scheduling optimizer / merger every 1s
2015-05-05-17:05:16:410 - TRACE - Log4jESLogger - [Killraven] [mimos][4] refresh with force[true]
2015-05-05-17:05:16:410 - DEBUG - Log4jESLogger - [Killraven] [mimos][4] recovery completed from [local], took [72ms]
2015-05-05-17:05:16:410 - DEBUG - Log4jESLogger - [Killraven] sending shard started for [mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:410 - DEBUG - Log4jESLogger - [Killraven] received shard started for [mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:403 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] scheduling optimizer / merger every 1s
2015-05-05-17:05:16:411 - TRACE - Log4jESLogger - [Killraven] [mimos][2] refresh with force[true]
2015-05-05-17:05:16:411 - DEBUG - Log4jESLogger - [Killraven] [mimos][2] recovery completed from [local], took [103ms]
2015-05-05-17:05:16:411 - DEBUG - Log4jESLogger - [Killraven] sending shard started for [mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:411 - DEBUG - Log4jESLogger - [Killraven] received shard started for [mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:412 - TRACE - Log4jESLogger - [Killraven] Start balancing cluster
2015-05-05-17:05:16:412 - TRACE - Log4jESLogger - [Killraven] Start distributing Shards
2015-05-05-17:05:16:412 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:412 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:412 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:413 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:413 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:413 - TRACE - Log4jESLogger - [Killraven] Start allocating unassigned shards
2015-05-05-17:05:16:414 - TRACE - Log4jESLogger - [Killraven] cluster state updated:
version [3], source [shard-started ([mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[FdRZqslHRsuI92g6qNab0A][V]
--------[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
--------[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-17:05:16:414 - DEBUG - Log4jESLogger - [Killraven] Publishing cluster state version 3
2015-05-05-17:05:16:414 - DEBUG - Log4jESLogger - [Killraven] Set cluster state to version 3. Broadcasting to listeners.
2015-05-05-17:05:16:415 - DEBUG - Log4jESLogger - [Killraven] processing [reroute_rivers_node_changed]: execute
2015-05-05-17:05:16:416 - TRACE - Log4jESLogger - [Killraven] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-05-17:05:16:417 - DEBUG - Log4jESLogger - [Killraven] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-17:05:16:417 - DEBUG - Log4jESLogger - [Killraven] sending shard started for [mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [master [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-17:05:16:418 - DEBUG - Log4jESLogger - [Killraven] received shard started for [mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [master [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-17:05:16:419 - TRACE - Log4jESLogger - [Killraven] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-05-17:05:16:421 - DEBUG - Log4jESLogger - [Killraven] sending shard started for [mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [master [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-17:05:16:421 - DEBUG - Log4jESLogger - [Killraven] received shard started for [mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [master [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-17:05:16:422 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] creating shard
2015-05-05-17:05:16:422 - DEBUG - Log4jESLogger - [Killraven] [mimos] creating shard_id [3]
2015-05-05-17:05:16:431 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] Using [keep_only_last] deletion policy
2015-05-05-17:05:16:433 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] using [tiered] merge policy with expunge_deletes_allowed[10.0], floor_segment[2mb], max_merge_at_once[10], max_merge_at_once_explicit[30], max_merged_segment[5gb], segments_per_tier[10.0], reclaim_deletes_weight[2.0], async_merge[true]
2015-05-05-17:05:16:433 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] using [concurrent] merge scheduler with max_thread_count[2]
2015-05-05-17:05:16:435 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] state: [CREATED]
2015-05-05-17:05:16:435 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] interval [5s], flush_threshold_ops [5000], flush_threshold_size [200mb], flush_threshold_period [30m]
2015-05-05-17:05:16:438 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] state: [CREATED]->[RECOVERING], reason [from gateway]
2015-05-05-17:05:16:439 - TRACE - Log4jESLogger - [Killraven] [{}][{}] master [{}] marked shard as initializing, but shard already created, mark shard as started
2015-05-05-17:05:16:439 - DEBUG - Log4jESLogger - [Killraven] sending shard started for [mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [master [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-17:05:16:439 - DEBUG - Log4jESLogger - [Killraven] received shard started for [mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [master [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]] marked shard as initializing, but shard already started, mark shard as started]
2015-05-05-17:05:16:439 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] starting recovery from local ...
2015-05-05-17:05:16:440 - TRACE - Log4jESLogger - [Killraven] cluster changed (version 3), trying to index again
2015-05-05-17:05:16:441 - TRACE - Log4jESLogger - [Killraven] [mimos][3] using existing shard data, translog id [1430291139236]
2015-05-05-17:05:16:444 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] starting engine
2015-05-05-17:05:16:446 - TRACE - Log4jESLogger - [Killraven] [mimos][3] warming [StandardDirectoryReader(segments_1:1:nrt)], new [StandardDirectoryReader(segments_1:1:nrt)]
2015-05-05-17:05:16:447 - TRACE - Log4jESLogger - [Killraven] [mimos][3] warming took [182.5micros]
2015-05-05-17:05:16:448 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] state: [RECOVERING]->[STARTED], reason [post recovery]
2015-05-05-17:05:16:449 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] scheduling refresher every 1s
2015-05-05-17:05:16:449 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] scheduling optimizer / merger every 1s
2015-05-05-17:05:16:450 - TRACE - Log4jESLogger - [Killraven] [mimos][3] refresh with force[true]
2015-05-05-17:05:16:450 - DEBUG - Log4jESLogger - [Killraven] [mimos][3] recovery completed from [local], took [11ms]
2015-05-05-17:05:16:450 - DEBUG - Log4jESLogger - [Killraven] sending shard started for [mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:450 - DEBUG - Log4jESLogger - [Killraven] received shard started for [mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], reason [after recovery from gateway]
2015-05-05-17:05:16:452 - TRACE - Log4jESLogger - [Killraven] primary shard [[mimos][2]] is not yet active or we do not know the node it is assigned to [FdRZqslHRsuI92g6qNab0A], scheduling a retry.
2015-05-05-17:05:16:453 - TRACE - Log4jESLogger - [Killraven] retry scheduling ignored as it as we already have a listener in place
2015-05-05-17:05:16:454 - TRACE - Log4jESLogger - [Killraven] [mimos][1] writing shard state, reason [version changed from [14] to [16]]
2015-05-05-17:05:16:512 - DEBUG - Log4jESLogger - [Killraven] processing [shard-started ([mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: done applying updated cluster_state (version: 3)
2015-05-05-17:05:16:513 - DEBUG - Log4jESLogger - [Killraven] processing [shard-started ([mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]: execute
2015-05-05-17:05:16:513 - DEBUG - Log4jESLogger - [Killraven] applying started shards [[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], [mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], [mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], [mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], [mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], [mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING], [mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]], reason [after recovery from gateway]
2015-05-05-17:05:16:514 - TRACE - Log4jESLogger - [Killraven] Start balancing cluster
2015-05-05-17:05:16:514 - TRACE - Log4jESLogger - [Killraven] Start distributing Shards
2015-05-05-17:05:16:515 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:515 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:515 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:515 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:516 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:516 - TRACE - Log4jESLogger - [Killraven] Start allocating unassigned shards
2015-05-05-17:05:16:516 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][0], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:517 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][1], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:517 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][2], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:517 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][3], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:518 - TRACE - Log4jESLogger - [Killraven] No Node found to assign shard [[mimos][4], node[null], [R], s[UNASSIGNED]]
2015-05-05-17:05:16:518 - TRACE - Log4jESLogger - [Killraven] Start balancing cluster
2015-05-05-17:05:16:518 - TRACE - Log4jESLogger - [Killraven] Start distributing Shards
2015-05-05-17:05:16:519 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:519 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:519 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:519 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:519 - TRACE - Log4jESLogger - [Killraven] Assigned shard [[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]] to node [FdRZqslHRsuI92g6qNab0A]
2015-05-05-17:05:16:520 - TRACE - Log4jESLogger - [Killraven] Start allocating unassigned shards
2015-05-05-17:05:16:521 - TRACE - Log4jESLogger - [Killraven] cluster state updated:
version [4], source [shard-started ([mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[INITIALIZING]), reason [after recovery from gateway]]
nodes: 
   [Killraven][FdRZqslHRsuI92g6qNab0A][inet[/10.11.66.27:9300]], local, master
routing_table:
-- index [mimos]
----shard_id [mimos][0]
--------[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][0], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][1]
--------[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][2]
--------[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][3]
--------[mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
----shard_id [mimos][4]
--------[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

routing_nodes:
-----node_id[FdRZqslHRsuI92g6qNab0A][V]
--------[mimos][0], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][1], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][2], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][3], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
--------[mimos][4], node[FdRZqslHRsuI92g6qNab0A], [P], s[STARTED]
---- unassigned
--------[mimos][0], node[null], [R], s[UNASSIGNED]
--------[mimos][1], node[null], [R], s[UNASSIGNED]
--------[mimos][2], node[null], [R], s[UNASSIGNED]
--------[mimos][3], node[null], [R], s[UNASSIGNED]
--------[mimos][4], node[null], [R], s[UNASSIGNED]

2015-05-05-17:05:16:521 - DEBUG - Log4jESLogger - [Killraven] Publishing cluster state version 4
2015-05-05-17:05:16:521 - DEBUG - Log4jESLogger - [Killraven] Set cluster state to version 4. Broadcasting to listeners.
2015-05-05-17:05:16:522 - DEBUG - Log4jESLogger - [Killraven] processing [reroute_rivers_node_changed]: execute
2015-05-05-17:05:16:523 - DEBUG - Log4jESLogger - [Killraven] processing [reroute_rivers_node_changed]: no change in cluster_state
2015-05-05-17:05:16:525 - TRACE - Log4jESLogger - [Killraven] cluster changed (version 4), trying to index again
2015-05-05-17:05:16:528 - TRACE - Log4jESLogger - [Killraven] [mimos][0] writing shard state, reason [version changed from [14] to [16]]
2015-05-05-17:05:16:552 - TRACE - Log4jESLogger - [Killraven] [mimos][2] index [Document<stored,indexed,omitNorms<_uid:> stored<_source:[7b 22 6e 61 6d 65 22 3a 22 70 65 61 6e 22 2c 22 69 64 22 3a 22 31 38 35 36 32 22 2c 22 61 67 65 22 3a 22 32 31 22 7d]> indexed,omitNorms,indexOptions=DOCS_ONLY<_type:Programmer> indexed,tokenized<name:pean> indexed,tokenized<id:18562> indexed,tokenized<age:21> indexed,tokenized<_all:>>]
2015-05-05-17:05:16:560 - TRACE - Log4jESLogger - [Killraven] [mimos][4] writing shard state, reason [version changed from [18] to [20]]
2015-05-05-17:05:16:598 - DEBUG - Log4jESLogger - [Killraven] Sending mapping updated to master: index [mimos] type [Programmer]
2015-05-05-17:05:16:619 - TRACE - Log4jESLogger - [Killraven] [mimos][3] writing shard state, reason [version changed from [16] to [18]]
